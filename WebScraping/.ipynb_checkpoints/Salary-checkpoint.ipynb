{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "\n",
    "# Web Scraping for Indeed.com and Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Case Overview\n",
    "\n",
    "You're working as a data scientist for a contracting firm that's rapidly expanding. Now that they have their most valuable employee (you!), they need to leverage data to win more contracts. Your firm offers technology and scientific solutions and wants to be competitive in the hiring market. Your principal wants you to\n",
    "\n",
    "   - determine the industry factors that are most important in predicting the salary amounts for these data.\n",
    "\n",
    "To limit the scope, your principal has suggested that you *focus on data-related job postings*, e.g. data scientist, data analyst, research scientist, business intelligence, and any others you might think of. You may also want to decrease the scope by *limiting your search to a single region.*\n",
    "\n",
    "Hint: Aggregators like [Indeed.com](https://www.indeed.com) regularly pool job postings from a variety of markets and industries.\n",
    "\n",
    "**Goal:** Scrape your own data from a job aggregation tool like Indeed.com in order to collect the data to best answer this question.\n",
    "\n",
    "---\n",
    "\n",
    "### Directions\n",
    "\n",
    "In this project you will be leveraging a variety of skills. The first will be to use the web-scraping and/or API techniques you've learned to collect data on data jobs from Indeed.com or another aggregator. Once you have collected and cleaned the data, you will use it to address the question above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factors that impact salary\n",
    "\n",
    "To predict salary the most appropriate approach would be a regression model.\n",
    "Here instead we just want to estimate which factors (like location, job title, job level, industry sector) lead to high or low salary and work with a classification model. To do so, split the salary into two groups of high and low salary, for example by choosing the median salary as a threshold (in principle you could choose any single or multiple splitting points).\n",
    "\n",
    "Use all the skills you have learned so far to build a predictive model.\n",
    "Whatever you decide to use, the most important thing is to justify your choices and interpret your results. *Communication of your process is key.* Note that most listings **DO NOT** come with salary information. You'll need to be able to extrapolate or predict the expected salaries for these listings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\").\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9732c901-ae26-4160-8376-42e22dd327df"
   },
   "source": [
    "#### Setup a request (using `requests`) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)\n",
    "\n",
    "The URL here has many query parameters:\n",
    "\n",
    "- `q` for the job search\n",
    "- This is followed by \"+20,000\" to return results with salaries (or expected salaries >$20,000)\n",
    "- `l` for a location \n",
    "- `start` for what result number to start on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "focus": false,
    "id": "e915023e-6b0d-4982-af2a-b1e0355f4927"
   },
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "focus": false,
    "id": "2efefc73-064a-482d-b3b5-ddf5508cb4ec"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "results = soup.find_all('div', class_='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"jobsearch-SerpJobCard unifiedRow row result\" data-jk=\"725fc70c4bf910ea\" data-tn-component=\"organicJob\" id=\"p_725fc70c4bf910ea\">\n",
      " <h2 class=\"title\">\n",
      "  <a class=\"jobtitle turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=725fc70c4bf910ea&amp;fccid=4f11fda3f02f70cd&amp;vjs=3\" id=\"jl_725fc70c4bf910ea\" onclick=\"setRefineByCookie(['salest']); return rclk(this,jobmap[0],true,0);\" onmousedown=\"return rclk(this,jobmap[0],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"NLP Data Scientist Internship\">\n",
      "   NLP\n",
      "   <b>\n",
      "    Data\n",
      "   </b>\n",
      "   <b>\n",
      "    Scientist\n",
      "   </b>\n",
      "   Internship\n",
      "  </a>\n",
      " </h2>\n",
      " <div class=\"sjcl\">\n",
      "  <div>\n",
      "   <span class=\"company\">\n",
      "    <a class=\"turnstileLink\" data-tn-element=\"companyName\" href=\"/cmp/Vee\" onmousedown=\"this.href = appendParamsOnce(this.href, 'from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=725fc70c4bf910ea&amp;jcid=4f11fda3f02f70cd')\" rel=\"noopener\" target=\"_blank\">\n",
      "     Vee\n",
      "    </a>\n",
      "   </span>\n",
      "   <span class=\"ratingsDisplay\">\n",
      "    <a aria-label=\"Company rating 3.9 out of 5 stars\" class=\"ratingNumber\" data-tn-variant=\"cmplinktst2\" href=\"/cmp/Vee/reviews\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=cmplinktst2&amp;from=SERP&amp;jt=NLP+Data+Scientist+Internship&amp;fromjk=725fc70c4bf910ea&amp;jcid=4f11fda3f02f70cd');\" rel=\"noopener\" target=\"_blank\" title=\"Vee reviews\">\n",
      "     <span class=\"ratingsContent\">\n",
      "      3.9\n",
      "      <svg class=\"starIcon\" height=\"12px\" role=\"img\" width=\"12px\">\n",
      "       <g>\n",
      "        <path d=\"M 12.00,4.34 C 12.00,4.34 7.69,3.97 7.69,3.97 7.69,3.97 6.00,0.00 6.00,0.00 6.00,0.00 4.31,3.98 4.31,3.98 4.31,3.98 0.00,4.34 0.00,4.34 0.00,4.34 3.28,7.18 3.28,7.18 3.28,7.18 2.29,11.40 2.29,11.40 2.29,11.40 6.00,9.16 6.00,9.16 6.00,9.16 9.71,11.40 9.71,11.40 9.71,11.40 8.73,7.18 8.73,7.18 8.73,7.18 12.00,4.34 12.00,4.34 Z\" style=\"fill: #FFB103\">\n",
      "        </path>\n",
      "       </g>\n",
      "      </svg>\n",
      "     </span>\n",
      "    </a>\n",
      "   </span>\n",
      "  </div>\n",
      "  <div class=\"recJobLoc\" data-rc-loc=\"New York State\" id=\"recJobLoc_725fc70c4bf910ea\" style=\"display: none\">\n",
      "  </div>\n",
      "  <span class=\"location accessible-contrast-color-location\">\n",
      "   New York State\n",
      "  </span>\n",
      "  <span class=\"remote-bullet\">\n",
      "   â€¢\n",
      "  </span>\n",
      "  <span class=\"remote\">\n",
      "   Remote\n",
      "  </span>\n",
      " </div>\n",
      " <div class=\"summary\">\n",
      "  <ul style=\"list-style-type:circle;margin-top: 0px;margin-bottom: 0px;padding-left:20px;\">\n",
      "   <li style=\"margin-bottom:0px;\">\n",
      "    You will help build Vee's\n",
      "    <b>\n",
      "     data\n",
      "    </b>\n",
      "    capability and\n",
      "    <b>\n",
      "     data\n",
      "    </b>\n",
      "    strategy.\n",
      "   </li>\n",
      "   <li>\n",
      "    Solid background in\n",
      "    <b>\n",
      "     data\n",
      "    </b>\n",
      "    mining and statistical analysis.\n",
      "   </li>\n",
      "  </ul>\n",
      " </div>\n",
      " <div class=\"jobsearch-SerpJobCard-footer\">\n",
      "  <div class=\"jobsearch-SerpJobCard-footerActions\">\n",
      "   <div class=\"result-link-bar-container\">\n",
      "    <div class=\"result-link-bar\">\n",
      "     <span class=\"date\">\n",
      "      30+ days ago\n",
      "     </span>\n",
      "     <div class=\"tt_set\" id=\"tt_set_0\">\n",
      "      <div class=\"job-reaction\">\n",
      "       <button aria-expanded=\"false\" aria-haspopup=\"true\" aria-label=\"save or dislike\" class=\"job-reaction-kebab\" data-ol-has-click-handler=\"\" onclick=\"toggleKebabMenu('725fc70c4bf910ea', false, event); return false;\" tabindex=\"0\">\n",
      "       </button>\n",
      "       <span class=\"job-reaction-kebab-menu\">\n",
      "        <button class=\"job-reaction-kebab-item job-reaction-save\" data-ol-has-click-handler=\"\" onclick=\"changeJobState('725fc70c4bf910ea', 'save', 'linkbar', false, '');return false;\">\n",
      "         <svg focusable=\"false\" height=\"16\" viewbox=\"0 0 24 24\" width=\"16\">\n",
      "          <g>\n",
      "           <path d=\"M16.5,3A6,6,0,0,0,12,5.09,6,6,0,0,0,7.5,3,5.45,5.45,0,0,0,2,8.5C2,12.28,5.4,15.36,10.55,20L12,21.35,13.45,20C18.6,15.36,22,12.28,22,8.5A5.45,5.45,0,0,0,16.5,3ZM12.1,18.55l-0.1.1-0.1-.1C7.14,14.24,4,11.39,4,8.5A3.42,3.42,0,0,1,7.5,5a3.91,3.91,0,0,1,3.57,2.36h1.87A3.88,3.88,0,0,1,16.5,5,3.42,3.42,0,0,1,20,8.5C20,11.39,16.86,14.24,12.1,18.55Z\" fill=\"#2d2d2d\">\n",
      "           </path>\n",
      "          </g>\n",
      "         </svg>\n",
      "         <span class=\"job-reaction-kebab-item-text\">\n",
      "          Save job\n",
      "         </span>\n",
      "        </button>\n",
      "        <button class=\"job-reaction-kebab-item job-reaction-dislike\" data-ol-has-click-handler=\"\" onclick=\"dislikeJob(false, false, '725fc70c4bf910ea', 'unsave', 'linkbar', false, '');\">\n",
      "         <span class=\"job-reaction-dislike-icon\">\n",
      "         </span>\n",
      "         <span class=\"job-reaction-kebab-item-text\">\n",
      "          Not interested\n",
      "         </span>\n",
      "        </button>\n",
      "        <button class=\"job-reaction-kebab-item job-reaction-report\" onclick=\"reportJob('725fc70c4bf910ea');\">\n",
      "         <span class=\"job-reaction-report-icon\">\n",
      "         </span>\n",
      "         <span class=\"job-reaction-kebab-item-text\">\n",
      "          Report Job\n",
      "         </span>\n",
      "        </button>\n",
      "       </span>\n",
      "      </div>\n",
      "      <span class=\"result-link-bar-separator\">\n",
      "       Â·\n",
      "      </span>\n",
      "      <a class=\"sl resultLink save-job-link\" href=\"#\" id=\"sj_725fc70c4bf910ea\" onclick=\"changeJobState('725fc70c4bf910ea', 'save', 'linkbar', false, ''); return false;\" title=\"Save this job to my.indeed\">\n",
      "       Save job\n",
      "      </a>\n",
      "      <span class=\"result-link-bar-separator\">\n",
      "       Â·\n",
      "      </span>\n",
      "      <button aria-expanded=\"false\" class=\"sl resultLink more-link\" id=\"tog_0\" onclick=\"toggleMoreLinks('725fc70c4bf910ea', '0'); return false;\">\n",
      "       More...\n",
      "      </button>\n",
      "     </div>\n",
      "     <script>\n",
      "      if (!window['result_725fc70c4bf910ea']) {window['result_725fc70c4bf910ea'] = {};}window['result_725fc70c4bf910ea']['showSource'] = false; window['result_725fc70c4bf910ea']['source'] = \"Vee\"; window['result_725fc70c4bf910ea']['loggedIn'] = false; window['result_725fc70c4bf910ea']['showMyJobsLinks'] = false;window['result_725fc70c4bf910ea']['baseMyJobsUrl'] = \"https://myjobs.indeed.com\";window['result_725fc70c4bf910ea']['undoAction'] = \"unsave\";window['result_725fc70c4bf910ea']['relativeJobAge'] = \"30+ days ago\";window['result_725fc70c4bf910ea']['jobKey'] = \"725fc70c4bf910ea\"; window['result_725fc70c4bf910ea']['myIndeedAvailable'] = true; window['result_725fc70c4bf910ea']['showMoreActionsLink'] = window['result_725fc70c4bf910ea']['showMoreActionsLink'] || true; window['result_725fc70c4bf910ea']['resultNumber'] = 0; window['result_725fc70c4bf910ea']['jobStateChangedToSaved'] = false; window['result_725fc70c4bf910ea']['searchState'] = \"q=data scientist $20,000&amp;l=New+York&amp;start=10\"; window['result_725fc70c4bf910ea']['basicPermaLink'] = \"https://www.indeed.com\"; window['result_725fc70c4bf910ea']['saveJobFailed'] = false; window['result_725fc70c4bf910ea']['removeJobFailed'] = false; window['result_725fc70c4bf910ea']['requestPending'] = false; window['result_725fc70c4bf910ea']['currentPage'] = \"serp\"; window['result_725fc70c4bf910ea']['sponsored'] = false;window['result_725fc70c4bf910ea']['reportJobButtonEnabled'] = false; window['result_725fc70c4bf910ea']['showMyJobsHired'] = false; window['result_725fc70c4bf910ea']['showSaveForSponsored'] = false; window['result_725fc70c4bf910ea']['showJobAge'] = true; window['result_725fc70c4bf910ea']['showHolisticCard'] = true; window['result_725fc70c4bf910ea']['showDislike'] = true; window['result_725fc70c4bf910ea']['showKebab'] = true; window['result_725fc70c4bf910ea']['showReport'] = true;\n",
      "     </script>\n",
      "    </div>\n",
      "   </div>\n",
      "  </div>\n",
      " </div>\n",
      " <div class=\"tab-container\">\n",
      "  <div class=\"more-links-container result-tab\" id=\"tt_display_0\" style=\"display:none;\">\n",
      "   <div class=\"more_actions\" id=\"more_0\">\n",
      "    <ul>\n",
      "     <li>\n",
      "      <span class=\"mat\">\n",
      "       View all\n",
      "       <a href=\"/q-Vee-l-New-York-State-jobs.html\">\n",
      "        Vee jobs in New York State\n",
      "       </a>\n",
      "       -\n",
      "       <a href=\"/l-New-York-State-jobs.html\">\n",
      "        New York State jobs\n",
      "       </a>\n",
      "      </span>\n",
      "     </li>\n",
      "     <li>\n",
      "      <span class=\"mat\">\n",
      "       Salary Search:\n",
      "       <a href=\"/salaries/data-scientist-Salaries,-New-York-State\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=serp-more&amp;fromjk=725fc70c4bf910ea&amp;from=serp-more');\">\n",
      "        Data Scientist salaries in New York State\n",
      "       </a>\n",
      "      </span>\n",
      "     </li>\n",
      "     <li>\n",
      "      <span class=\"mat\">\n",
      "       See popular\n",
      "       <a href=\"/cmp/Vee/faq\" onmousedown=\"this.href = appendParamsOnce(this.href, '?from=serp-more&amp;campaignid=serp-more&amp;fromjk=725fc70c4bf910ea&amp;jcid=4f11fda3f02f70cd');\">\n",
      "        questions &amp; answers about Vee\n",
      "       </a>\n",
      "      </span>\n",
      "     </li>\n",
      "     <li>\n",
      "      <span class=\"mat\">\n",
      "       Explore career as Data Scientist:\n",
      "       <a href=\"/career/data-scientist\" onmousedown=\"this.href = appendParamsOnce(this.href, 'from=jasx');\">\n",
      "        overview\n",
      "       </a>\n",
      "       ,\n",
      "       <a href=\"/career/data-scientist/career-advice\" onmousedown=\"this.href = appendParamsOnce(this.href, 'from=jasx');\">\n",
      "        career advice\n",
      "       </a>\n",
      "       ,\n",
      "       <a href=\"/career/data-scientist/faq\" onmousedown=\"this.href = appendParamsOnce(this.href, 'from=jasx');\">\n",
      "        FAQs\n",
      "       </a>\n",
      "      </span>\n",
      "     </li>\n",
      "    </ul>\n",
      "   </div>\n",
      "   <a class=\"close-link closeLink\" href=\"#\" onclick=\"toggleMoreLinks('725fc70c4bf910ea'); return false;\" title=\"Close\">\n",
      "   </a>\n",
      "  </div>\n",
      "  <div class=\"dya-container result-tab\">\n",
      "  </div>\n",
      "  <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "  </div>\n",
      "  <div class=\"sign-in-container result-tab\">\n",
      "  </div>\n",
      " </div>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results[0].prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "bb0b866a-26a7-45e9-8084-5a0f90eb4b3e"
   },
   "source": [
    "Let's look at one result more closely. A single `result` looks like\n",
    "\n",
    "```\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=2480d203f7e97210&amp;jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```\n",
    "\n",
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is in a `span` with `class='salaryText'`.\n",
    "- The title of a job is in a link with class set to `jobtitle` and a `data-tn-element='jobTitle'`.  \n",
    "- The location is set in a `span` with `class='location'`. \n",
    "- The company is set in a `span` with `class='company'`. \n",
    "- Decide which other components could be relevant, for example the region or the summary of the job advert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = {\n",
    "    'salary': [],\n",
    "    'job_title': [],\n",
    "    'location': [],\n",
    "    'company': [],\n",
    "    'company_rating': [],\n",
    "    'description': []\n",
    "}\n",
    "\n",
    "for job in results:\n",
    "    try:\n",
    "        jobs['salary'].append(job.find('span', class_='salaryText').text)\n",
    "    except:\n",
    "        jobs['salary'].append(np.nan)\n",
    "        \n",
    "    try:\n",
    "        # job.find('h2', class_='title').find('a')['title']\n",
    "        jobs['job_title'].append(job.find('a', attrs={'data-tn-element': 'jobTitle'})['title'])\n",
    "    except:\n",
    "        jobs['job_title'].append(np.nan)\n",
    "        \n",
    "    try:\n",
    "        jobs['location'].append(job.find('span', class_='location').text.strip())  \n",
    "    except:\n",
    "        jobs['location'].append(np.nan)\n",
    "        \n",
    "    try:\n",
    "        company_name = job.find('a', attrs={'data-tn-element':'companyName'})\n",
    "        if company_name:\n",
    "            jobs['company'].append(company_name.text.strip())\n",
    "        else:\n",
    "            jobs['company'].append(job.find('span', class_='company').text.strip())\n",
    "    except:\n",
    "        jobs['company'].append(np.nan)\n",
    "        \n",
    "    try:\n",
    "        jobs['company_rating'].append(job.find('span', class_='ratingsContent').text.strip())\n",
    "    except:\n",
    "        jobs['company_rating'].append(np.nan)\n",
    "        \n",
    "    try:\n",
    "        lists = job.find('div', class_='summary').find_all('li')   \n",
    "        jobs['description'].append((' ').join([lst.text for lst in lists]))\n",
    "    except:\n",
    "        jobs['description'].append(np.nan)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'company': ['Vee',\n",
      "             'Valiance Solutions',\n",
      "             'Sightly Enterprises',\n",
      "             'Unite Us',\n",
      "             'IBM',\n",
      "             'IBM',\n",
      "             'Northwestern Mutual',\n",
      "             'Naval Nuclear Laboratory',\n",
      "             'Warner Music Group',\n",
      "             'BNY Mellon',\n",
      "             'CKM Analytix',\n",
      "             'MassMutual',\n",
      "             'Altice',\n",
      "             'RISIRISA',\n",
      "             'QuaEra'],\n",
      " 'company_rating': ['3.9',\n",
      "                    nan,\n",
      "                    nan,\n",
      "                    '5.0',\n",
      "                    '3.9',\n",
      "                    '3.9',\n",
      "                    '3.8',\n",
      "                    '2.8',\n",
      "                    '4.1',\n",
      "                    '3.5',\n",
      "                    nan,\n",
      "                    '3.7',\n",
      "                    '3.4',\n",
      "                    nan,\n",
      "                    nan],\n",
      " 'description': [\"You will help build Vee's data capability and data strategy. \"\n",
      "                 'Solid background in data mining and statistical analysis.',\n",
      "                 'Amounts of data using SQL, R and Excel. Using data science, '\n",
      "                 'machine learning and cloud technologies. Ability to '\n",
      "                 'understand and interpret data within the contextâ€¦',\n",
      "                 'Gathering and analyzing unique ad placement and performance '\n",
      "                 'data. Understanding and communicating data requirements for '\n",
      "                 'the purpose of product development.',\n",
      "                 'Experience with healthcare data and analytics is preferred. '\n",
      "                 'Experience working with health data, or in a healthcare '\n",
      "                 'related field preferred.',\n",
      "                 'Identify data and ad tech solutions in response to any and '\n",
      "                 \"all platform requests. In this role, you will be the 'tip of \"\n",
      "                 \"the spear' supporting both the data andâ€¦\",\n",
      "                 'Data exploration, extraction and manipulation. This is part '\n",
      "                 'one of a two-year summer internship program, aimed at '\n",
      "                 'placing candidates into full-time consultantâ€¦',\n",
      "                 'Ability to tell a story with data. A data scientist on this '\n",
      "                 'team will work on both developing these models and '\n",
      "                 'capabilities in addition to developing andâ€¦',\n",
      "                 'Processing, refining, and verifying the integrity of data '\n",
      "                 'used for analysis. Experience with data visualization '\n",
      "                 'packages, such as Tableau, SAS, and Rstudio.',\n",
      "                 'Interact with data engineering teams to identify the data '\n",
      "                 'needs for mathematical models. The Research + Analysis '\n",
      "                 'department works to influence WMGâ€™s strategyâ€¦',\n",
      "                 'As a data scientist, you will be embedded with the '\n",
      "                 'engineering team as the primary subject matter expert '\n",
      "                 'realated to data analysis, natural language processingâ€¦',\n",
      "                 'Passion for quantitative problem solving and developing data '\n",
      "                 'driven solutions to difficult business questions.',\n",
      "                 '3+ years working with data and relevant computational '\n",
      "                 'frameworks and systemsÃ‚. Assemble data sets from disparate '\n",
      "                 'sources and analyze using appropriateâ€¦',\n",
      "                 'You will partner with other data scientists, data engineers, '\n",
      "                 'and application developers on the Data Science team. Strong '\n",
      "                 'ability to conduct literature reviews.',\n",
      "                 'Experience with a range of data science techniques including '\n",
      "                 'clustering, machine learning, natural language processing, '\n",
      "                 'and network analysis.',\n",
      "                 'Experience with R, Python, PySpark and data visualization '\n",
      "                 'software such as Tableau. Ability to efficiently construct '\n",
      "                 'data sets from large scale distributedâ€¦'],\n",
      " 'job_title': ['NLP Data Scientist Internship',\n",
      "               'Data Scientist Scientist',\n",
      "               'DATA SCIENTIST',\n",
      "               'Data Scientist',\n",
      "               'Partnership Account Executive - Data and AdTech Specialist',\n",
      "               'Data Analyst (Rising Junior) Intern 2021â€“ Chief Analytics '\n",
      "               'Office',\n",
      "               'Data Scientist',\n",
      "               'Data Scientist',\n",
      "               'Econometric Data Scientist, International',\n",
      "               'Data Scientist',\n",
      "               'Data Scientist',\n",
      "               'Data Scientist',\n",
      "               'Data Scientist',\n",
      "               'Data Scientist',\n",
      "               'Data Scientist'],\n",
      " 'location': ['New York State',\n",
      "              'New York, NY 10019 (Midtown area)',\n",
      "              'New York, NY',\n",
      "              'New York State',\n",
      "              'New York, NY 10002 (Lower East Side area)',\n",
      "              'Armonk, NY 10504',\n",
      "              'New York, NY',\n",
      "              'Niskayuna, NY 12309',\n",
      "              'New York, NY',\n",
      "              'New York, NY 10286 (Tribeca area)',\n",
      "              'New York, NY',\n",
      "              'New York, NY',\n",
      "              'Long Island City, NY',\n",
      "              'New York, NY',\n",
      "              'New York, NY 10018 (Garment District area)'],\n",
      " 'salary': [nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan]}\n"
     ]
    }
   ],
   "source": [
    "pprint(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NLP Data Scientist Internship</td>\n",
       "      <td>New York State</td>\n",
       "      <td>Vee</td>\n",
       "      <td>3.9</td>\n",
       "      <td>You will help build Vee's data capability and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist Scientist</td>\n",
       "      <td>New York, NY 10019 (Midtown area)</td>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amounts of data using SQL, R and Excel. Using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Sightly Enterprises</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gathering and analyzing unique ad placement an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York State</td>\n",
       "      <td>Unite Us</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Experience with healthcare data and analytics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Partnership Account Executive - Data and AdTec...</td>\n",
       "      <td>New York, NY 10002 (Lower East Side area)</td>\n",
       "      <td>IBM</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Identify data and ad tech solutions in respons...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   salary                                          job_title  \\\n",
       "0     NaN                      NLP Data Scientist Internship   \n",
       "1     NaN                           Data Scientist Scientist   \n",
       "2     NaN                                     DATA SCIENTIST   \n",
       "3     NaN                                     Data Scientist   \n",
       "4     NaN  Partnership Account Executive - Data and AdTec...   \n",
       "\n",
       "                                    location              company  \\\n",
       "0                             New York State                  Vee   \n",
       "1          New York, NY 10019 (Midtown area)   Valiance Solutions   \n",
       "2                               New York, NY  Sightly Enterprises   \n",
       "3                             New York State             Unite Us   \n",
       "4  New York, NY 10002 (Lower East Side area)                  IBM   \n",
       "\n",
       "  company_rating                                        description  \n",
       "0            3.9  You will help build Vee's data capability and ...  \n",
       "1            NaN  Amounts of data using SQL, R and Excel. Using ...  \n",
       "2            NaN  Gathering and analyzing unique ad placement an...  \n",
       "3            5.0  Experience with healthcare data and analytics ...  \n",
       "4            3.9  Identify data and ad tech solutions in respons...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(jobs).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "f1eddb90-4ba8-483c-a229-77e93aa53119"
   },
   "source": [
    "### Write 4 functions to extract each item: location, company, job, and salary.\n",
    "\n",
    "Example: \n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
    "\n",
    "- **Make sure these functions are robust and can handle cases where the data/field may not be available.**\n",
    "    - Remember to check if a field is empty or `None` for attempting to call methods on it.\n",
    "    - Remember to use `try/except` if you anticipate errors.\n",
    "- **Test** the functions on the results above and simple examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_null(content):\n",
    "    \"\"\"return content or raise exception if no content is given\"\"\"\n",
    "    if content not in ('', None):\n",
    "        return content\n",
    "    else:\n",
    "        raise Exception('No content found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "focus": false,
    "id": "a1af53c9-9090-494f-b82e-cadb60a54909"
   },
   "outputs": [],
   "source": [
    "def extract_location_from_result(result):\n",
    "    \"\"\"return location of the company\"\"\"\n",
    "    try:\n",
    "        data = result.find('span', class_='location').text.strip()\n",
    "        return not_null(data)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_from_result(result):\n",
    "    \"\"\"return company name\"\"\"\n",
    "    try:\n",
    "        company_name = result.find('a', attrs={'data-tn-element':'companyName'})\n",
    "        if company_name:\n",
    "            return not_null(company_name.text.strip())\n",
    "        else:\n",
    "            data = result.find('span', class_='company').text.strip()\n",
    "            return not_null(data)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_from_result(result):\n",
    "    \"\"\"return job title\"\"\"\n",
    "    try:\n",
    "        return not_null(result.find('a', attrs={'data-tn-element': 'jobTitle'})['title'])\n",
    "    except:\n",
    "        return np.nan\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_salary_from_result(result):\n",
    "    \"\"\"return salary\"\"\"\n",
    "    try:\n",
    "        return not_null(result.find('span', class_='salaryText').text.strip())\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rating_from_result(result): \n",
    "    \"\"\"return company rating\"\"\"\n",
    "    try:\n",
    "        return not_null(result.find('span', class_='ratingsContent').text.strip())\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_summary_from_result(result):\n",
    "    \"\"\"return job description\"\"\"\n",
    "    try:\n",
    "        lists = result.find('div', class_='summary').find_all('li')   \n",
    "        return not_null((' ').join([lst.text for lst in lists]))\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "results = soup.find_all('div', class_='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLP Data Scientist Internship</td>\n",
       "      <td>New York State</td>\n",
       "      <td>Vee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>You will help build Vee's data capability and ...</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist Scientist</td>\n",
       "      <td>New York, NY 10019 (Midtown area)</td>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amounts of data using SQL, R and Excel. Using ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Sightly Enterprises</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gathering and analyzing unique ad placement an...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York State</td>\n",
       "      <td>Unite Us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Experience with healthcare data and analytics ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Partnership Account Executive - Data and AdTec...</td>\n",
       "      <td>New York, NY 10002 (Lower East Side area)</td>\n",
       "      <td>IBM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Identify data and ad tech solutions in respons...</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst (Rising Junior) Intern 2021â€“ Chie...</td>\n",
       "      <td>Armonk, NY 10504</td>\n",
       "      <td>IBM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data exploration, extraction and manipulation....</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Northwestern Mutual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ability to tell a story with data. A data scie...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Niskayuna, NY 12309</td>\n",
       "      <td>Naval Nuclear Laboratory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Processing, refining, and verifying the integr...</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Econometric Data Scientist, International</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Warner Music Group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interact with data engineering teams to identi...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY 10286 (Tribeca area)</td>\n",
       "      <td>BNY Mellon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As a data scientist, you will be embedded with...</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                      NLP Data Scientist Internship   \n",
       "1                           Data Scientist Scientist   \n",
       "2                                     DATA SCIENTIST   \n",
       "3                                     Data Scientist   \n",
       "4  Partnership Account Executive - Data and AdTec...   \n",
       "5  Data Analyst (Rising Junior) Intern 2021â€“ Chie...   \n",
       "6                                     Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8          Econometric Data Scientist, International   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                    location                   company  \\\n",
       "0                             New York State                       Vee   \n",
       "1          New York, NY 10019 (Midtown area)        Valiance Solutions   \n",
       "2                               New York, NY       Sightly Enterprises   \n",
       "3                             New York State                  Unite Us   \n",
       "4  New York, NY 10002 (Lower East Side area)                       IBM   \n",
       "5                           Armonk, NY 10504                       IBM   \n",
       "6                               New York, NY       Northwestern Mutual   \n",
       "7                        Niskayuna, NY 12309  Naval Nuclear Laboratory   \n",
       "8                               New York, NY        Warner Music Group   \n",
       "9          New York, NY 10286 (Tribeca area)                BNY Mellon   \n",
       "\n",
       "   salary                                            summary rating  \n",
       "0     NaN  You will help build Vee's data capability and ...    3.9  \n",
       "1     NaN  Amounts of data using SQL, R and Excel. Using ...    NaN  \n",
       "2     NaN  Gathering and analyzing unique ad placement an...    NaN  \n",
       "3     NaN  Experience with healthcare data and analytics ...    5.0  \n",
       "4     NaN  Identify data and ad tech solutions in respons...    3.9  \n",
       "5     NaN  Data exploration, extraction and manipulation....    3.9  \n",
       "6     NaN  Ability to tell a story with data. A data scie...    3.8  \n",
       "7     NaN  Processing, refining, and verifying the integr...    2.8  \n",
       "8     NaN  Interact with data engineering teams to identi...    4.1  \n",
       "9     NaN  As a data scientist, you will be embedded with...    3.5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary = []\n",
    "job_title = [] \n",
    "location = []\n",
    "company = []\n",
    "summary = []\n",
    "rating = []\n",
    "\n",
    "for job in results:\n",
    "    salary.append(extract_salary_from_result(job))\n",
    "    job_title.append(extract_job_from_result(job))\n",
    "    location.append(extract_location_from_result(job))\n",
    "    company.append(extract_company_from_result(job))\n",
    "    rating.append(extract_rating_from_result(job))\n",
    "    summary.append(extract_summary_from_result(job))\n",
    "    \n",
    "\n",
    "job_market = pd.DataFrame({'job_title': job_title,\n",
    "                           'location': location,\n",
    "                           'company': company,\n",
    "                           'salary': salary,\n",
    "                           'summary': summary,\n",
    "                           'rating': rating})\n",
    "\n",
    "job_market.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34070e89-9521-4b45-90c8-57a6599aac68"
   },
   "source": [
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL above.\n",
    "\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "There are two query parameters here we can alter to collect more results, the `l=New+York` and the `start=10`. The first controls the location of the results (so we can try a different city). The second controls where in the results to start and gives 10 results (thus, we can keep incrementing by 10 to go further in the list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10%22\n",
    "\n",
    "titles = ['data scientist', \n",
    "          'data analyst',\n",
    "          'research scientist',\n",
    "          'business intelligence',\n",
    "          'database developer',\n",
    "          'data engineer',\n",
    "          'database administrator']\n",
    "\n",
    "cities = ['New York',\n",
    "          'Dallas',\n",
    "          'Boston',\n",
    "          'Houston',\n",
    "          'San Francisco',\n",
    "          'Seattle',\n",
    "          'Austin',\n",
    "          'Miami',\n",
    "          'New Orleans',\n",
    "          'Atlanta',\n",
    "          'Jacksonville',\n",
    "          'Chicago',\n",
    "          'Philadelphia',\n",
    "          'Las Vegas',\n",
    "          'Los Angeles',\n",
    "          'Phoenix']\n",
    "\n",
    "titles_encoded = ('%2C+').join([t.replace(' ', '+') for t in set(titles)])\n",
    "\n",
    "# Ascii Encoding Reference:\n",
    "# space -> %20\n",
    "# # -> %23\n",
    "# $ -> %24\n",
    "# % -> %25\n",
    "# & -> %26\n",
    "# , -> %2C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indeed website analyses the user behaviour and blocks further server requests after a while by enabling captchas. In the first attempt several endeavors were taken to create a workaround for these captchas like rotating user agents in the html requests, changing proxy addresses and applying random delays. Unfortunately, the ip addresses from a free proxy server list can be detected by the website to make them useless. Further attempts have shown that these captchas occur after a specific number html requests from the same ip address. For this reason, the scraping function is implemented in a way to split the requests by setting the job locations and titles manually. After each request the ip address was changed with vpn software. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.scrapehero.com/how-to-fake-and-rotate-user-agents-using-python-3/\n",
    "\n",
    "user_agent_list = [\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "]\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\", \n",
    "    \"Accept-Encoding\": \"gzip, deflate, sdch\", \n",
    "    \"Accept-Language\": \"en-GB,en-US;q=0.9,en;q=0.8\", \n",
    "    \"Dnt\": \"1\", # do not track (1... prefers not to be tracked)\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "#     \"Host\": \"indeed.com\",\n",
    "#     \"Cache-Control\": \"max-age=0\",\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code is used from https://www.scrapehero.com/how-to-rotate-proxies-and-ip-addresses-using-python-3/\n",
    "# xpath expressions:\n",
    "# / -> selects from the root node (if occurring after a node then referring to children node)\n",
    "# // -> selects nodes from the current node\n",
    "# . -> selects current node\n",
    "\n",
    "# from lxml.html import fromstring\n",
    "# def get_proxies():\n",
    "#     \"\"\"return ip address and port from a proxy server\"\"\"\n",
    "# #     url = 'https://free-proxy-list.net/'\n",
    "#     url = 'https://www.us-proxy.org/'\n",
    "#     response = requests.get(url)\n",
    "#     # fromstring() returns document_fromstring or fragment_fromstring\n",
    "#     parser = fromstring(response.text)\n",
    "#     proxies = set()\n",
    "#     for i in parser.xpath('//tbody/tr')[:20]:\n",
    "#         if i.xpath('.//td[7][contains(text(),\"yes\")]'):  # <td class='hx'>yes</td>\n",
    "#             #Grabbing IP and corresponding PORT\n",
    "#             # i.xpath('.//td[1]')[0].text\n",
    "#             proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
    "#             proxies.add(proxy)\n",
    "#     return proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_indeed(cities, titles_encoded, headers=None, user_agent_list=None, delay=False):\n",
    "    \"\"\"\n",
    "    This function scrapes the indeed platform and returns a data frame with relevant job features (title, location,\n",
    "    company, salary, rating and description). \n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    cities (list): a list of city names\n",
    "    titles_encoded (str): ascii encoded string with all job titles\n",
    "    headers (dict): optional html request header\n",
    "    user_agent_list (list): Optional container of user agents for 'User-Agent' attribute of the header html request.\n",
    "                            It can only be applied if headers parameter is added. \n",
    "    delay (boolean): if true, then time delays are executed during the single server requests to decrease the chance \n",
    "                     of getting blocked\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    df (pd.DataFrame): dataframe with following features: \n",
    "                                                           - job_title\n",
    "                                                           - location\n",
    "                                                           - company\n",
    "                                                           - salary\n",
    "                                                           - rating\n",
    "                                                           - summary\n",
    "    \"\"\"\n",
    "    salary = []\n",
    "    job_title = [] \n",
    "    location = []\n",
    "    company = []\n",
    "    rating = []\n",
    "    summary = []\n",
    "    url_template = \"http://www.indeed.com/jobs?q={job}+%2420%2C000&l={location}&start={page}\"\n",
    "    \n",
    "    if type(cities) != list:\n",
    "        raise Exception('cities parameter must be a list')\n",
    "        return\n",
    "\n",
    "#     from itertools import cycle\n",
    "#     proxies = get_proxies()\n",
    "#     proxy_pool = cycle(proxies)\n",
    "\n",
    "    for c in tqdm(set(cities)):\n",
    "        if user_agent_list and headers:\n",
    "            user_agent = random.choice(user_agent_list)\n",
    "            headers['User-Agent'] = user_agent\n",
    "#         proxy = next(proxy_pool)\n",
    "#         proxy_flag = False\n",
    "\n",
    "#         while not proxy_flag:\n",
    "#             try:\n",
    "#                 response = requests.get('http://www.indeed.com', proxies={'http': proxy, 'https': proxy})\n",
    "#                 print(f\"Request {c}\")\n",
    "#                 print(response.json())\n",
    "#                 proxy_flag = True\n",
    "#             except:\n",
    "#                 proxy = next(proxy_pool)\n",
    "#                 print(\"Skipping. Connnection error\")\n",
    "\n",
    "        for page in tqdm(range(10, 800, 10), position=0):\n",
    "            try:\n",
    "                r = requests.get(url_template.format(job=titles_encoded,\n",
    "                                                     location=c.replace(' ', '+'),\n",
    "                                                     page=page),\n",
    "                                 headers=headers)\n",
    "#                                  proxies={\"http\": proxy, \"https\": proxy})\n",
    "            except:\n",
    "                raise Exception('check headers')\n",
    "\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            results = soup.find_all('div', class_='result')\n",
    "\n",
    "            # when the last result is shown a message box appears which includes \n",
    "            # a paragraph with a class attribute called 'dupetext'\n",
    "            duplicate_msg = soup.find('p', class_='dupetext')\n",
    "\n",
    "            for job in results:\n",
    "                salary.append(extract_salary_from_result(job))\n",
    "                job_title.append(extract_job_from_result(job))\n",
    "                location.append(extract_location_from_result(job))\n",
    "                company.append(extract_company_from_result(job))\n",
    "                rating.append(extract_rating_from_result(job))\n",
    "                summary.append(extract_summary_from_result(job))\n",
    "\n",
    "            if not results or duplicate_msg:  # nothing found or end result is reached\n",
    "                if delay:\n",
    "                    time.sleep(15 + random.random() * 10)  # 15-25 sec, prevent to submit captchas\n",
    "                print(f'{c} with {page/10} pages.')\n",
    "                break\n",
    "            elif page % 80 == 0:\n",
    "                if delay:\n",
    "                    time.sleep(10 + random.random() * 5)  # 10-15 sec\n",
    "            else:\n",
    "#                 print(f'city: {c}, page: {page}')\n",
    "                if delay:\n",
    "                    time.sleep(1 + random.random() * 3)  # 1-4 sec\n",
    "                \n",
    "    df = pd.DataFrame({'job_title': job_title,\n",
    "                       'location': location,\n",
    "                       'company': company,\n",
    "                       'salary': salary,\n",
    "                       'rating': rating,\n",
    "                       'summary': summary})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file_exists(filename, cities, titles_encoded, headers=None, user_agent_list=None, delay=False):\n",
    "    \"\"\"\n",
    "    Applying the scrape_indeed function and additionally saving the data frame.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    filename (str): file name without extension (.csv)\n",
    "    cities (list): a list of city names\n",
    "    titles_encoded (str): ascii encoded string with all job titles\n",
    "    headers (dict): optional html request header\n",
    "    user_agent_list (list): Optional container of user agents for 'User-Agent' attribute of the header html request.\n",
    "                            It can only be applied if headers parameter is added. \n",
    "    delay (boolean): if true, then time delays are executed during the single server requests to decrease the chance \n",
    "                     of getting blocked\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    df (pd.DataFrame): dataframe with following features: \n",
    "                                                           - job_title\n",
    "                                                           - location\n",
    "                                                           - company\n",
    "                                                           - salary\n",
    "                                                           - rating\n",
    "                                                           - summary\n",
    "    \"\"\"\n",
    "    file = Path(f\"./datasets/{filename}.csv\")\n",
    "    if not file.exists():\n",
    "        df = scrape_indeed(cities=cities, titles_encoded=titles_encoded, \n",
    "                           headers=headers, user_agent_list=user_agent_list, \n",
    "                           delay=delay)\n",
    "        df.to_csv(f'./datasets/{filename}.csv', index=False)\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        print('file already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>rating</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Syracuse, NY</td>\n",
       "      <td>Excelacom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Bachelorâ€™s Degree or higher. Responds to data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst/Assistant Research Scientist (par...</td>\n",
       "      <td>New York, NY 10012 (Greenwich Village area)</td>\n",
       "      <td>New York University</td>\n",
       "      <td>$18 an hour</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Cultivate deep familiarity with methodological...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Intelligence Analyst</td>\n",
       "      <td>New York, NY 10176 (Murray Hill area)</td>\n",
       "      <td>CBS Interactive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>As a business intelligence analyst, youâ€™ll lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Melville, NY 11747</td>\n",
       "      <td>North American Partners in Anesthesia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1+ year of hands-on experience with MS SQL as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Northwestern Mutual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.8</td>\n",
       "      <td>This team focuses on developing data science m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                                       Data Analyst   \n",
       "1  Data Analyst/Assistant Research Scientist (par...   \n",
       "2                      Business Intelligence Analyst   \n",
       "3                              Business Data Analyst   \n",
       "4                                     Data Scientist   \n",
       "\n",
       "                                      location  \\\n",
       "0                                 Syracuse, NY   \n",
       "1  New York, NY 10012 (Greenwich Village area)   \n",
       "2        New York, NY 10176 (Murray Hill area)   \n",
       "3                           Melville, NY 11747   \n",
       "4                                 New York, NY   \n",
       "\n",
       "                                 company       salary  rating  \\\n",
       "0                              Excelacom          NaN     3.2   \n",
       "1                    New York University  $18 an hour     4.2   \n",
       "2                        CBS Interactive          NaN     3.5   \n",
       "3  North American Partners in Anesthesia          NaN     2.9   \n",
       "4                    Northwestern Mutual          NaN     3.8   \n",
       "\n",
       "                                             summary  \n",
       "0  Bachelorâ€™s Degree or higher. Responds to data ...  \n",
       "1  Cultivate deep familiarity with methodological...  \n",
       "2  As a business intelligence analyst, youâ€™ll lea...  \n",
       "3  1+ year of hands-on experience with MS SQL as ...  \n",
       "4  This team focuses on developing data science m...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_file_exists('df_0', cities=[cities[0]], titles_encoded=titles_encoded, headers=headers, user_agent_list=user_agent_list)\n",
    "df_0 = pd.read_csv('./datasets/df_0.csv')\n",
    "df_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0[df_0['salary'].notnull()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "e8beed7c-3e42-40c0-810f-5f67f8f885a0"
   },
   "source": [
    "### Complete the following code to collect results from multiple cities and starting points. \n",
    "- Enter your city below to add it to the search.\n",
    "- Remember to convert your salary to U.S. Dollars to match the other cities if the currency is different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "20339c09-5032-4e27-91be-286e9b46cd13"
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_1', cities=[cities[1]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_1 = pd.read_csv('./datasets/df_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_2', cities=[cities[2]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_2 = pd.read_csv('./datasets/df_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_3', cities=[cities[3]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_3 = pd.read_csv('./datasets/df_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_4', cities=[cities[4]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_4 = pd.read_csv('./datasets/df_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_5', cities=[cities[5]], titles_encoded=titles_encoded)\n",
    "df_5 = pd.read_csv('./datasets/df_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_6', cities=[cities[6]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_6 = pd.read_csv('./datasets/df_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_7', cities=[cities[7]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_7 = pd.read_csv('./datasets/df_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_8', cities=[cities[8]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_8 = pd.read_csv('./datasets/df_8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_9', cities=[cities[9]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_9 = pd.read_csv('./datasets/df_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_10', cities=[cities[10]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_10 = pd.read_csv('./datasets/df_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_11', cities=[cities[11]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_11 = pd.read_csv('./datasets/df_11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_12', cities=[cities[12]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_12 = pd.read_csv('./datasets/df_12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_13', cities=[cities[13]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_13 = pd.read_csv('./datasets/df_13.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_14', cities=[cities[14]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_14 = pd.read_csv('./datasets/df_14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_15', cities=[cities[15]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_15 = pd.read_csv('./datasets/df_15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "MY_CITY = 'London'  # no exchange conversion needed, autimatically set to dollar\n",
    "check_file_exists('df_16', cities=[MY_CITY], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_16 = pd.read_csv('./datasets/df_16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14992, 7)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding the individual data frames to one large data frame \n",
    "\n",
    "if MY_CITY not in cities:\n",
    "    cities.append(MY_CITY)\n",
    "for i in range(len(cities)):\n",
    "    # add city names\n",
    "    globals()[f'df_{i}']['city'] = np.repeat(cities[i], globals()[f'df_{i}'].shape[0])\n",
    "    \n",
    "df_indeed = pd.concat([df_0, df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8,\n",
    "                       df_9, df_10, df_11, df_12, df_13, df_14, df_15, df_16], axis=0)\n",
    "df_indeed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>rating</th>\n",
       "      <th>summary</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Fleet Tire Sales Specialist</td>\n",
       "      <td>North Las Vegas, NV 89081 (North Last Vegas area)</td>\n",
       "      <td>Goodyear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Previous business to business sales experience...</td>\n",
       "      <td>Las Vegas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>IT Business Analyst/Trainer</td>\n",
       "      <td>Philadelphia, PA 19107 (City Center East area)</td>\n",
       "      <td>Philadelphia District Attorney's Office</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.1</td>\n",
       "      <td>The preferred candidate will also have or demo...</td>\n",
       "      <td>Philadelphia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Training Coordinator</td>\n",
       "      <td>Seattle, WA 98104 (Downtown area)</td>\n",
       "      <td>US Department of Agriculture</td>\n",
       "      <td>$72,750 - $94,581 a year</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Ph.D. or equivalent doctoral degree or 3 full ...</td>\n",
       "      <td>Seattle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>Test Technician</td>\n",
       "      <td>Redmond, WA</td>\n",
       "      <td>Sigma Design</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Document the appropriate data from test result...</td>\n",
       "      <td>Seattle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Manager Risk and Compliance (Client Security A...</td>\n",
       "      <td>Las Vegas, NV 89169 (Paradise area)</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Bachelorâ€™s degree in Computer Science, Busines...</td>\n",
       "      <td>Las Vegas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_title  \\\n",
       "264                        Fleet Tire Sales Specialist   \n",
       "164                        IT Business Analyst/Trainer   \n",
       "340                               Training Coordinator   \n",
       "909                                    Test Technician   \n",
       "370  Manager Risk and Compliance (Client Security A...   \n",
       "\n",
       "                                              location  \\\n",
       "264  North Las Vegas, NV 89081 (North Last Vegas area)   \n",
       "164     Philadelphia, PA 19107 (City Center East area)   \n",
       "340                  Seattle, WA 98104 (Downtown area)   \n",
       "909                                        Redmond, WA   \n",
       "370                Las Vegas, NV 89169 (Paradise area)   \n",
       "\n",
       "                                     company                    salary  \\\n",
       "264                                 Goodyear                       NaN   \n",
       "164  Philadelphia District Attorney's Office                       NaN   \n",
       "340             US Department of Agriculture  $72,750 - $94,581 a year   \n",
       "909                             Sigma Design                       NaN   \n",
       "370                                 Deloitte                       NaN   \n",
       "\n",
       "     rating                                            summary          city  \n",
       "264     3.7  Previous business to business sales experience...     Las Vegas  \n",
       "164     4.1  The preferred candidate will also have or demo...  Philadelphia  \n",
       "340     4.1  Ph.D. or equivalent doctoral degree or 3 full ...       Seattle  \n",
       "909     3.7  Document the appropriate data from test result...       Seattle  \n",
       "370     4.0  Bachelorâ€™s degree in Computer Science, Busines...     Las Vegas  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indeed.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2061"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indeed[df_indeed['salary'].notnull()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def not_null1(content):\n",
    "#     if content not in ('', None):\n",
    "#         return content\n",
    "#     else:\n",
    "#         raise Exception('No content found!')\n",
    "        \n",
    "# def extract_location_from_result1(result):\n",
    "#     try:\n",
    "#         data = result.find_element_by_css_selector('span.location').text.strip()\n",
    "#         return not_null1(data)\n",
    "#     except:\n",
    "#         return np.nan\n",
    "    \n",
    "    \n",
    "# def extract_job_from_result1(result):\n",
    "#     try:\n",
    "#         return not_null1(result.find_element_by_css_selector('a[data-tn-element=jobTitle]').get_attribute('title'))                                                        \n",
    "#     except:\n",
    "#         return np.nan\n",
    "    \n",
    "# def extract_company_from_result1(result):\n",
    "#     try:\n",
    "#         company_name = result.find_element_by_css_selector('a[data-tn-element=companyName]') \n",
    "#         if company_name:\n",
    "#             return company_name.text.strip()\n",
    "#         else:\n",
    "#             data = result.find_element_by_css_selector('span.company').text.strip()\n",
    "#             return not_null1(data)\n",
    "#     except:\n",
    "#         return np.nan\n",
    "    \n",
    "# def extract_salary_from_result1(result):\n",
    "#     try:\n",
    "#         return not_null1(result.find_element_by_css_selector('span.salaryText').text.strip())\n",
    "#     except:\n",
    "#         return np.nan\n",
    "\n",
    "# driver = webdriver.Chrome(executable_path='/Users/gabriel/Desktop/DataScience/chromedriver')\n",
    "\n",
    "\n",
    "# def extract_summary1(result):\n",
    "#     sleep(2)\n",
    "\n",
    "#     try:\n",
    "#         summary_html = result.find_element_by_css_selector('div#vjs-desc').get_attribute('innerHTML')\n",
    "#         return not_null1(summary_html)\n",
    "#     except:\n",
    "#         return np.nan\n",
    "\n",
    "\n",
    "# url_template = \"http://www.indeed.com/jobs?q={job}+%2420%2C000&l={location}&start={page}\"\n",
    "# max_results_per_city = 10 #5000 \n",
    "\n",
    "# titles = ['data scientist', \n",
    "#           'data analyst',\n",
    "#           'research scientist',\n",
    "#           'business intelligence',\n",
    "#           'database developer',\n",
    "#           'data engineer',\n",
    "#           'database administrator']\n",
    "\n",
    "# titles_encoded = ('%2C+').join([t.replace(' ', '+') for t in titles])\n",
    "# titles_conded = 'data+scientist'\n",
    "                        \n",
    "# salary1 = []\n",
    "# job_title1 = [] \n",
    "# location1 = []\n",
    "# company1 = []\n",
    "# summary1 = []\n",
    "\n",
    "# for city in tqdm(set(['New+York'])): #, 'Chicago', 'San+Francisco', 'Austin', 'Seattle', \n",
    "# #     'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', \n",
    "# #     'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', YOUR_CITY])):\n",
    "#     counter = 0\n",
    "#     for start in range(0, max_results_per_city, 10):\n",
    "#         r = driver.get(url_template.format(job=titles_encoded,\n",
    "#                                              location=city,\n",
    "#                                              page=start))\n",
    "        \n",
    "#         results = driver.find_elements_by_css_selector('div.result')\n",
    "#         try:\n",
    "#             duplicate_test = driver.find_element_by_css_selector('p.dupetext')\n",
    "#         except:\n",
    "#             duplicate_test = None\n",
    "#         try:\n",
    "#             duplicate_test2 = driver.find_element_by_css_selector('div.related_searches') \n",
    "#         except:\n",
    "#             duplacte_test2 = None\n",
    "        \n",
    "#         print(f'City: {city}, Page: {start}, counter: {counter}, duplicate_test: {bool(duplicate_test) or bool(duplicate_test2)}')\n",
    "\n",
    "        \n",
    "#         if duplicate_test or duplicate_test2:\n",
    "#             counter += 1    \n",
    "#             if counter > 1:\n",
    "#                 break\n",
    "    \n",
    "\n",
    "#         for job in results:\n",
    "#             salary1.append(extract_salary_from_result1(job))\n",
    "#             job_title1.append(extract_job_from_result1(job))\n",
    "#             location1.append(extract_location_from_result1(job))\n",
    "#             company1.append(extract_company_from_result1(job))\n",
    "#             job.click()\n",
    "#             summary1.append(extract_summary1(driver))\n",
    "                        \n",
    "# test1 = pd.DataFrame({'tilte': job_title1, 'location': location1, 'salary': salary1, 'company': company1,\n",
    "#                      'summary': summary1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly, these will not be useful to us for now.\n",
    "1. Some of the entries may be duplicated.\n",
    "1. The salaries are given as text and usually with ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly (filter those that refer to hour or week). Also, remove duplicate entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, possibly duplicated entries are removed as well each entry with missing salary data. In the next step, the dataset is split into different data frames according to the type of payment period (hourly, monthly, yearly). Howerver, only the yearly salary payment is needed in the further process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = df_indeed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1538, 7)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.drop_duplicates(inplace=True)\n",
    "jobs[jobs['salary'].notnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.dropna(subset=['salary'], inplace=True)\n",
    "# jobs = jobs[jobs['salary'].str.contains(r'year')]\n",
    "# jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[jobs['salary'].str.contains('hour')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "975"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[jobs['salary'].str.contains('year')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[jobs['salary'].str.contains('month')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$40 per class    1\n",
       "$219 a day       1\n",
       "Name: salary, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[~jobs['salary'].str.contains('hour|year|month')]['salary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_hourly = jobs[jobs['salary'].str.contains('hour')].copy()\n",
    "jobs_monthly = jobs[jobs['salary'].str.contains('month')].copy()\n",
    "jobs_yearly = jobs[jobs['salary'].str.contains('year')].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "7d4bc860-b214-4f75-9cd0-b234830b1ec2"
   },
   "source": [
    "#### Write a function that takes a salary string and converts it to a number, averaging a salary range if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$60,000 - $70,000 a year' '$123,438 a year' '$50,000 - $60,000 a year'\n",
      " '$55,000 - $60,000 a year' '$63,809 - $80,882 a year']\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "print(jobs_yearly['salary'].sample(5).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$4,301 - $7,500 a month' '$4,096 - $5,766 a month'\n",
      " '$6,999 - $7,900 a month' '$4,500 - $4,900 a month' '$4,095 a month']\n"
     ]
    }
   ],
   "source": [
    "print(jobs_monthly['salary'].sample(5).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From $60 an hour' '$41 - $50 an hour' '$50 - $55 an hour'\n",
      " 'From $13 an hour' '$14 - $29 an hour']\n"
     ]
    }
   ],
   "source": [
    "print(jobs_hourly['salary'].sample(5).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "focus": false,
    "id": "a0f701e0-80bd-40ba-9101-4535860c0968"
   },
   "outputs": [],
   "source": [
    "def convert_salary(salary, period='y', currency_rate=1):\n",
    "    \"\"\"\n",
    "    Searches for salary details in a text and returns it as a number. A salary range is given back\n",
    "    as its mean. \n",
    "    \n",
    "    Following regex patterns are applied to the specific payment periods:\n",
    "    \n",
    "    'y': r'\\d+[, ]\\d{3,}'\n",
    "    'm': r'\\d*[, ]?\\d{3,}'\n",
    "    'h': r'(?<![\\.|,])\\d{2,3}|\\d[, ]?\\d{3}'\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    salary (str): text including the salary (range)\n",
    "    period (str): letter to indicate the type of payment period (y|m|h)\n",
    "    currency_rate (float|int): optional, the converted salary parameter to a number is multiplied by this parameter\n",
    "                               to exchange the currency\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    sal (np.nan|float): returns the salary as a number if a correct salary pattern is found else\n",
    "                        it returns NaN\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if period == 'y':\n",
    "            # [, ] -> space for some other currencies than dollar\n",
    "            sal = np.mean([float(re.sub(r'[, ]', '', s)) for s in re.findall(r'\\d+[, ]\\d{3,}', salary)])\n",
    "        elif period == 'm':\n",
    "            # could be less than $1000 therefore using r'\\d*[, ]?'\n",
    "            sal = np.mean([float(re.sub(r'[, ]', '', s)) for s in re.findall(r'\\d*[, ]?\\d{3,}', salary)])  \n",
    "        elif period == 'h':\n",
    "            # get rid of decimal points -> (?<![\\.|,])\\d{2,3} only give number back if there is no previous decimal point or coma \n",
    "            sal = np.mean([float(re.sub(r'[, ]', '', s)) for s in re.findall(r'(?<![\\.|,])\\d{2,3}|\\d[, ]?\\d{3}', salary)]) \n",
    "        else:\n",
    "            raise Exception(\"define period: ['y', 'm', 'h']\")\n",
    "        sal *= currency_rate\n",
    "        \n",
    "    except:\n",
    "        sal = np.nan\n",
    "    \n",
    "    return sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_hourly['salary'] = jobs_hourly['salary'].apply(lambda x: convert_salary(x, 'h'))\n",
    "jobs_monthly['salary'] = jobs_monthly['salary'].apply(lambda x: convert_salary(x, 'm'))\n",
    "jobs_yearly['salary'] = jobs_yearly['salary'].apply(lambda x: convert_salary(x, 'y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000.0    32\n",
       "50000.0    27\n",
       "70000.0    24\n",
       "55000.0    22\n",
       "65000.0    22\n",
       "Name: salary, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_yearly['salary'].value_counts().iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only saves the datasets if the file is executed as a script\n",
    "if __name__ != \"__main__\":\n",
    "    jobs_hourly.to_csv('./datasets/jobs_hourly.csv', index=False)\n",
    "    jobs_monthly.to_csv('./datasets/jobs_monthly.csv', index=False)\n",
    "    jobs_yearly.to_csv('./datasets/jobs_yearly.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "### Load in the the data of scraped salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>rating</th>\n",
       "      <th>summary</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intelligence Operations Specialist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>US Department of Homeland Security</td>\n",
       "      <td>144688.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Presents formal briefings or written reports o...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investigative Analyst</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York District Attorney's Office</td>\n",
       "      <td>48909.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>One year experience preferred, either as a par...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>Cyber Tech Group</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Providing legal and scholarly research; Keen e...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Research Scientist 1 (Biostatistics or Health ...</td>\n",
       "      <td>Albany, NY 12237</td>\n",
       "      <td>Health, Department of</td>\n",
       "      <td>72364.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Research Scientist will work under the dir...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>NYC HOUSING AUTHORITY</td>\n",
       "      <td>70437.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Fields of finance; economic, fiscal or statist...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title          location  \\\n",
       "0                 Intelligence Operations Specialist      New York, NY   \n",
       "1                              Investigative Analyst      New York, NY   \n",
       "2                                   Business Analyst      Brooklyn, NY   \n",
       "3  Research Scientist 1 (Biostatistics or Health ...  Albany, NY 12237   \n",
       "4                                   Business Analyst     Manhattan, NY   \n",
       "\n",
       "                               company    salary  rating  \\\n",
       "0   US Department of Homeland Security  144688.0     3.8   \n",
       "1  New York District Attorney's Office   48909.0     4.4   \n",
       "2                     Cyber Tech Group   65000.0     NaN   \n",
       "3                Health, Department of   72364.0     NaN   \n",
       "4                NYC HOUSING AUTHORITY   70437.5     3.8   \n",
       "\n",
       "                                             summary      city  \n",
       "0  Presents formal briefings or written reports o...  New York  \n",
       "1  One year experience preferred, either as a par...  New York  \n",
       "2  Providing legal and scholarly research; Keen e...  New York  \n",
       "3  The Research Scientist will work under the dir...  New York  \n",
       "4  Fields of finance; economic, fiscal or statist...  New York  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/jobs_yearly.csv')\n",
    "jobs = df.copy()\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(975, 7)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median).\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the salary value here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW salary.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extreme salaries. We don't have to choose the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 975 entries, 0 to 974\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   job_title  975 non-null    object \n",
      " 1   location   851 non-null    object \n",
      " 2   company    975 non-null    object \n",
      " 3   salary     975 non-null    float64\n",
      " 4   rating     574 non-null    float64\n",
      " 5   summary    971 non-null    object \n",
      " 6   city       975 non-null    object \n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 53.4+ KB\n"
     ]
    }
   ],
   "source": [
    "jobs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>975.000000</td>\n",
       "      <td>574.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>84166.722051</td>\n",
       "      <td>3.752787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>34348.361173</td>\n",
       "      <td>0.556025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78081.500000</td>\n",
       "      <td>3.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>101061.500000</td>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>400000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              salary      rating\n",
       "count     975.000000  574.000000\n",
       "mean    84166.722051    3.752787\n",
       "std     34348.361173    0.556025\n",
       "min     29500.000000    1.000000\n",
       "25%     60000.000000    3.500000\n",
       "50%     78081.500000    3.800000\n",
       "75%    101061.500000    4.200000\n",
       "max    400000.000000    5.000000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between salary and rating is almost inexistent and a great amount of rating data is missing therefore the complete rating feature is dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0489"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[['rating', 'salary']].corr().iloc[0,1].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating    401\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[['rating']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs['rating'].fillna(value=jobs['rating'].median(), inplace=True)\n",
    "if 'rating' in jobs.columns:  # to avoid error if invoking twice\n",
    "    jobs.drop(['rating'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title      0\n",
       "location     124\n",
       "company        0\n",
       "salary         0\n",
       "summary        4\n",
       "city           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scraped location data includes information about the city and the state among under things which are split into individual features in the process of further feature engineering to create more meaningful features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Checkmate Partners</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>Working cross-functionally with data scientist...</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Houston</td>\n",
       "      <td>JES Tech</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Bachelorâ€™s degree or certification in Data Sci...</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Measurement Data Analyst</td>\n",
       "      <td>Houston</td>\n",
       "      <td>SPL, Inc.</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Associates degree (A.A.) or equivalent from a ...</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    job_title location             company    salary  \\\n",
       "102             Data Engineer  Houston  Checkmate Partners  205000.0   \n",
       "116            Data Scientist  Houston            JES Tech   55000.0   \n",
       "117  Measurement Data Analyst  Houston           SPL, Inc.   80000.0   \n",
       "\n",
       "                                               summary     city  \n",
       "102  Working cross-functionally with data scientist...  Houston  \n",
       "116  Bachelorâ€™s degree or certification in Data Sci...  Houston  \n",
       "117  Associates degree (A.A.) or equivalent from a ...  Houston  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['summary'].fillna(value='Nothing', inplace=True)\n",
    "# if location is empty then using the city name from the search result\n",
    "empty_location_idx = jobs[jobs['location'].isnull()].index\n",
    "jobs.loc[empty_location_idx, 'location'] = jobs.loc[empty_location_idx].apply(lambda col: col['city'], axis=1)\n",
    "jobs.loc[empty_location_idx].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26     New York State\n",
       "102           Houston\n",
       "116           Houston\n",
       "117           Houston\n",
       "118           Houston\n",
       "Name: location, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[~jobs['location'].str.contains(',')]['location'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        New York, NY\n",
       "1        New York, NY\n",
       "2        Brooklyn, NY\n",
       "3    Albany, NY 12237\n",
       "4       Manhattan, NY\n",
       "Name: location, dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[jobs['location'].str.contains(',')]['location'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_location(data, c=True):\n",
    "    \"\"\"\n",
    "    This function returns either the city or the state name depending on the parameter c\n",
    "    (if c is True then city else state), but only if the string contains a comma. Otherwise\n",
    "    it returns the raw text. \n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    data [String]: location data\n",
    "    c [Boolean]: True for city name, False for state name\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    city [String]: city name\n",
    "    or\n",
    "    state [String]: state name\n",
    "    or\n",
    "    data [String]: raw data\n",
    "    \"\"\"\n",
    "    if ',' in data:\n",
    "        first_data, *second_data = data.split(',')  # in the case of several commas\n",
    "        splitted_names = re.findall(r'[A-Z][a-z]+', first_data)\n",
    "        city = (' ').join(splitted_names) if splitted_names else np.nan\n",
    "        state_match = re.search(r'[A-Z]{2}', second_data[0])\n",
    "        state =  state_match.group() if state_match else np.nan\n",
    "    else:\n",
    "        return data\n",
    "    if c:\n",
    "        return city\n",
    "    else:\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intelligence Operations Specialist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>US Department of Homeland Security</td>\n",
       "      <td>144688.0</td>\n",
       "      <td>Presents formal briefings or written reports o...</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investigative Analyst</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York District Attorney's Office</td>\n",
       "      <td>48909.0</td>\n",
       "      <td>One year experience preferred, either as a par...</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>Cyber Tech Group</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Providing legal and scholarly research; Keen e...</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            job_title      location  \\\n",
       "0  Intelligence Operations Specialist  New York, NY   \n",
       "1               Investigative Analyst  New York, NY   \n",
       "2                    Business Analyst  Brooklyn, NY   \n",
       "\n",
       "                               company    salary  \\\n",
       "0   US Department of Homeland Security  144688.0   \n",
       "1  New York District Attorney's Office   48909.0   \n",
       "2                     Cyber Tech Group   65000.0   \n",
       "\n",
       "                                             summary      city state  \n",
       "0  Presents formal briefings or written reports o...  New York    NY  \n",
       "1  One year experience preferred, either as a par...  New York    NY  \n",
       "2  Providing legal and scholarly research; Keen e...  Brooklyn    NY  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['city'] = jobs['location'].apply(lambda x: split_location(x))\n",
    "jobs['state'] = jobs['location'].apply(lambda x: split_location(x, False))\n",
    "jobs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty_states_indices = jobs[jobs['state'].isnull()].index.tolist()\n",
    "# empty_states_indices\n",
    "# jobs.loc[empty_states_indices, :]\n",
    "jobs['state'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TX                168\n",
       "FL                107\n",
       "AZ                 93\n",
       "CA                 82\n",
       "GA                 76\n",
       "IL                 68\n",
       "NV                 62\n",
       "WA                 52\n",
       "NY                 34\n",
       "MA                 34\n",
       "LA                 24\n",
       "OH                 22\n",
       "Austin             21\n",
       "PA                 20\n",
       "Phoenix            20\n",
       "Los Angeles        19\n",
       "San Francisco      15\n",
       "Miami              14\n",
       "Atlanta            13\n",
       "Houston            11\n",
       "Chicago            11\n",
       "NJ                  5\n",
       "DE                  2\n",
       "New York State      1\n",
       "IN                  1\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if scraped data doesn't include the location information then the city name of the search result was applied\n",
    "# both for city and state feature\n",
    "jobs['state'].replace({'Los Angeles': 'CA', \n",
    "                       'San Francisco': 'CA',\n",
    "                       'Austin': 'TX',\n",
    "                       'Houston': 'TX',\n",
    "                       'Chicago': 'IL',\n",
    "                       'Phoenix': 'AZ',\n",
    "                       'Miami': 'FL',\n",
    "                       'Atlanta': 'GA',\n",
    "                       'New York State': 'NY'}, inplace=True)\n",
    "jobs.drop(['location'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>summary</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>975</td>\n",
       "      <td>975</td>\n",
       "      <td>975</td>\n",
       "      <td>975</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>825</td>\n",
       "      <td>677</td>\n",
       "      <td>905</td>\n",
       "      <td>150</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>Experience in an ML engineer or data scientist...</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   job_title company  \\\n",
       "count                    975     975   \n",
       "unique                   825     677   \n",
       "top     Senior Data Engineer  Indeed   \n",
       "freq                      14      29   \n",
       "\n",
       "                                                  summary    city state  \n",
       "count                                                 975     975   975  \n",
       "unique                                                905     150    16  \n",
       "top     Experience in an ML engineer or data scientist...  Austin    TX  \n",
       "freq                                                    8      96   200  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "707                Supervisory Financial Systems Analyst\n",
       "530           Big Data Engineer, Digital Innovation Team\n",
       "131                              Financial Analyst, FP&A\n",
       "460                                   Programmer Analyst\n",
       "552    Analyst/Senior Analyst, Digital Success Experi...\n",
       "107                           IT Data Programmer Analyst\n",
       "629                              Senior Business Analyst\n",
       "289                 Database Administrator and Developer\n",
       "528                    Economist - local candidates only\n",
       "6                                           Data Analyst\n",
       "Name: job_title, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['job_title'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78081.5"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_salary = jobs['salary'].median()\n",
    "median_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "\n",
    "# salary distribution can be quite skewed therefore taking whisker factor 3\n",
    "sns.boxplot(x=jobs['salary'], orient='h', fliersize=8, \n",
    "            linewidth=1.5, saturation=0.5, whis=3.0, ax=ax)\n",
    "ax.set_title('Salary\\n', fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969, 6)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# salaries are usually spread quite skwed if high position jobs are offered as well\n",
    "# therefore the factor 3 is used for the interquartil range to detect outliers\n",
    "q1, q3 = np.quantile(jobs['salary'], [0.25, 0.75])\n",
    "iqr = q3 - q1\n",
    "outlier_upper_limit = q3 + 3*iqr\n",
    "salary_outlier_idx = jobs.loc[jobs['salary'] > outlier_upper_limit].index\n",
    "jobs.drop(index=salary_outlier_idx, inplace=True)\n",
    "jobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer = Binarizer(threshold=median_salary)\n",
    "jobs['high_salary'] = binarizer.transform(jobs[['salary']]).astype(int)\n",
    "# jobs.loc[:, 'salary'] = jobs['salary'].map(lambda x: 'High' if x > median_salary else 'Low')\n",
    "jobs.drop(['salary'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chart below shows on the one hand the mean value of high or low salary per state indicated by the bars and on the other hand the number of jobs per state by the red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAooAAAFzCAYAAAC5ASjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5zddZX/8deZPpOeTHqdJBOq0kPvMlJEFBFhf7qoKOKCq7uoWHFdZXfBdXUtiFhWdtcVkSKgSBeRTkIJCZBMyqROep3ePr8/7r3h3vv93My9M7ff9/PxuI+ZOff7vfesS2bO/ZTzMeccIiIiIiLxynKdgIiIiIjkJxWKIiIiIuKlQlFEREREvFQoioiIiIiXCkURERER8VKhKCIiIiJeFblOYCjKyspcbW1trtMQERERGVRHR4dzzhXk4FxBFoq1tbW0t7fnOg0RERGRQZlZZ65zGKqCrG5FREREJPNUKIqIiIiIlwpFEREREfFSoSgiIiIiXioURURERMRLhaKIiIiIeKlQFBEREREvFYoiIiIi4qVCUURERES8VCiKiIiIiJcKRREREZEcMrOZZvZnM3vTzJaZ2WfD8fFm9qiZNYe/jou658tmttLMlpvZuzOVmwpFERERkdzqA65zzh0CnABcY2aHAl8CHnfONQKPh38m/NxlwGHAucAtZlaeicRUKKZJU1MTCxYsoKmpKdepSLY5B3feCZdcAtdeC9u25TojEREpIM65Vufcy+Hv9wFvAtOBi4Dbw5fdDrwv/P1FwB3OuW7n3BpgJbAwE7lVZOJFS1FLSwvNzc25TkNy4be/hcsvf/vnZ56Bl18Gs9zlJCIi+aTCzBZF/Xybc+4234VmNgc4CngBmOyca4VQMWlmk8KXTQeej7ptQziWdioURYbr5z+P/fnVV+Gll2BhRj7ciYhI4elzzh072EVmNhK4G/icc26vJR5w8D3hhpFfQpp6FhmuFSuCsWXLsp+HiIgULDOrJFQk/to5d084vMXMpoafnwpsDcc3ADOjbp8BbMpEXioURYajpwc2bgzGly/Pfi4iIlKQLDR0+AvgTefcf0Q9dT9wRfj7K4D7ouKXmVm1mTUAjcCLmchNU88iw7F+PQwMBOO+UUYRERG/k4GPAK+b2avh2FeAfwPuNLMrgXXABwGcc8vM7E7gDUI7pq9xzvVnIjEViiLD0dLij2tEUUREkuScexr/ukOAsxPccyNwY8aSCtPUs8hwJCoUV66E/ox8uBMREckaFYoiw5GoUOzpgbVrs5qKiIhIuqlQFBmORIUiaPpZREQKngpFkeFQoSgiIkVMhaLIcByoUNTOZxERKXAqFEWGKlEPxQiNKIqISIFToSgyVOvXgzvAiUkaURQRkQKnQlFkqA407QywYQO0t2clFRERkUxQoSgyVIMViqBRRRERKWgqFEWGSoWiiIgUORWKIkOVTKGoDS0iIlLAVCiKDJUKRRERKXIqFEWGas2awa/R1LOIiBQwFYoiQ9HdDZs2DX7d8uUHbqEjIiKSxzJeKJrZuWa23MxWmtmXPM+PMbMHzOw1M1tmZh/LdE4iw+broThpEtTVxcb27YMtW7KXl4iISBpltFA0s3Lgx8B5wKHA5WZ2aNxl1wBvOOeOAM4AvmtmVZnMS2TYfOsT586FxsZgXOsURUSkQGV6RHEhsNI5t9o51wPcAVwUd40DRpmZASOBnUBfhvMSGR5fodjQAAcdFIyrUBQRkQJVkeHXnw6sj/p5A3B83DU/Au4HNgGjgA855wYynJfI8PgKxTlzoLw8GNeGFhERKVCZLhTNE4tf2f9u4FXgLGAe8KiZ/dU5tzfmhcyuAq4CqKrSzLTkWKJCMX6NImhEUUREClamp543ADOjfp5BaOQw2seAe1zISmANcHD8CznnbnPOHeucO7aiItP1rcggEhWKCxYE4yoURUSkQGW6UHwJaDSzhvAGlcsITTNHWwecDWBmk4GDgNUZzktkeBIVir41iqtXQ29vpjMSERFJu4wWis65PuBa4GHgTeBO59wyM7vazK4OX/Yt4CQzex14HLjeObc9k3mJDEuiHoqzZsGYMTB5cmy8vz9ULIqIiBSYjM/hOuceBB6Mi90a9f0moCnTeYikja+H4tSpUFMT+n7BgmDvxBUr/KONIiIieUwns4ikKtG0c4Ra5IiISJFQoVgkmpqaWLBgAU1NGpzNOBWKIiJSIrR9uEi0tLTQ3Nyc6zRKw2CFom/ns3opiohIAdKIokiq1qwJxjSiKCIiRUiFokiqBhtRnDs3eELLli2wZ08msxIREUk7FYoiqRqsUKysDBWL8TT9LCIiBUaFokgqDtRDMZqmn0VEpAioUBRJxbp1wdi0aW/3UIzQhhYREUmSmf3SzLaa2dKo2G/N7NXwo8XMXg3H55hZZ9RztyZ+5eHTrmeRVAw27RyhEUUREUner4AfAf8dCTjnPhT53sy+C0QvdF/lnDsyG4mpUBRJhQpFERFJM+fcU2Y2x/ecmRlwKXBWNnOK0NSzSCqSLRR9U8/NzTAwkO6MREQk/1WY2aKox1Up3HsqsMU5F90sucHMXjGzv5jZqWnONYZGFEVSkWyhOGUKjBoF+/a9HevogI0bYebMTGUnIiL5qc85d+wQ770c+E3Uz63ALOfcDjM7Bvi9mR3mnNs77Cw9NKIokopkC0UzTT+LiMiwmFkFcDHw20jMOdftnNsR/n4xsArwTGOlh0YUE9j2k/9N6fr+Pfv2f03l3omf/nBK7yM5lmyhCKHp50WLYmMrVsC73pXurEREpDi9C3jLObchEjCzicBO51y/mc0FGoHVmUpAI4oiyUq2h2KERhRFRCQJZvYb4DngIDPbYGZXhp+6jNhpZ4DTgCVm9hpwF3C1c25npnLTiKJIshL1UKyu9l+vXooiIpIE59zlCeIf9cTuBu7OdE4RGlEUSVYq086gEUURESl4KhRFkrVmTTB2oEKxsTEYa2mBrq50ZSQiIpJRKhRFkpXqiOLIkTB9emzMOVi1Kp1ZiYiIZIwKRZFkpVoogqafRUSkoKlQFEmWCkURESkxKhRFkuUrFBsaDnyPdj6LiEgBU6EokoyuLmhtjY2ZDX4cn0YURUSkgKlQFElGqj0UI3yFokYURUSkQKhQFEnGUNYnAsyeDVVVsbEdO0IPERGRPKdCUSQZQy0Uy8th/vxgXNPPIiJSAFQoiiRjqIUiaEOLiIgULBWKUjSamppYsGABTU1N6X/x4RSK2tAiIiIFqiLXCYikS0tLC83NzZl68WBMhaKIiBQ5jSiKJENTzyIiUoJUKIoMprNzaD0UI3wjiitXQn//8HPLIxmd+hcRkZzQ1HMea73l+qSv7d+zff/XVO6b+nc3pZxXyRlqD8WI+noYPx527nw71t0det3BTnYpIBmd+hcRkZzQiKLIYIYz7Rzhm37WOkUREclzKhRFBpOOQlEbWkREpACpUBQZjK9QTHXKWBtaRESkAKlQFBmMRhRFRKREqVAUGYwKRRERKVEqFEUGk45Ccd68UEudaBs2QHv7ULMSERHJOBWKIgfS2QmbN8fGUumhGFFbC7NnB+NqJyMiInlMhaLIgfh6KE6fDlVVqb+Wb/pZG1pERCSPqVAUOZB0TDtHqJeiiIgUGBWKIgeSzkJRG1pERKTAqFAUOZBMjyhq6llERPKYCkWRA8nGiKJzQ3s9ERGRDFOhKHIga9YEY0MtFGfMCO1+jrZ3L2zZMrTXExERyTAVipI2TU1NLFiwgKamplynkj7pHFEsK4PGxmBc088iIiXNzH5pZlvNbGlU7J/MbKOZvRp+nB/13JfNbKWZLTezd2cyNxWKkjYtLS00NzfT4iuuClFnZ3C0byg9FKNpQ4uIiAT9CjjXE/+ec+7I8ONBADM7FLgMOCx8zy1mVp6pxFQoiiSydm0wNtQeihHqpSgiInGcc08BO5O8/CLgDudct3NuDbASWJip3FQoiiTiGxltaBjea6qXooiIJO9aM1sSnpoeF45NB9ZHXbMhHMsIFYoiiaRzfWKEpp5FREpRhZktinpclcQ9PwHmAUcCrcB3w3HzXJux9hkVmXphkYKXiULRN6K4ejX09kJl5fBeW0RE8lWfc+7YVG5wzu1fJG9mPwP+EP5xAxC9WH4GsGnYGSagEUWRRDJRKI4dC5Mmxcb6+vxteEREpGSZ2dSoH98PRHZE3w9cZmbVZtYANAIvZioPFYoiiWSiUARNPxepomwPJSJZYWa/AZ4DDjKzDWZ2JXCzmb1uZkuAM4F/AHDOLQPuBN4AHgKucc71Zyo3TT2LJJKpQnHBAvjrX2Nj2vlc8CLtoUREUuWcu9wT/sUBrr8RuDFzGb1NI4oiPr4eimVlodNVhksjiiIiUiA0opgmM8fXx3yVApeJHooR6qWYEU1NTbS0tDBnzhweeeSRXKcjIlIUVCimye/+/vpcpyDplKlpZ1AvxQzR1K+ISPpp6lnEJ5OF4ty5UB532tLmzbB3b3peX0REJE1UKIr4+NrVpKtQrKoKFYvxNP0sIiJ5RoWiiE8mRxRB088iIlIQVCiK+GS6UNTOZxERKQAqFEV8cjGiOMypZzV8FhGRdNOuZ5F4HR2wdWtsrKwMZs70Xz8UGRhR1K5fERFJt4yPKJrZuWa23MxWmtmXElxzhpm9ambLzOwvmc5J5IB8PRRnzIDKyvS9R6Jeis6l7z1ERESGKaMjimZWDvwYOAfYALxkZvc7596IumYscAtwrnNunZlNymROxWrG+DExX2UYMj3tDDBlCowcCW1tb8c6OmDjxvSc/iIiIpIGmZ56XgisdM6tBjCzO4CLCB1kHfE3wD3OuXUAzrmtgVeRQd3xmUtznULxyEahaBYaVVy8ODa+fLkKRREZEp1OJJmQ6ann6cD6qJ83hGPRFgDjzOxJM1tsZn/reyEzu8rMFpnZor6+vgylK0J2CkXQUX4iklaRdcotvt9hIkOU6RFF88TiF2FVAMcAZwO1wHNm9rxzLuYvpnPuNuA2gBEjRmghl2ROtgpF9VIUEZE8l+lCcQMQvVV0BrDJc81251w70G5mTwFHABpakdzI5YiiCkUREckjmZ56fgloNLMGM6sCLgPuj7vmPuBUM6swszrgeODNDOclklguRxQ19SwiInkko4Wic64PuBZ4mFDxd6dzbpmZXW1mV4eveRN4CFgCvAj83Dm3NJN5iSSUqIdiEhtMUm547SsUW1qguzu5+0VERDIs4w23nXMPAg/GxW6N+/k7wHcynYvIoIbRQzHlhtcjR8L06aGWOBEDA7BqFRx6aPKvIyIikiE6wk8k2po1wVgmpp0jtKFFRETymApFkWjZWp8YoQ0tIiKSx1QoikTLh0JRG1pERCRPqFAUiZbtQlFTzyIiksdUKIpE8xWKDQ2Zez9NPYuISB5ToSgSLdsjinPmBHdU79gReoiIiOSYCkWRiPZ22LYtNlZenlQPxSErL4f584NxrVMUEZE8oEJRJCJRD8WKDLcb1YYWERHJUyoURSKyPe0coQ0tIiKSp1QoikTkqlDUhhYREclTGT/CTwrXSz+9MKXru/Zs2v812XuP+9QDKeeVMflUKGrqWURE8oBGFEUi8mnqubkZ+vsz/94iIiIHoEJRJCJXhWJ9PYwbFxvr7oZ16zL/3iIiknNm9ksz22pmS6Ni3zGzt8xsiZnda2Zjw/E5ZtZpZq+GH7dmMjcViiIRa9YEY9koFM00/SwiUtp+BZwbF3sUONw5905gBfDlqOdWOeeODD+uzmRiKhRFANraYPv22FimeyhG085nEZGS5Zx7CtgZF3vEOdcX/vF5YEh/kMxs/HByU6EoArnroRihEUUREUns48Cfon5uMLNXzOwvZnbqIPe+YGa/M7PzzcxSfWMViiKQu/WJERpRFBEpZhVmtijqcVWyN5rZV4E+4NfhUCswyzl3FPCPwP+Z2egDvMQC4DbgI8BKM/sXM/P80UmQeLIXihQ1X6HY0JC991cvRRGRYtbnnDs21ZvM7ArgPcDZzjkH4JzrBrrD3y82s1WEisFFvtcI3/co8KiZnQn8L/B3ZvYa8CXn3HMHykGFogjkfkRx/vzQppbQ74GQ9euhowPq6rKXh4iI5AUzOxe4HjjdOdcRFZ8I7HTO9ZvZXKARWH2A15kAfJjQiOIW4DPA/cCRwO+AA46KaOpZBHJfKNbWwqxZwXhzc/ZyEBGRnDCz3wDPAQeZ2QYzuxL4ETCK0EhgdBuc04Al4RHBu4CrnXM7vS8c8hwwGnifc+4C59w9zrk+59wiYNDWOkmPKJpZuXNOHYAla+775XkpXd++d+P+r8nee9HHw2uDc10oQmj6OX5TzfLlcMQR2c1DCtPAQGhUOvW16iKSY865yz3hXyS49m7g7hRe/qDItLXntW4a7OZURhRXhps/HprCPSKFIV8KxXja+SzJePjh0IaokSPhwx+Gzs5cZyQi+eORSLNuADMbZ2YPJ3tzKoVipOHjz83seTO7apBdNiKFIVEPxenTs5uHdj7LUOzbB3/7t7BqVWhN669/DZ/4RK6zEpH8MdE5tzvyg3NuFzAp2ZuTLhSdc/uccz9zzp0EfBH4BtBqZreb2fxUMhbJK74eijNnZq+HYoRGFGUonngCtm6Njf3f/8Ef/5ibfEQk3/Sb2f5F8GY2G/BORfuktEYRuAD4GDAH+C6hnj6nAg8S2potUngSTDv/9H/endLL7Amvkdyzd2NK937qI+EZgEQjis5p3Zkk9uKL/vinPw1Ll8JoTfyIlLivAk+b2V/CP58GJN3HMZWp52bgIuA7zrmjnHP/4Zzb4py7C3gohdcRyS/5sD4RQqOYtbWxsT17gqNFItESFYrr18OXv+x/TkRKhnPuIeBo4LfAncAxzrn0rlEMjyb+yjl3pXPuWU8Sf5/sG4rknXwpFMvKoLExGNf0syQyMAAvvZT4+Vtugaefzl4+IpKvqgmdJb0HONTMTkv2xqQKxXBbnDOHlptInluzJhjLRaEI2tAiqWluDo06H8gnPgFdXdnJR0TyjpndBDxDaAr6C+HH55O9P5XV+s+a2Y8IDV22R4LOuZdTeA2R/JNoRHFdthNBR/lJahJNO0dbvhy+9S248cbM5yMi+eh9hHopdg/l5lQKxZPCX/85KuaAs4byxiJ5I98LRU09SyLJFIoAN98MH/wgHHlkZvMpcU1NTbS0tDBnzhweeeSRXKcjErEaqCR8PnSqki4UnXOaepbis28f7NgRG8tFD8UIz9Tz1kWP8927zh301u1tG/d/vT6J6yNuusS/F+3831+X9GsAbGzbtv9rKvc++L7vpvQ+EsVXKH7zm/Dtb0Nv79uxvj648kp44YXst30qIS0tLTTr2E3JPx3Aq2b2OFHFYrL7S1L6jWFmFwCHATVRb/TPie+QrOnrp3xPG/3jRkOZWqkkzddDcdas3P0x9YwoTtjSQVn/AAPlOppdonR3w6uvBuMf+1hok8s3vxkbf/ll+N734AtfyE5+2dbVBdu2waRJUF2d62xE8sn94ceQJP2XJ3wY9YeAzwAGfBCYPdQ3lvSpWrGWSV+7lUk3/JSJ/3Qb5VsPdDa4xMiXHc8RY8eG/tBFKe93jNuqI9kkzpIl0NMTG5syBWbMCLXFOeyw4D033AArV2Ynv2x66imYPz/0Ie/QQ0NFsYgA4Jy7nVBbnOedc7dHHsnen8oQxUnOub8FdjnnvgmcCMxMLV1Ju75+xt7+R8r3hfYXVezYw/hb74G+/hwnViDyrVAE7/TzxE3tngulpPmmnRcuDDVnr66Gn/882Ki9qws++clQE/disWwZvOc9sDG09ILVq+Haa3Obk0geMbMLgVcJ97w2syPNLOkRxlQKxciQRoeZTQN6gYYU7pcMqH6rhfLdbTGxii07GfHEAXqrydvysVD0TD9P3NSRg0QkryUqFCNOOAH+3rME6cknQ0VkMdi+Hd773tBa42jPPQdbtuQmJ5H880/AQmA3gHPuVVKo31IpFP9gZmOB7wAvAy3AHSncLxlQs/gtb3zkn56jfMcg/dUkPwtFjShKMjyF4kdvuYWmpqa3A9/+tv+/589//u0RuELV2xvayb16tf/5Z57Jbj4i+avPORdfECQ9rZB0oeic+5Zzbrdz7m5CaxMPds59Pdn7JQN6+6hZ4t9hV9bTy+i7n8hyQgUoHwtFz4hivQpFibZnD7wV/JB436ZNtET/Nz1yJPz0p8H79+6Fa64p3Clo5+AznwmNjiaiQlEkYqmZ/Q1QbmaNZvZDIHDKXiKDFopmdnH8A7gAODv8veRI9RtrKOvqSfh8zWvNVC9dlcWMClCBFIoTWzX1LFEWLQqEVldWhuaV4jU1wUc/Gozfdx/cdVfaUmpqamLBggWxI5qZcsst/gI4mo4uFIn4DKGONd3Ab4C9wOeSvTmZHiAXHuA5B9yT7JtJetW+7J92jjb6zsfYtmAWVFVmIaPCUtHZF+yhWFEB06blJqGIuXNDvRz7396QNHpXN9UdfXTXqQee4J12fr2mJrZ3YrTvfhf+9Kfgur1rr4WzzoIJE4adUtZ6CD72GHz2s4Nf9/LL0NEBdXWZz0kkjznnOggd3/fVodw/6F8d59zHhvLCkmE9vVQvGbzNRcWOPYx85Hna3nNqFpIqLLU7PC1nZs7MfUPiqipoaAi0MalvbWfjvDE5SkryiqdQXFJTE9zUETF+PPzwh3DppbHxrVvhuuvgV79Kf46Z0NwcWpfY7+nqUFkZbDL+4otwxhlZS08kH5nZn/GsSXTOJXWyXkodfM3sAjP7opndEHmkcr+kT83S1ZT1xI4eDNRW090Y7Fg08tEX1VvRo85XKOZ62jnCu/NZ6xQlzFMovlZT47kwyiWXwPveF4zffjsUwnFzu3fDhReGvsa7+mr4wAeCca1TFAH4PPCF8OPrhFrlBNevJKCG2wWqxjPt3HXEAvZc1oSLO8HD+voZc+djhbtwPUPqtudxoejd+ax1ikJot/KmTbGxykreqqo68H1m8OMfwxjPqPRVV0FbWzCeL/r64LLLYPny4HNnnAE/+AGcfHLwOa1TFME5tzjq8Yxz7h+B45O9Xw23C5B19VDj2aTSeczB9E+ZQPu7Fgaeq36zhZpXPL9kS1heF4q+nc+tGlEU/P0TjziCnrIkfp1Pmwbf+U4wvnYtfO1rw88tU774RXj44WB87tzQhpzKSjjllODzzz3nn6YWKSFmNj7qUW9m7wamJHu/Gm4XoOqlq7DevpjYwIhaeg6aBcC+c0+kb/zowH2j734C6+oOxEtVXheK6qUoiQzWaHswn/gEnHlmMP6DH8Dzzw89r0z55S9DZ1THGzUKHnjg7Y0473hHKBZtz57QyS0ipW0xoanmxcBzwHXAlcnerIbbBci327nzyAWhnbIAVZXs/eDZgWvKd7cx8sGkWycVvUJbo1i/qUPLB2T4haIZ3HYbxK9pdA6uvBK68+jD5NNPh9YfxjODO+4InescUV4OJ54YvFbrFKXEOecanHNzw18bnXNNzrmk12Wo4XaBsc5uqpcFTyLoOvrgmJ+739lI1zvmBa4b8edFVGzclrH8Col3RLEhTwbJp06lu6Y8JlTd3c/onXn0R1yyb2AAXvIcz5lKoQgwfz5861vB+BtvwL/+69ByS7eWFrj4Yn/Ln5tvhvPPD8a1TlEkwNcPO6439gEl3QfEzD4IPOSc20do58zRZvYt59wrw8hfUlTz+kqsL3bNTf+oOno8u533XnI21W+tjZmmtgHHmN8+yo5/uDz0qbxEVXT2UdUe9wcoH3ooRpixbeoIZqzZGxOeuKmdvRMG2d1aJC6454cpXb+xbff+r6nc+8eLP5PS++TU8uXBFjijRnlHoAf1uc+FRuUWL46N/8u/hHZIH3740PMcrrY2uOgi2Ob5UHvFFaGWPj6+dYoaURS5EjgJiBzXdibwJLCHJPphp9Iw7uvOud+Z2SnAu4F/B24lhZ0zMny+s527jjoIyoODw/31Y2k790RGPfDXmHjVqg3UvrCMzhNy+Icgx7w9FGfNenv6Pg9sm1YXKBTrWztY9Y7hN0eWwb3nrl+ndP2mtn37v6Zy7x8u+X/Jv4lv2vm44yCZjSzxKirgF7+AY48N7SqO6O0NrWN85pnc/HsYGICPfASWLAk+d+KJoRNZPB9ym5qa2LJ6NS+bUR69RGPtWtiwAWbMyGDSInnNAYc651oBzGwq8ONk+2Sn8tslMox1AfAT59x9wCD9GCSdrKOL6jfXBOLx087R2s4+jr5J4wLxUfc+iXV0pTW/QpLXG1nCtk8fEYhpQ0uJG+76xHhHHAHXXx+Mv/BCqEF3LtxwA/z+98H4zJlwzz1QXe29raWlhSWrVvGGr02QRhWltM2JFIlhW4DgjskEUikUN5rZT4FLgQfNrDrF+2WYal5rxvoHYmL9Y0bQM2964psqK9hz6TmBcHlbB6PufyrdKRaMvN7IErZtqgpFiZPuQhFCbXF8U9df/SqsCX4wzajf/AZuvDEYr6sLnU09ZfCOHotra4NBFYpS2p40s4fN7KNmdgXwR+DPyd6cSqF3KfAwcK5zbjcwntBaRQDMLDhsJWnlbbJ91MGDTjv1HDKHzmOCo451T7/qXxhfAgphRHHbtGChWK9CsXR1dcFrrwXjwy0Ua2rg5z8Pxjs6Qo24s7XT/qWX4OMf9z/33/8NRx2V1Mss9p1Qow0tUsKcc9cSWip4BHAkcJtzLunF2anseu5wzt3jnGsO/9zqnIs+9+nxZF9LUmdtnVS/tTYQ9xWAPnsvPpOB6srY13TApz9dkg1pC6FQ3D61LhAbv7WT8t4Bz9VS9F57LbgDeNo0mH6AGYVknXIKXHNNMP7YY6Ej/jJt48bQ5pUuz3KYb37TfzxfAi/7RhRfey3xOdgiecDMfmlmW81saVRsvJk9ambN4a/jop77spmtNLPl4Qbag3kZ+KNz7h+Ah81s1GA3RKRz6rh0t9BmQc1rK7CBuGnncaPonZPcLt2BsaNoe49nR+DixaGeamkwbUItMyeNYNoEzy/qPJOJqecJE2uZNLmOCRPT839/T20Fe8bFrscqczBhs47yK0mZmHaO9q//GloHGO8f/gE2b07f+8Tr7AydQcB9W4YAACAASURBVN3aGnzu0kvh66l1YdtWURE6sSXawEB+NhMXeduvgHPjYl8CHnfONRIajPsSgJkdClwGHBa+5xYzS7jzzMw+CdwF/DQcmg54FgL7pbLreTDqBJxBtZ7dzp1HHQRlydfn7acfQ+3zS6mM76P4la+EPrFPmjSsHH/42ROGdX82ZWJE8bNfPGZY9/tsmzaCMbtieyfWt7azdebItL+X5LlMF4qjRsGtt8IFF8TGd++Gz3wGfve79L1XhHOh6eZFi4LPHX00/Nd/Da2N18knw+q4frPPPAPnBNdri+QD59xTZjYnLnwRcEb4+9sJtbS5Phy/wznXDawxs5XAQkKnrvhcE37+hfB7NZtZ0n/wtRmlAJTta6dqxbpAvOuYQ1J7ofIy9nzI84ty9+7QWaolIu97KEbZPi04/awNLSUq04UihJpY/z9Pu5677oJ7703ve0FoFPMOzwFfU6aENq/UBf/7T4oab0v+qTCzRVGPq5K4Z3Jkt3L4a6S4mw6sj7puQziWSLdzrifyg5lVkMLgnqaeC0DNKyuwuAXlfRPG0Ds76TO99+udN4OOE94RfOL22+Gp0tgF7R1NzLMeihG+DS0TN2nqueTs2gUrVgTjxx6b/vf6/vehvj4Yv+aa0IfKdLn33tDO6njV1aH2OMPpe+hrvP3887H9IkWyq885d2zUYzhrvnz11oEKv7+Y2VeAWjM7B/gd8ECyb5ZSoWhm5WY2zcxmRR5RTwcPF5a08O52PvrgIZ+ssu99pzNQ59kZ+Hd/5z8uq8gUQmucCO18FsA/NXvwwTBmTPrfq74efvCDYLy1Fb7whWB8KJYsCTXV9vn5z+H4YZ7jcMghMHZsbKy93b9rXCR/bQk3x440yd4ajm8AohcUzwA2HeB1rge2Aa8DnwIeBL6WbBJJF4pm9hlCTRofJdSD54/AHyLPO+d2Jvtakryy3fuoWrk+EO88eghHdoUNjKpj33tPCz6xbJn/D0SRqdvuGZHL00LRt/NZU88lKBvTztEuuyy4VhFCRdwTTwTjqdi6Fd773lDhFu/66+HDHx7e60OoZZhv+ln9FKWw3A9cEf7+CuC+qPhlZlZtZg1AI+D5JQFmVga87pz7mXPug865S8LfZ2Tq+bPAQc65w5xz7wg/3pnC/TIEoWnn2FjfxLH0zZw8rNftOPmd9MyeGnziG98IHXdVxGp9U88NDdlPJAm7JtXSVx47cjxyXy+1+3oS3CFFKduFohn85CehDS7xPvnJUI/FoejuDm2cWxts9cWFF/qbbQ+V1ilKATGz3xDajHKQmW0wsyuBfwPOMbNm4JzwzzjnlgF3Am8ADwHXOOe8fe6ccwPAa3EzwClJpVBcT+gAacmiWs+0c+cxhwx52nm/sjL2XHZO8HXa20PtMIpY3Q5Pr7Y8HVEcKC9jxxTPqGKr1imWDOdCR+rFy2ShCKFWOTfdFIyvXh06Zi9VzoX6tvqKtcMPh1//Or3rhH3rFJ95JnsNxEVS4Jy73Dk31TlX6Zyb4Zz7hXNuh3PubOdcY/jrzqjrb3TOzXPOHeSc+9MgLz8VWGZmj5vZ/ZFHsrkN2h7HzP4x/O1qQsfA/BHY36/DOfcfyb6ZpKZs116qVm8MxA90tnMq+mZNCa1L/PGPY5+46y54+OG0vEc+KoRm29G2TxvB5I2x03T1m9pZt2BsgjukqGzYAFu2xMaqquCdWZjQ+dSnQsfq/fWvsfHvfQ8+9CE47rjkX+v73w+1u4k3YQLcf79/9HI4jj0WKitj111v2gQtLXk7gyCSTmZWHW6h883hvE4yI4qjwo91hNYnVkXF0vwvW6LVvrw8EOubPJ6+aZ4diUP17W/7+ydeey3WW5wnthRaobjN2yJHI4olwzftfOSRod3BmVZWBj/7WfC9BgbgyiuhJ8klEA89BJ//fDBeUQF3352Zwq221r8rXOsUpXRE+ip+wjn3l/hHsi8y6Iiic25YlagMXY2vyfYxQ9/t7DV2LPz7v8Pf/m1sfOVKpj5SxqYLFqTvvfJARUcvVR1xO7srK2GqZ71mntg+1dciRxtaSka21yfGO+ig0Nrlr3wlNv7663DzzfC1QTZPvvVWaPRxwHP05C23wOmnpy/XeCefDM/F9SB++un0bJgRyX9VZnYFcJKZXRz/pHPunmReJJVdzw9Ez22HH/9jZp81M0+vlf33nRs+i3ClmX3pANcdZ2b9ZnZJsjkVtZYWqtYGj7RKucl2Mj78YTgtuAt66p9WUr2tuAoS7/rEPO2hGKEWOSUu14UihEYDjzwyGP/Wt+DNNxPft3NnaJPK3r3B5z7zmdDGmExKtE5RpDRcDZwAjAUujHu8J9kXSWUzy2qgDfhZ+LGXULucBeGfA8JnD/4YOA84FLg8fEah77qbgOJdGJeqO+8MhHqnTaRvyoT0v5dZ6JN9RewAc1nfALN+u6yoFn8XUg/FCG+huLkDGyie/79IAv39/h6K2S4UKyvhF78IfqDq6YFPfMI/WtjbGzqreeXK4HPvehf8RxaWt590UjC2bFmogblIkXPOPe2c+zTwRefcx+IeH0/2dVIpFI9yzv2Nc+6B8OPDwELn3DXA0QnuWQisdM6tDh8fcwehMwrjfQa4m7ebScpvfxsIdQ2jd+KgDjvMu9t57NKtjH11c+beN8sKqYdiRPvoSjpGxBbxlb0DjN3uGR2V4vLWW9DWFhsbMwYaG7Ofy9FHw3XXBePPPhv6oBnvH/8RHn88GG9sDH0Qrhh05dPwTZwYmjqP5lxwOlqkiDnnfjGc+1P5lzrRzGY559YBhHvyRHZVJFrR7DuPMKblvplNB94PnAUk3EIXPhfxKoCqqqoU0i5AK1fCyy8Hwp3HpGe3c0I33BDa4RjXR3HWncvYe+hEBqqz8Is9w7w9FPO8UMSM7dNGMKs5tjtVfWs7uybV5igpybSL7voTZ//5Ef4+Lv7qrAa+cU9w8mVTW/v+rxfdNVi3jLfdd8l5ySf1T/8E99wTHCX88peZVl9Pc+TnW2+FH/0oeP+YMfDAAzBuXPLvOVwnnwzL4zYGPvNM6FxrERlUKiOK1wFPm9mfzexJ4K/AF8xsBHB7gnuSOY/w+8D1iZpF7r/JudsiZyRWZOOTaC75pp1nTqJ/0vjMvu/IkfCf/xkIV+/qYtqDzZ4bCk8h9VCM5j/zWesUi11jc/B85+b5GZxZGExtbWgXdLy2Nv55a2hCaGFHR2j9YbyystBMSfwIX6ap8bbIsCRdcTnnHjSzRuBgQgXgW865yF/d7ye4LZnzCI8F7rDQTt564Hwz63PO/T7Z3IqOZ9q58+gMbGLxef/74dxzQ+0sokx+dDXbj59B17TC7ohUt63wpp4BtvmO8tuoQrHYNa4MFoorGnPcieCMM+Cqq+C222LCp3V08FXgutZW/5rF//gPePe7s5JiDN+GlhdfDK2vLPbZKZGw8K7nUwgN1j3tnLs32XsHHVE0s7Oi3uQCYB4wl1BBF9huHecloNHMGsysCriM0BmF+znnGpxzc5xzc4C7gL8r6SLxrbdgyZJAOKPrE6OZwQ9/GOibVjbgmH3H0oLf2FKIm1kg1HQ7Xr1OZylqVd3dzFm3JhDP6YhixM03w7RpgfC3gXG+IvHKK+Hv4yfRs6SxMbRWMVpXl3d5j0gxMrNbCO2Afh1YCnzKzH584LvelszUc6TJVfSW6veQxPZq51wfcC2h3cxvAnc655aZ2dVmdnWySZYUz2hiz+wp9Ndn8RSO+fPhy18OhEev2MH4F4MnxRSKUA/FvthgnvdQjNDUc+lpaFlNRX/sipztE+rZNS7DS1CSMWZM6CzoZJx6amizSzr7v6bCzD/9rDY5UjpOB97tnPsv59x/AecDZyR786CFonPuG+FvPw08BqwC1gIt4cdg9z/onFsQPpPwxnDsVufcrZ5rP+qcuyvZ5IuSZ31iuo7sS8n119M1MTjdOevuNynv7PXckP+8o4l53kMxYvuUOgbi/s6O295FZXdxnp4j0LgyeDLTivl51AD/ve8Ntb85kNmzQyev5HqKV+sUpbQtB2ZF/TwTCE5dJpDKZpbfExpF7CXUTzHykHRZuhTeeCMQ7sxFoVhTw7oPHR4IV+7tZvr9wT9ghcB7dF+BnPnaV13O7vpgX/sJmzX9XKwWeNYn5sW0c7Qf/ADGJxjhHDEidIZz/LRvLiRqvF3gS2lEDiRyUAowAXjTzJ4Mb0Z+E0j6H2Yq24dnOOfOTS1NSYlv2rlhGgPjR+cgGdhz+CR2HjWF8a/E9lGc9GQL20+cScesMTnJa6gK7YzneNunjmD8tthd2xM3tbN5dmFvMBI/30aW5nwaUQSYPBm+9z244orYuBn8+tfwznfmJq94Rx8NNTWhtYkR27ZBczMsyLP/TUXS59/T8SKpjCg+a2bvSMebiodz/t3Ome6dOIj1HzyM/urYqVlzMPs3r0OBnQxSqBtZInSUXwnZuZNpm2MbRAyYsXJuDhptD+YjH4EPfjA2dtNNcJHvbIUcqaryn2ajdYpSxJxzf4k8gLeAUeHHm+FYUgYdUTSz1wltp64APmZmq4FuQi1ynHMuTz4yFrjXXgt9uo3iDLqOyu1UU8/4WjZdsICZ98Se5zpyzW7qn1nH9lNn5yiz1BX6iOK2aZ4WOZs09VyUXnopENowfSaddcH/BjLpkruT2xlc/oHrmPTI48zds5O/jJ9IxdyzIcl77/pAooO90uzkk+Gpp2JjTz8NH/tYdt5fJEfM7FLgO8CThGq3H5rZF5LdE5LM1HPSB0fLMPimnefNYGBs7qcVt5zdQP1z66ltjV2SOvP3b7H7qKn0jSyMXmQFeSpLFF+LHO18LlIvvhgI5d20c5T+ikp+VTeStj07GVldSw66JQ4u0TpFkeL3VeA459xWADObSGhzclKFYjK7ntce6DGs1CUkwbRzTnY7e7jyMtZeHlx1UNHey4x73/TckZ+Kcuq5tV0L8ouRp1BckW8bWQrNiScGY8uXh9YqihS3skiRGLaDFJYeprJGUTJl0SJYE9dYt6ws59PO0fYtmMD246cH4hOfWc/IVTtzkFFqfD0UB8qtIHooRuyZUENvZew/2br2PkbsDR21PmZiLeOm1jFmos5/LmjOFdyIYkEYNw4OD3Zy4Nlns5+LSHY9ZGYPm9lHzeyjwINA0gfCq1DMB57eiZxxBgOjgyNIubT+A4fSVxtcrTD7N0uh33MaQx7xjSZ2TKgNnT9bIFyZsd13lF94neKlXz+WT/7gVC79+rHZTk3Sad062Lo1JtRTWcnaWXNyk08xUeNtKUHOuS8APwXeAbwTuNU598Vk7y+cv5LFyjl/ofihD2U/l0H0ja5m40XB6fC6DXuZ/GRL9hNKgW8jS0d94Y286YSWEuAZTVw9Zx59lZU5SKbI+NYpqvG2FCkzezr8dR/wK+Aq4JPA/5jZHjNbY2Z/N9jrqFDMteefD40gRCsvh4sHO0Y7N7aeNpt2T//E6Q+soHJ3l+eO/OAtFCcUXqG4fapa5BQ9TTtnjm9EcdEi6PSsXxYpcM65U8JfRznnRoe/Rh5jgGOBzw72OioUc82ziYWzz4b6+uznkowyY+3lh+PijpMr7+pj5t3BU2Xyha9Q7CzEEcXpnqnnVrXIKSq+QrExf9YrF7Q5c4Lrknt7Q8WiSIlxzu0giTOfUzmZRdJtYAB+97tgPA+nnaO1N4xj2ymzmPTX2JHQCS9tYtvJs9h3cP4VuZp6loLQ1+ctWvLqjOcsuune1qSv3dXWv//rge67qOFYDm59IDb4zDNw6qlDylGkkDnnBv1HphHFHKpc3QybNsUFK+H9789NQinY8L6D6fX0T5z9m9ex3v4cZAQTJ9QybXIdEz1Tygk3sxQY39Tz+M0dlOX5ZiJJ0ptvQkfsCHHbiJG0TpmWo4SKz4aDjwsGtU5RJCGNKOZQ9eLng8Fzzgm1cchz/SOq2HDxITT892sx8dot7Ux5fA2t587Pek7fvM7zByCsWEYUO0dW0ja6ipHhljgAFf2OcVs72eEpIqXAJFqfaOa5WIZiwyGeo/yefTY0w1NAXRBEskX/KnJlYIDqV4LHdOX7tHO07SfMYN+8YFE79aGVlHf25iAjv4qOXio7Y3so9lcYXWOqc5TR8OgovyLmbbRdmtPOmbJ1zqH01MT9G9q1KzSaKyIBKhRzpLL5Lcr27okNVlXBRRflJqGhKDPWXv4OXFnsaEd5Vx8T49Yv5pJ3I8uEWigrzFEa3/Sz1ikWCe+IojaypJMrr2DTAs/50uqnKOKlQjFHqhe/EAyedx6MCbaeyWedM0az7eSZgfjkx1djffmxbq5YWuNEbJue4Cg/KWwdHfD664Fw87zGHCRT3DZqnaJI0lQo5kJ/P9WveqadL700+7mkweZz5gXa5VTt6Wb8ixtzk1Ac70aWAlyfGLHNezqLCsWC98or0B+7EWxr/UR2jxufo4SK14aDPesUNaIo4qXNLDlQufwNytr2xQZrauDCC3OT0DB1TxrBrqOmMv7l2F32Ux9dxY4TZuR8irdYNrJEbPe0yKnXGsXCp2nnrNl00DEMlJVRNhA167F6NbS2xvRZ/NNvt6f0uu37+vd/Tfbe8z6Uf+3EJPvM7CAgurHyXOAGYCyh01S2heNfcc49mM3cNKKYA97dzhdcAKNGZT+ZNNl8ztxArLa1jTFLt3quzq5im3reMbmOgbjae8yubqriNuxIgdGJLFnTUzuSrbMPDT6hUUXJEefccufckc65I4FjgA7g3vDT34s8l+0iEVQoZl9fH9WvLQ7GC2i3s097wzj2NganyKY8uioH2cQqtqnn/soydk4K5q/p5wLn3fGsEcVM8a5TVKEo+eFsYJVzbm2uEwEVillX9dZSyjri/qDX1cH55+cmoTTa3DQvEBvdvJMRa3blIJu3Jdz1XMB8J7TU6yi/wrV9e2jqM0q/lbFqbvb7kZYKbz9FbWiRzKkws0VRj6sOcO1lwG+ifr7WzJaY2S/NLOuNllUoZpl3t/OFF8KIwm+WvOfwSXRMC06fT3kkd6OKxdZDMcK3TlEjigXspeDmtvUzZtJVW9gfaPKZd0TxlVegXf+OJCP6nHPHRj1u811kZlXAe4HI+b4/AeYBRwKtwHezkm0UFYrZ1NtDVRFOO+9n5l2rOO7VzVRvactBQsXXQzFCZz4XGW1kybp99dPYUz89NtjfDy94PsyLZM95wMvOuS0Azrktzrl+59wA8DPAMxSeWSoUs6jqzaWUdcUVLiNHhvonFomdx02nZ2xNTMwcTHlsdYI7MmtEkW1kifCdzqKdzwXMVyg2aiNLpnmnn7VOUXLrcqKmnc1satRz7weWZjshFYpZ5N3tfNFFodY4RcJVlLHlrIZAvP65DVTs7c56PrVF1honwns6S2s7OJeDbGRYnEvLRpa6iZMZMXUadRMnpyuzoqfG25JPzKwOOAe4Jyp8s5m9bmZLgDOBf8h2XuqjmC09PVQteSUYL5Zp5yhbT53F1Aebqeh6e21gWd8Ak59sYeN7szudVmw9FCP2jq+mu6ac6q63GzRXd/Uzalc3+8YXzwePktDSEtrMEq2mhnUzZ6f0Mid+/cb05VQivCOKzz0XmoIuL89+QlLSnHMdwIS42EdylM5+GlHMkqplr1HW3RUTG6itg6amHGWUOQO1lWw7LfhHbtKTLZR1ZbfXn7c1ThFMPWPGNp35XBw8o4kcfTT9Ffocn2nbZx4Eo0fHBvft8x6lKFKqVChmiW+3c88Rx0B1Ye++TWTLWQ0MlMduGKno6KX+2fVZzaNYRxQBtnvWKU7UOsXC4ysUF2Z9vXpJcuXlcNJJwSe0TlFkPxWK2dDdRfXS4LRz9zHH5yCZ7OgdW8OO42cE4lMeWw39A547MsC5omu2HU07n4uECsXcOvnkYEzrFEX2U6GYBdWvv4r19MTEBkaMpOfgw3KUUXZsflewVU71zs7AmdCZUtnR5+mhWEb36OIYxfU23VahWFDK+vthsadllgrF7DnllGBMI4oi+6lQzALftHP3kcdCeXGvQeqaNopd7wzuwJzyyKqs7M7191CsKfgeihHbp/qmnnNXKNZOGkPd1LHUThqTsxwKzez1G6Az7r/T8eNhbvBDlmTIwoUQvx50/XpYty43+YjkmeKuVPKAdXVStey1QLyYp52jbT5nLuOWbImJjVi/l9FvbWfvIRMz+t7FPO0M/hHF8Vs7Ke8doL8y+58BF/7TB7L+noVuwUpPf9GFC8GK48NMQairg6OPDi4BeOYZKDsnNzmJ5BGNKGZY1ZKXsb7emNjAyFH0Nh6So4yyq23+eNoaxgbi2TjWr1h7KEb01FawZ1zsNHqZgwlbtKGlUCxY6fl3oGnn7NM6RZGEVChmmHfa+ajjSqdHlxmbm+YFwmPe3E7t+j0ZfWvvjudiaI0Txbfzub5VhWKhSDiiKNmldYoiCalQzCDraKfqjSWBePcxJ+Qgm9zZdcQUuiYFp0mnZnhUsdinnkE7nwtZdVcXs9Z52kUd5zktRDLLN6L4+utUdOzNfi4ieUaFYgZVLXkZ6++PifWPHkNvikdzFbwyY/M5wcX54xe3wtq1GXvbkhhR9DXd3liahWLdpPHUTZ1I3aTxuU4lKfPXtFAev6lrzhyYNCkn+ZS0yZNhXtzMx8AAY5sX5SYfkTyizSwZ5DvbueeohVBWevX59hNmMP3+5VTue7tNkA04+N734PvfT/8bFnkPxQhvi5zW0iwUF95wTa5TSImmnfPMKafAqthZjnHLX2T7EWflKCGR/FB6FUuWWNs+qt5cFoh3lchu53iuspwtZzYEn/jZz2DnzrS/X2V7b1H3UIzYptNZClZjszay5BXP9PO45cE15iKlRoVihlS/thgbiJt2HjuOvrmNOcoo97aePpv+6rhNPB0d8JOfpP29fKOJxdRDMWLXpFr64o5KHLm3h9q23gR3SL7QiGKe8WxoGbMy2LVCpNSoUMwQ727no48vyWnniP4RVWw7eVbwiR/8INh0eJiK+YznaAPlZeycEhxVnLSxLQfZSLLG7NnDlG3bYoNlZaF+fpIbBx0UanYepaK7g9Frl+YoIZH8ULpVSwbZvr1UrngjEC+VJtsHsuXsBlz8qN7WrfDf/53W9/EViu31wYKqGPjWKS58bEMOMilttRPrGTF1CrUT6we9ttE3mnj44TAi+P/LQlE3cSojp86ibuLUXKcyNGVlmn4W8dBmlgyofuUlbGAgJtY/vp6+OcF+gqWmZ0IdO4+ZyoSXNsU+8d3vwic+kbb+kt6p5yIcUQRY+Y7xHPbS1pjYUU+18vgl89g5uTiL43x0/Ne/lPS1xTjtfOoNt+Q6heE7+WR44IGY0Li3XqDl/KtzlJBI7mlEMQP80846liui1dOAm+ZmuO++tL2H91SWImuNE7HojOm0j6qMiZUPOM6811OMSF7QiSx5yrNOceyKF7NyNr1IvlKhmGa2ZzeVK98KxLuPLa0m2wfSOXMMew7xTM/dfHPafiGXQmuciJ7aCp66cE4gfsyTmxi7Lb1rPyUNnCvKEcVcGzdpBvVT5zJu0oyhv8gxx0BVVUyoZvdW6ra0DC85kQKmQjHNql95CYsrdvrrJ9E3c05uEspTvmP9eOGF9Jyv6lzJbGaJeO7ds+gYEbuSpLzfcca9a3KUkSQyZctWRrfFbTaqrYXDDstNQkXiym/cwed//DRXfuOOob9ITY33ZJyxK14cRmYihU2FYprVeJpsdx9zvKad4+w9uJ72maODT9x887Bfu7K9l8quuNZElWV0j65KcEfh666r4On3zAnEj3tiA2M8RbPkjnfa+ZhjoEJLxvOCb0PLW9rQIqVLhWIale3aSeWqFYF4qTbZPiAz/6jiH/4AbwR3jKfCO+08obboi/VnzptFZ11ssVHR7zj9vpbcJCRemnbOc551iuM0oiglTIViGlW/Evxl0jd5Kv3TPb0DhZ1HT4XZs4NP/Pu/D+t1S23aOaJrRCXPnB/833Ph4xsYtbMrBxmJjzay5LmTTgqERm1YTmXbrhwkI5J7KhTTKGGT7SIfyRqy8jK47rpg/H//FzZtCsaT5C0Ui3THc7ynz59FV21si6HK3gFOv78lNwlJjPK+Puatbgk+oUIxf0yYAIccEgiPXf5SDpIRyT0VimlStmM7lWtWBuJqsj2Ij388cBoCvb3wn/855JcspR6K8TpHVfHsucFRxRMeWc/IXd05yEiizV6/gereuCPh6uthzpyc5CMJ+NYprtA6RSlNKhTTpPrl4C+RvqnT6Z82jFYNpWDECLjmmmD81lup6Owb0kuW8ogiwF/fM5vu6uCo4mkPtOQmIdkv4bSzZh3yiza0iOynQjFNvNPOx6h3YlKuvTbUliLa3r3M/sv6Ib1cqa5RjOgYXcVz584MxE98ZD0j9vTkICOJWNCsjSwFwbOhZczqVynr1ai8lB4VimlQtm0LleuC/eo07ZykSZPgox8NhOc91oL1DQSvP5AS7KHo89SFc+ipiv3nXdXdz6l/aMlNQgJoI0vBmDcv9HspSnlvN6NXv5ajhERyR4ViGvhGE/tmzKJ/8tQcZFOgrrsuMP1Wu6ubGS+0pvQyle29VHSXVg9Fn/Yx1TzfFBxVPOmhddTt06hiLtR2djJrw8bgE54Gz5JjZmqTIxKmQjENajzrE7uO1mhiSubPh4svDoYfWpPSsX4JRxNLcA3YU+9toLcy9p94dVc/p/xxbY4yKm3zVrdQFvffcuvkSaHNLJJ/tE5RBFChOGzlW1qp2LAuENe08xB84QuB0OhNbUx6fXvSL1HqG1mi7RtXzQvvCm6mOvnBddS29XrukEzyTTuvmD83B5lIUhKNKKbpPHqRQqFCcZh80869sxoYmDg5B9kUuOOPh9NOC4QbH/JsAEjAeypLia1PjPaXixroq4gdTa3p7OPkP2lUMdt8J7KsmO85nUjyw1FH0V8VP6VexAAAIABJREFU+7ujat9ORmwKtkETSQczazGz183sVTNbFI6NN7NHzaw5/HVctvNSoThMZXt348pi/2fUaOIwfPGLgVD98l2MXb07qds1ohhr74QaXjzbM6r4x7XUtGtUMZv8I4oqFPNWZSW75x8dCI9brulnyagznXNHOueODf/8JeBx51wj8Hj456xSoThMbZd9lB3/+kP2Xf4xeg46FFdWFjqNRYbmvPPgsMMC4fkPBXeV+2hEMegvFzXQVx47qljX3seJDwWXTEhmjN21m0nbd8TE+svKWN3gOcJS8saug4I70lUoSpZdBNwe/v524H3ZTkCFYhq4UaPpOvUs9nz2y+z4tx8xMEGL04esrAw+//lAeNrLWxixpX3Q230jiqVyKksiuyfWsvjM6YH4qX9YS9UQm5pLahasCk47t8yaSXd1dQ6ykWTtOij4oX/ccu18liGpMLNFUY+rPNc44BEzWxz1/GTnXCtA+Oskz30ZpUIxzdzIUblOofD9zd/AtGkxIXMw75GWA9+XqIdiCU89R/z5/XPpjxtVHNHWy4kPa1QxG7SRpTDtXnAcLq5jwojNq6navTVHGUkB63POHRv1uM1zzcnOuaOB84BrzCy4aD8HVChK/qmqgs99LhCe9cxGqvYmPhlBPRQT2zWplpdPmxaIn3Z/C7QPPlIrw6ONLIWpr240+2YeGoiPW/FSDrKRYuec2xT+uhW4F1gIbDGzqQDhr1n/lJLxQtHMzjWz5Wa20swCizDN7P+Z2ZLw41kzOyLTOUkBuOoqemsrYkLlvQPMfSLxCJh6KB7YExfPpb8s9n+Lkft64dZbc5RRiXBOG1kKmG+d4lhNP0uamdkIMxsV+R5oApYC9wNXhC+7Argv27lltFA0s3Lgx4SGUQ8FLjez+I9na4DTnXPvBL4F+IZjpdSMGUPL6cGTRRqeWEd5t39dnaadD2znlDpePdVzWtB3vgMdHdlPqERM27yFke2x//t2VlezfkZw3ajkn92eQnG8NrRI+k0Gnjaz14AXgT865x4C/g04x8yagXPCP2dVpkcUFwIrnXOrnXM9wB2EdvDs55x71jm3K/zj80Cwl4eUpNXvms1A3Lq6qvZeZj3tOQaNA4woyn5PvH8uA/EDrFu2wM9+lpN8SoFvNHHl3AYGyrXypxDs9GxoGb1mCWXd+nAl6ROuk44IPw5zzt0Yju9wzp3tnGsMf92Z7dwqBr9kWKYD66N+3gAcqHfMlcCffE+EdwBdBVBVpTVnpaBrXA3rT5jG7GdiC8N5j7TQcsZMXNwfWm9rHI0oxtg+fQSvnTyVo56OO0P7ppvgU5+CmprcJFbEFjRrI0sh66qfQdf4qdTsfPvfTFl/L2NXvcLOQ4PH/KXTslu3pHR9z57+/V9Tufewq3VAhCSW6Y+0vsVh3vOPzOxMQoXi9b7nnXO3RXYLVVRkur6VfLHq3IZAbMT2TqYtCv4S1Ihicp642DOq2NoKv/hFTvIpdt6NLI1an1gwzLyjilqnKKUi04XiBiB6odkMYFP8RWb2TuDnwEXOuR3xz0vp2jdtJJuPmBiIz39oTeDMVfVQTM7WmSN5/YQpwSf+7d+gO/GuckldRW8fc1uCxyVqI0th8a1TVONtKRWZLhRfAhrNrMHMqoDLCO3g2c/MZgH3AB9xzq3IcD5SgJo9o4pj1+2l/s2opRrOeaee21Uoej3xAc/U54YN8KtfZT2XYjZ73XqqemOPStw1ZjTb6ifkKCMZCm/j7RUvwcBADrIRya6MForOuT7gWuBh4E3gTufcMjO72syuDl92AzABuCX6IGyRiJ2N49g5d0wg3vjQ21N6VW3BHop9VWX0jNJ6Vp/Ns0fx+vGeBv//8i/Q05P9hIqUbyNL8/x5atlUYPbNOpS+mhExscqOvYzc8FaOMhLJnoxvu3POPeicW+Ccmxe1i+dW59yt4e8/4ZwbFz4EO/ogbJEQM1Z6RhUnLdvB6PV7Af9Gls4J6qF4II9/wDP9uW4d/M//ZD+ZIqUTWYqDK69gd+NxgbiO85NSoP4MUhBaj5pM26S6QHz+Q2sAqNVGlpS1Noxm2bHB9Z/ceCPETZfK0OhEluLha7ytdYpSClQoSmEoM1a+e04gPP3FzdRu71Sz7SF6/BJP0bJmDfzf/2U/mSJT29HBzI2BvXusmKcRxULkXaeoEUUpASoUpWCsP2k6XXHnNpcNOOY91uLvoagRxUFtnDcGzj8/+MSNN1LWr4X6wzF/dQtlcTvzN02ZTNuokTnKSIZjd+PRDJSVx8Tqtq2jemdrgjtEioMKRSkYA1XlrDlrdiA++6kNjF27NxBXoZikr389GGtu5rSnl2c/lyKi852LS3/NSPbNOTwQ1/SzFDsVilJQ1pw5k76q2E/1Fd39jF+1O3Ctpp6TdMIJ0NQUCF/2uxc0qjgM/vWJmnYuZLsWaJ2ilB4VilJQekdWsfa05I4D14hiCm64IRCatXEnpzzXnINkioNGFIuPf0OL1ilKcVOhKAVn1TlzGCg7cNsb9VBM0cknw1lnBcKX3fk8NuA9dVMOYPzOXUzcsTMm1ldezuo5waUTUjh8G1pGtyylvLMtB9mIZIcKRSk4nfW1bDzOcwRd9DXqoZg6z6jinPU7OOkFjSqmqnFVcNq5ZdZMeqr14aWQdY+fSsfEWTExcwOMXbkYgMkTZzFtylwmx10jUsgqcp2AyFCsPLeBmS8k3m2oaechOP10OO00eOqpmPDldz7Ps8c34gYZxc01Cx+n5spy//l3QbOmnYvVroOOp27bupjYuOUvsuMdp3PjV3+Xo6xEMif3v1FFhmDvrNFsPTTxebnayDJEnlHFuS3bOf6lYOGTL8r7+rn8zj/xq099g/+98mtc/bPfMbKtI6c5eTeyNGojSzFQ420pNSoUpWCtPC94rF9Ex8TgKS6ShLPOgpNOCoQvv/N5cPm3VnHK5u3c/LXv8+Hf/on6nXsYu7eNCx/6K7f+/Y2c/tfFOcnZBga8U88aUSwOuw4OrlMc27wI6+/LQTYimadCUQrWtkMmsHvmKO9zGlEcIjPvqGLj6q0ct3hNDhJK7PS/LuaHn7+Jg5vXBp4bt2cfX/z+7fzzt3/C5C07sprXtNbNjOyIHdHsqKlhw7RpWc1DMqNt+kH0jhgTE6voamfUumU5ykgks1QoSuEySziqqDWKw9DUBAuD02t/kyejijWd3XzuR7/mi9+/nbrO7gNee8yrb3HL5/6FD/z+Mcr7+rOSn2/aeeW8BgbK9eu2KJSVsWvBcYGw2uRIsdJvLilom46dQseEmphYf2UZbVP+f3v3HSdVdf5x/PNsoy29g0gHaRZEhWAlBiN2UYFE0ZgYNaICgt1IDIoFbNFo7DWiKLZoggV/KihNQRBRkF4F6ewK287vj3tXZ2fuwu4yd2bL9/16zWtn7jk757mzd2aePfeec2olKaJKoJhexc5LNtBzXmzvXSK1X7aaB0ffzW8+Kvk1YdVzcrn4+be4/9p76BTQ+xhvmj+x8gucePtbXacolZMSRanQXGoK84Z2x0UMyP2+fxvyamhA/34ZMIAl7ZrEbP7dy58n7bq/M9+ayoQb7qXl+k2BdTY0acCMI2KXWCvUbuU6JtxwL5c98So1smPXBo8XrchS+QVdp1j/u5nlosddJN70bSoV3qbujZg69mgaL9zMzuaZ/LiX0dBSQma8dF5v/nrnW0U2d/1uPYcsWM1XBydunrh623Yw4qEX6TV3UbF1Pu7bk4cuHUR2rRocNXsBlz8+icabY5d1THGO0/77CX1mfsWjfzqHz486JK6xpuXm0m5FbK+lehQrl+3tD6MgNZ2U/Nyft1XfuoEam1bzUxPNoSiVixJFqRR2NctkV7PMZIdRqcw4sj1L2zSm/YqiPXi/e/nzhCWKh81bxDX/eIH623YGlu+ulsEjfzqHD0446ucJ1mce0YP53Tty/kvvcNp/PyE1YGWZRlu2c/PdT/L5ET3gyLPggJItC7kvbVeuIj2v6OjXLfXq8mPDBnF5fikfCjJqsL3dIdRfMqfI9vqLZylRlEpHp55FJJgZE8+LPcXW45u1dP96dbht5+Rw8bNvMPbvjxSbJC5t25Kr7hnNB/16x6zC81ON6jx+8UBGjruGpW1bFttMn9kLoEsXePBByN//wS7Bp53ba5WgSkjXKUpVoURRRIr12VEdWdEq9lT+716ZEV6jS5ZA374MfGtqsVXeOPV4Ro4bydqWTff6VN93OJDhd43iiQvPZHdxy+ft2gVXXw19+sC8efsTuQayVCGB8yku1shnqXyUKIpIsVyKMfG83jHbD12wmq7frI1/g88/Dz17wpw5gcXb6mRy642X8vgfziYvPb1ET1mQmsrrp/fj8vtvYHbPrsVXnD0bevWC0aMhK6ss0WsgSxWyLWCKnNqrF5GWtT0J0YiER4miiOzVtD4dWdUy9hq7IZPi2Ku4Ywecfz4MHer18AWYe3Bnht17HXMO71amJjY2aciYGy9l3MiL2FoveKJ28vNh/Hjo3p3D535VquevmZVNq7XrYrYvaa9EsTLKqduYrGZF/7bmHPUWz05SRCLhUKIoIntVkJrCxHNjT7MdPm8lnb+LTYxKbdYsOOwwePHFwOK81BSevOAMbrnlcrbWrxtYp8TMmNa3J5c+eBPv9u9bfL0VK/jbHfdw7X0PUW9r7OjpIB2XxfYmrmnejKxMzelZWQVOk6PTz1LJKFEUkX365OjOrG1eL2b7kEllv3jfChznTJ4FfftCQJIFsK5ZI0bdMYLJZ/4alxK/j6usWjV5+NJBjLp9OHQt/nT0sZ/N4NER13LS+1OxgoK9PmexA1mk0tKAFqkKlCiKyD4VpKYw8ZzY3pMjv1hOx+83lPr56m/ZxdjbXuPi56dB1HQyhaYe24ur7hnNkg6tS/38JbXooHYwdy6MHQvVqgXWyczK5srHnuLOv46l1erir8vstCRgIEtHJYqV2daDYq/frbd0LpaXk4RoRMKhRFFESuT/jj2I9U1jT/0OfqV0PSi9vljGP0c8z2FfrQqukJkJzz3HhKuH8lPNBKzZnZEBN90ECxZAv37FVuv23WIeHH0j50+cRHpObCKggSxVT1bz9uTULjorQGrOT9RZviBJEUlFZWatzOwjM1tkZgvN7Gp/+xgzW2tm8/zbgETHpkRRREokPy2Vl8+JPdXWZ/ZS2i3buM/fT8vN489PfsRtY9+g7o5iltDr1cvr4bvggv0Nt/Q6doQPPoBnn4WGwav7pOfnM/i1N3lo1I0cvGDhz9sbbt5Cw61bi9TNTU1leWtNvlypmbG1c8DpZ12nKKWXB1zjnOsC9AauMLPC62Luc84d6t/eTXRgShRFpMSmHteVHxrXidm+rxHQB6zZwn3XvcSZ/5lbfKVrr4Xp06FDh/0Ns+zMvJHX337LB8cdU2y1lus3cMdt4xj+0L+os2Nn4PyJy9scSG5GMXM3SqURmCjqOkUpJefceufcl/79ncAioPjVAhJIiaKIlFheeiqvDIz9Yuw743varNwU+wvO0f+DBTw46gXaLw8oB2jaFKZMgbvu8k4DlweNGnH/sEu58a83sLZ5s2KrnfjxpzwyfDSnvzMlpkwDWaqGrZ1jr91tNP8j6n2nZFGKSDOzORG3PxdX0czaAIcBhQfRMDObb2ZPmVn9BMRahBJFESmV9/t1ZVPD2HW1B0eNgK6VtZvrJ7zD8Iffp/qe4AErcw5rA/PnQ//+YYS63+b36Maw8XcwceAZ5KamBtapu3MXPRZ9G7Nd8ydWDTvaHkx+etGBUGl7sjny9nNp/OV7SYpKyqE851yviNtjQZXMLBN4DRjunNsBPAK0Bw4F1gMTEhaxT4miiJRKXnoak86O7VU8+rPFtFq9GYAu367joREvcOz0xYHPkZuWwmN/OI5bbz4LmjQJNd79lZuRwQuDz+Wqe+5gYedOJf499ShWDQXp1VjXd2DM9tScn+g5figtPp2UhKikIjKzdLwk8UXn3GQA59wPzrl851wB8DgQ++EbMiWKIlJqU07szub6RSeSTnHeGtCDJs3k7ptepummHYG/u6ZFfUbeOYQ3Tj8cl2KJCDcuVrdqyfW33cw/Lv0ju2rV3Gvd7BrVWduieYIik2RbPORmdrWIvbY2pSCfQx7+C63f/VcSopKKxMwMeBJY5Jy7N2J75AfJWcDXiY5NiaKIlFpuRhqvnhW71u1x077jwn9PJ7XABf7ee/26cdX437O0fdOwQwyFS0lhyokncNl9d/Nx39g59AotadeOglR9vFYVOXUbM3PM22xvd0hgedfnbqbjy+PABb8vRIC+wAVAv6ipcO42swVmNh84ARiR6MD0SSYiZfK//j3YUm/vPWuFsmpmcNfIAdx/5UnsrlFOBqzsh23163HP8GHceuNoNjRuHFM+84ieSYhKkimnTiNm3vIGP3YLHi3f4fV76fbkaCjIT3BkUhE456Y558w5d3DkVDjOuQuccz387ac759YnOjYliiJSJnuqpfPamb32WW9Rp+YMu/cCPj7moARElVhfHHYIV9w7jlfPOJWsGt7k4J/8qjf/O7H4ibul8sqvkckX17/EhiNPCSw/8INnOfSBS0jJ3ZPgyETKLi3ZAYhIxfXuSYdw3uTZgRNoFxi8cvaRvDi4D/lpwSOGK4M91avzzPmDeWHQQFLz89lTvXqyQ5IkKkivxtzhT9LtidEcOPX5mPLmM98mPXsHX458hvwasbMHiJQ36lEUkTLbUz24V/HHBrW4acw5PHf+0ZU6SYyUl56uJFE8KaksvGQC3585PLC40YKPOXLs2aTv2JzgwERKT4miiOyXyacfzid9vWlj8lOMT/t0ZNh9Q/nqYC1fJ1WYGUsG38SiC/4eWFxv6Vx6jzkVVhWz5rlIOaFTzyKyXwpSU7hz1Kn86+Jd3tq3UdPmiFRlK065jJza9enx6NWkRA1kyVz3PfTtC++9B126JClCkb1Tj6KIxMXWBplKEkUCrDt2EHOveZb89IBLE9asgWOOgVmzEh+YSAkoURQREQnZxsNPYvaNr5Bbs05s4ebN0K8fvP9+4gMT2QcliiIiIgmwtUsfZt76JrvrBSxbmZUFp5wCk7Tkn5QvShRFREQSZGfr7swc8x+ym7SJLczNhUGD4NFHEx6XSHGUKIqIiCRQdrO2zPjb2+w4sFtsoXNw+eUwdqyW/JNyQYmiiIhIgu2p34yZt74JRx8dXOGWW2g26RYoKEhsYCJRlCiKiIgkQV6tujBlCpx6amB5w4+eoOWzV0J+boIjE/mFEkUREZFkqVkTJk+GoUMDi+vNeo0DH70Iy8lOcGAiHiWKIiIiyZSeDk8/DSNHBhbX/vpD2jwwiJSsbQkOTESJooiISPKlpMD48TBuXGBxzWWzaXvvmaRt25DgwKSqU6IoIiJSHpjB9dfDY495iWOU6uu+pe3408jYuDwJwUlVpURRRESkPLnkEnjlFQrSMmKKMjavpu3406i+ekESApOqSImiiIhIeTNwIKuu+Df51WLXT0/b+SNt7j2bmos/S0JgUtUoURQRESmHsg46mhUjXiMvs0FMWerunbT+xxBqf/W/JEQmVYkSRRERkXJqd+tDWX7NW+Q0aBlTlpK3h1b/uph6n72UhMikqlCiKCIiUo7lNOvA8lFvs7tZx5gycwW0fH4EDd97OAmRSVWgRFFERKScy6vfghXXvEl2m56B5c1e/zvX79qc4KikKlCiKCIiUgHkZzZg5dWT2NXl+MDyy7K38wxweM5uUndsAucSGZ5UUmnJDkBERERKpqB6LVb95TlaPnMldb94M6b8QuDCbevguh7kV69NTpO25DRpx54mbclp0p6cJu3IadKW/Fr1Ex+8VEhKFEVERCoQl5bBmov/SX6t+jT45Jli66Xu3kmNVfOpsWp+TFlerfrkNPaSSDYdDB07/nKrUyfE6KWiUaIoIiJS0aSksn7wOPJqN6TJOxNK/etpWVtJy9pKzRVfwqxXixY2afJL0tip0y/3O3SAWrHzOkrlpkRRRESkIjJj06mjyc9sQLNJf8UK8uPzvBs3erfp02PLWrSITSA7doT27aF69fi0L+WKEkUREZEKbMvxf2RntxOZcudJtMjeRrfUdDqlpJKSuzv+ja1b590+/rjodjNo1cpLJDMzoXbtoj/3ta3wfq1agetcS/IoURQREangchu3ZkJmA1Zmb6N1w1a8c+s00ratp9rG5WRsWkbGxmVk/LCMapuWk75pBSn5ufENwDlYtcq77a9atYpPJEu6rWVLaNhw/2OR8BNFM/st8ACQCjzhnLszqtz88gFANnCRc+7LsOMSERGptFJSyGvQkrwGLck66OiiZQX5pG9ZQ8bG5VTbuIzmTTfAkiXebflyyI/TKeyyysrybj/8UPbnuO02uOWW+MWUAPvKl5Il1ETRzFKBh4HfAGuA2Wb2lnPum4hqJwMd/dtRwCP+TxEREYm3lFRyG7Umt1FrsroeT/PLmv5SlpsLK1Z4SePixb8kkEuWwMqVFWduxszMZEdQKiXMl5Ii7B7FI4HvnXPLAMxsInAGELnjZwDPOeccMMPM6plZc+fc+pBjExERkUjp6b8MUBkwoGjZnj2wbFlwErlmTXLiLU7t2smOoLRKki8lRdiJYktgdcTjNcT2FgbVaQkoURQRESkvqlWDLl28W7TsbO+09bZtsGsX7Nzp/Yy8H7Qtujw7Oz6xVrAeRUqWLyWFuRC7kc3sXOAk59yf/McXAEc6566MqPMOMM45N81//CFwrXPui6jn+jPwZ/9hT+Cn0AIvuzQgrwq3Xx5iUPtqX+2r/WRKdgxqP/nHQJAaQOT4i8ecc48VPihJvpQsYfcorgFaRTw+AFhXhjr4L+hj0dvLEzOb45zrVVXbLw8xqH21r/bVfrLaLw8xqP3kHwNlVKJcKBnCnqxoNtDRzNqaWQYwGHgrqs5bwFDz9Aa26/pEERERqUJKki8lRag9is65PDMbBkzBG+79lHNuoZld5pc/CryLNzXO93jT4/whzJhEREREypPi8qUkhwUkYB5F59y7eMlg5LZHI+474Iqw40iQZJ8aT3b7kPwY1L7aV/tqP5mSHYPar6CC8qXyINTBLCIiIiJScWlBRREREREJpESxlMzsPjMbHvF4ipk9EfF4gpmNNLM0M/vRzMaFFEczM5toZkvN7Bsze9fMOvllI8xst5nVDaPtqDh2+T/bmNnXYbfnt+XM7PmIx2lmtsnM/hNV700z+zyE9hua2Tz/tsHM1vr3l5rZcjNr4Ner7z9uHUIMzswmRDweZWZjzOz46H32X58fzKx5nGPI9/f7azObZGY1I9oL7dj32yhu//ub2ef+0qCYWaof46/i3P4B/vG1xP+7P2BmGf7rH30cPmNm58Sz/YjnLvwbFN7aBMUQUttNzezfZrbMzL7wX/ezIsof8N8boX3PmNlZ/rFwkP/4iqjX42u/PGDiv/1ue9deykLf94i2At8L/v0xZjYqpHYLj72FZvaV/72X4pcdb2bbo/4WJ4YUR+R3kDOzyOn3HjKzi8JotypRolh6nwG/AvDfFI2AbhHlvwKmA/2B74DzCr+04sV/vteB/3POtXfOdQVuBArXYRqCN4LqrGKeoqLLArqbWQ3/8W+AtZEVzKwe3nyb9cysbTwbd85tds4d6pw7FHgUuM9/3B5vCcrC9TnvxJsra2U82/ftAc42s0ZR2z8BDjCzNhHbTgS+DmE2gZ/8/e4O5ACX+dtDO/YjBO6/c+49YCXwR3/TlcBs59xn8WrY36fJwBvOuY5AJyATuD1ebZRC4d+g8LYiEY36r8EbwCfOuXbOucPxRmke4Jen4H3+rAaODTGUIcA0v22ccw9Hvh54o0ZfdM4tCjGGIhK474WK+ywIW+Gx1w3vM3gAcGtE+adRx+YHCYhpI3C1eaOGJU6UKJbedPxEES9B/BrY6fceVQO6AHPxPsAeAFYBveMcwwlAbtSgoHnOuU/NrD3el9bNfgyV1X+BU/z7Q4CXosoHAm8DE/G/RBLkPqC3eb3ORwMT9lG/rPLwLtoeEbnROVcATAIGRWweTOzrE2+fAh38+2Ee+4UC9983ArjBzLoBw4Dr4tx2P2C3c+5pAOdcvt/mxUDNOLdVXvUDcqI+g1Y65/7hPzwB77PxEUL6HDKzTKAv3j8FMe9xMzsWOA/4Sxjt70Xo+x5lb++FhHDObcRbEGNYiP8clsQm4EPgwiTGUOkoUSwl59w6IM/MDsRLGD8HZgJ9gF7AfLyh7b8G/oP3BR3vD4vuwBfFlBUmTZ8Cnc2sSZzbLi8mAoPNrDpwMN7fIFLh6xDG618s51wuMBovYRzunMsJsbmHgd9b7CUGL+F/cfr/vAwAXgsrCDNLA04GFvi9vGEe+5EC99/vOb0f77051jm3Jc7tdiPq/eec24GXGHcAjok85QacHuf2I9WIaOv1ENuJ1o2iq0xEK3z/vQ6cambpIcRwJvA/59xiYIuZ9Sws8M8oPA1c6P9tEikR+x6tuM+ChPHXKE4BCr9zirwP/E6MRLgTuMbMUhPUXqWnRLFsCnsVCxPFzyMefwacCnzknMvG+4I+K4EH7WBgot+zNBk4N0HtJpRzbj7QBu9Duch0AmbWFO8Le5r/JZJnZt0TGN7JeGuVh9qm/wX4HHBV1PbZQKaZdfZjmeGc2xpCCDX8RGgOXpL0JAk89ovbf9/DQKpz7pkQmjYgaLqIwu1FTrkR7qS5kaeek3apiZk97F+nNts/7TcA79T8Drx/4vqH0OwQvH8Y8X9G/lPyCPCCc256CO0WK4H7XsQ+3guJFNmbGH3qeWkiAnDOLQdmAb9LRHtVQejzKFZShdcp9sA7xbAauAbYATyFN2l4XzNb4ddviHc6Il7XaCwEYi6ON7ODgY7A+37vfwawDO9LszJ6CxgPHI/3GhcaBNQHlvuvQx28BPrmsAM/6+g8AAAEc0lEQVQys0PxrtfpDUwzs4khrzR0P17PztNR2wtPuXchvNPOP/mJ0M/MbAjhHvvRAvffOVdgZmHN/bUQ79KGn5lZHbzltxLyZVgOFHkNnHNX+NfIzQF+C9TF62EG73R8NvBOvBo3s4Z4p7+7+3/nVMCZ2bXAULx/Ii+IV3ulEPq+70VxnwUJYWbtgHy86wTjPniolO4AXsW7Zlv2k3oUy2Y6Xs/JFudcvn9qqx7e6eev8K5NO9A518Y51wZvQvF4noKbClQzs0sKN5jZEXjXhY0pbNc51wJoaSGMui0nngJuc84tiNo+BPhtxOtfeKF9qPxrcx7BO+W8CrgHL5ENjX/svcIvgzcKvQScj/dlmpBloPxkKexjv4i97H+YPgRqmtlQ8EZW412L+gxeUlAVTAWqm9nlEdsKr88cAvwp4hhoC/Q3f1R8nJwDPOeca+230wpYjjd45Hbg9865vDi2V1KJ2PdASXovAGBmjfEG9j3kysHkzM65b4Fv8L6nZT8pUSybBXijnWdEbduO98U81Tm3J6LsTeB0/3qx/ea/Ec8CfmPe1BwLgTF4PWvR1ym9TuIGc3Q2szURt1BPezvn1jjnHojc5o/2PZCIv41/KmKHmR0VZjzAJcAq59z7/uN/AgeZ2XEhtzsB73j8mXPuG7ykZapzLivk9gudTcjHfjFi9j9MEe+/c81sCbAY2I0380B58euo92KfeD65/xqcCRxn3hRQs4Bn8Ua9nkRED5p//E0DTotjCEOI/ax7DbgIqAVMjro+7pg4tl2oZtRrfCOJ2fe9iX4vpOGNig5D4fWxC/HOGLwH/C2iPPoaxVCmiNqL2/FH4cv+0cosIiIilZA/wOlx5y0NJ1Im6lEUERGpZMxsAVCA19MnUmbqURQRERGRQOpRFBEREZFAShRFREREJJASRREREREJpERRRKoUMxteknntSlpPRKQy02AWEalS/FVjejnnfoxHPRGRykw9iiJSaZlZLTN7x1+H+GszuxVoAXxkZh/5dR4xszlmttDM/uZvuyqgXn8z+9zMvjSzSWaWmaz9EhFJFPUoikilZWYD8ZZzvMR/XBdvmc2fewrNrIFzbou/FN+HwFXOufmRPYr+OsaTgZOdc1lmdh1QzTl3WzL2S0QkUdSjKCKV2QLgRDO7y8yOcc5tD6hznpl9CcwFugFdA+r09rdPN7N5wIVAZV1DXUTkZ2nJDkBEJCzOucVmdjgwABhnZkVWqTCztsAo4Ajn3FYzewaoHvBUBrzvnBsSdswiIuWJehRFpNIysxZAtnPuBWA80BPYCdT2q9QBsoDtZtYUODni1yPrzQD6mlkH/3lrmlmnBOyCiEhSqUdRRCqzHsA9ZlYA5AKXA32A/5rZeufcCWY2F1gILAOmR/zuY1H1LgJeMrNqfvnNwOJE7YiISDJoMIuIiIiIBNKpZxEREREJpERRRERERAIpURQRERGRQEoURURERCSQEkURERERCaREUUREREQCKVEUERERkUBKFEVEREQk0P8DcdYOQPHeuBYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_order = jobs.groupby('state').mean().sort_values(by='high_salary', ascending=False)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='state', y='high_salary', data=jobs, order=state_order.index, \n",
    "            errcolor='k')\n",
    "plt2 = plt.twinx()\n",
    "plt2.set_ylim([0, 210])\n",
    "plt2.plot(jobs.groupby('state').size().reindex(state_order.index), lw=5, c='r')\n",
    "plt2.set_ylabel('job frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5046"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_accuracy = round(jobs['high_salary'].value_counts(normalize=True).max(), 4)\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "### Create a classification model to predict High/Low salary. \n",
    "\n",
    "\n",
    "- Start by ONLY using the location as a feature.\n",
    "- Use at least two different classifiers you find suitable.\n",
    "- Remember that scaling your features might be necessary.\n",
    "- Display the coefficients/feature importances and write a short summary of what they mean.\n",
    "- Create a few new variables in your dataframe to represent interesting features of a job title (e.g. whether 'Senior' or 'Manager' is in the title).\n",
    "- Incorporate other text features from the title or summary that you believe will predict the salary.\n",
    "- Then build new classification models including also those features. Do they add any value?\n",
    "- Tune your models by testing parameter ranges, regularization strengths, etc. Discuss how that affects your models.\n",
    "- Discuss model coefficients or feature importances as applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_union, make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_Albany</th>\n",
       "      <th>city_Alpharetta</th>\n",
       "      <th>city_Anaheim</th>\n",
       "      <th>city_Andover</th>\n",
       "      <th>city_Arlington Heights</th>\n",
       "      <th>city_Atlanta</th>\n",
       "      <th>city_Austin</th>\n",
       "      <th>city_Avondale</th>\n",
       "      <th>city_Baldwinsville</th>\n",
       "      <th>city_Bellevue</th>\n",
       "      <th>...</th>\n",
       "      <th>state_IN</th>\n",
       "      <th>state_LA</th>\n",
       "      <th>state_MA</th>\n",
       "      <th>state_NJ</th>\n",
       "      <th>state_NV</th>\n",
       "      <th>state_NY</th>\n",
       "      <th>state_OH</th>\n",
       "      <th>state_PA</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_WA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_Albany  city_Alpharetta  city_Anaheim  city_Andover  \\\n",
       "0            0                0             0             0   \n",
       "\n",
       "   city_Arlington Heights  city_Atlanta  city_Austin  city_Avondale  \\\n",
       "0                       0             0            0              0   \n",
       "\n",
       "   city_Baldwinsville  city_Bellevue  ...  state_IN  state_LA  state_MA  \\\n",
       "0                   0              0  ...         0         0         0   \n",
       "\n",
       "   state_NJ  state_NV  state_NY  state_OH  state_PA  state_TX  state_WA  \n",
       "0         0         0         1         0         0         0         0  \n",
       "\n",
       "[1 rows x 164 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = jobs[['city', 'state', 'high_salary']].copy()\n",
    "X = pd.get_dummies(X, prefix=['city', 'state'], columns=['city', 'state'], drop_first=True)\n",
    "y = X.pop('high_salary')\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropDummyfierPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"The transformer allows to drop and dummify columns.\"\"\"\n",
    "    \n",
    "    def __init__(self, columns_to_drop=None, columns_to_dummify=None, prefix=None): #, drop_first=False):\n",
    "        self._feature_names = []\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "        self.columns_to_dummify = columns_to_dummify\n",
    "        self.prefix = prefix\n",
    "        # self.drop_first = drop_first\n",
    "        self.X_new = None  \n",
    "        \n",
    "    def _drop_unused_cols(self, X):\n",
    "        \"\"\"try to drop each selected column by its own\"\"\"\n",
    "        for col in self.columns_to_drop:\n",
    "            try:\n",
    "                X = X.drop(col, axis=1)\n",
    "            except:\n",
    "                pass\n",
    "        return X\n",
    "\n",
    "    def _make_dummy_cols(self, X):\n",
    "        \"\"\"dummify categorical features\"\"\"\n",
    "        if len(self.prefix) != len(self.columns_to_dummify):\n",
    "            self.prefix = None\n",
    "        X = pd.get_dummies(X, columns=self.columns_to_dummify, prefix=self.prefix) #, drop_first=self.drop_first)\n",
    "        return X\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        \"\"\"return feature names\"\"\"\n",
    "        return self._feature_names\n",
    "    \n",
    "    def transform(self, X, *args):\n",
    "        X = self._make_dummy_cols(X)\n",
    "        # compare features which are created when the dataset is fitted (training set) with the\n",
    "        # features when it is transformed (test set). Each feature that is not included in the\n",
    "        # the process of fitting is discareded. Thus, in the case of fitting training data and\n",
    "        # afterwards transforming the test data both possess the same features.\n",
    "        if isinstance(self.X_new, pd.DataFrame):\n",
    "            cols_union = list(set(self.X_new) & set(X))  \n",
    "            cols_diff = list(set(self.X_new) - set(X))  \n",
    "            X[cols_diff] = 0  \n",
    "            X = pd.concat([X[cols_union], X[cols_diff]], axis=1)  \n",
    "        X = self._drop_unused_cols(X)\n",
    "        self._feature_names = X.columns\n",
    "        return X\n",
    "    \n",
    "    def fit(self, X, *args):\n",
    "        self.X_new = self._make_dummy_cols(X)  \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first process only the location features are used to predict high (above median) salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('prep_dum', DropDummyfierPreprocessor(columns_to_drop=['job_title', 'company', 'summary', 'high_salary'], \n",
    "                                                        columns_to_dummify=['state', 'city'], \n",
    "                                                        prefix=['state', 'city'])),\n",
    "                 ('prep_scale', StandardScaler())])\n",
    "X = pipe.fit_transform(jobs)\n",
    "y = jobs['high_salary'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'estimator': [DecisionTreeClassifier(), \n",
    "                  LogisticRegression(solver='liblinear'),\n",
    "                  KNeighborsClassifier(),\n",
    "                 ],\n",
    "    \n",
    "    'param_grid': [\n",
    "        {\n",
    "            'max_depth': [1, 2, 3],\n",
    "            'min_samples_split': [2, 3, 4, 20,  30, 50],\n",
    "            'ccp_alpha': [0, 0.001, 0.005, 0.01]\n",
    "        },\n",
    "        {\n",
    "            'C': np.logspace(-4, 4, 15), \n",
    "            'penalty': ['l2', 'l1'],\n",
    "        },\n",
    "        {\n",
    "            'n_neighbors': range(3, 100, 2),\n",
    "            'weights': ['uniform', 'distance']\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimators_scores(X_train, y_train, X_test=None, y_test=None, \n",
    "                          models=[], params=[], verbose=1, n_jobs=2, cv=5, \n",
    "                          filenames=[], grid=True, pipeline_classifier=None):\n",
    "    \"\"\"\n",
    "    This function fits a list of models with all possible combinations given by the\n",
    "    params list either by applying grid search or randmized search and returns them. \n",
    "    The models are saved if the number of names for the filenames parameter matches \n",
    "    with the number of models. \n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    X_train (pd.DataFrame): training data frame\n",
    "    y_train (pd.Series): training target values\n",
    "    X_test (pd.DataFrame|default=None): test set data frame\n",
    "    y_test (pd.Series|default=None): test target values\n",
    "    models (list|default=[]): list of classifiers\n",
    "    params (list|default=[]): list of dictionaries with parameters of each classifier for grid search or \n",
    "                              randomized search\n",
    "    verbose (int|default=1): verbose parameter of the classifiers\n",
    "    n_jobs (int|default=2): n_jobs parameter of the classifiers\n",
    "    cv (int|cross-validation generator|default=5): cv parameter of the classifiers\n",
    "    filenames (list|default=[]): a list of names to save the models, if empty then models won't be saved\n",
    "    grid (boolean|default=True): True for using GridSearchCV else RandomizedSearchCV\n",
    "    pipeline_classifier (str|default=None): prefix for grid search or randomized search in the parameter name \n",
    "                                            if a pipeline is used (step name of the classifier) \n",
    "                                    \n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    best_estimators (list): a list of best estimators for each model\n",
    "    \"\"\"\n",
    "    best_estimators = []\n",
    "    save_file = False\n",
    "    if filenames and len(filenames) == len(models) and all(isinstance(elem, str) for elem in filenames):\n",
    "        save_file = True\n",
    "    \n",
    "    param_obj = None\n",
    "    searchCV = None\n",
    "    if grid:\n",
    "        searchCV = GridSearchCV\n",
    "        param_obj = 'param_grid'\n",
    "    else: \n",
    "        searchCV = RandomizedSearchCV\n",
    "        param_obj = 'param_distributions'\n",
    "        \n",
    "    for i, _ in enumerate(models):\n",
    "        \n",
    "        if save_file and os.path.isfile(f'./models/{filenames[i]}.sav'):\n",
    "            print('***********************')\n",
    "            print(f'{filenames[i]}.sav exists')\n",
    "            print('***********************')\n",
    "            m = joblib.load(f'./models/{filenames[i]}.sav')\n",
    "            best_estimators.append(m)\n",
    "            continue\n",
    "            \n",
    "        p = {param_obj: params[i]}\n",
    "        gs = searchCV(estimator=models[i], \n",
    "                          verbose = verbose,\n",
    "                          n_jobs = n_jobs,\n",
    "                          cv = cv,\n",
    "                          **p)\n",
    "        gs.fit(X_train, y_train)\n",
    "        model_name = type(gs.estimator).__name__ if pipeline_classifier == None \\\n",
    "                                                 else type(gs.estimator.named_steps['classifier']).__name__\n",
    "        print('--------------------------------------------------------')\n",
    "        print('{model} - Accuracy score: {score}'.format(model=model_name,\n",
    "                                                         score=gs.score(X_train, y_train).round(4)))\n",
    "        print('{model} - CV training score: {score}'.format(model=model_name, \n",
    "                                                            score=gs.best_score_.round(4)))\n",
    "        \n",
    "        if isinstance(X_test, (pd.DataFrame, np.ndarray)) and isinstance(y_test, (pd.Series, np.ndarray)):\n",
    "            print('{model} - CV test score: {score}'.format(model=model_name,\n",
    "                                                            score=gs.score(X_test, y_test).round(4)))\n",
    "        print('--------------------------------------------------------')\n",
    "        \n",
    "        best_estimators.append(gs)\n",
    "        \n",
    "        if save_file:\n",
    "            joblib.dump(gs, f'./models/{filenames[i]}.sav')\n",
    "            print('***********************')\n",
    "            print(f'{filenames[i]}.sav saved')\n",
    "            print('***********************')\n",
    "                \n",
    "    return best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = get_estimators_scores(X_train, y_train, X_test, y_test,\n",
    "                                  models = model_params['estimator'], \n",
    "                                  params = model_params['param_grid'],\n",
    "                                  cv = skf,\n",
    "                                  filenames = ['dtc_location_only', \n",
    "                                               'lr_location_only', \n",
    "                                               'knn_location_only'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_score(X_train, y_train, X_test=None, y_test=None, model=None, classifier_name=None):\n",
    "    \"\"\"Loads model and prints its results.\"\"\"   \n",
    "    if model:\n",
    "        if classifier_name:\n",
    "            model_name = model.best_estimator_.named_steps[classifier_name].__class__.__name__\n",
    "        else:\n",
    "            model_name = model.best_estimator_.__class__.__name__\n",
    "        print('--------------------------------------------------------')\n",
    "        print('{model} - Accuracy score: {score}'.format(model=model_name,\n",
    "                                                             score=model.score(X_train, y_train).round(4)))\n",
    "        print('{model} - CV training score: {score}'.format(model=model_name, \n",
    "                                                                score=model.best_score_.round(4)))\n",
    "\n",
    "        if isinstance(X_test, (pd.DataFrame, np.ndarray)) and isinstance(y_test, (pd.Series, np.ndarray)):\n",
    "            print('{model} - Test score: {score}'.format(model=model_name,\n",
    "                                                                score=model.score(X_test, y_test).round(4)))\n",
    "        print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['dtc_location_only', \n",
    "               'lr_location_only', \n",
    "               'knn_location_only']\n",
    "models = [joblib.load(f'./models/{m}.sav') for m in model_names]\n",
    "\n",
    "for m in models:\n",
    "    print_model_score(X_train, y_train, X_test, y_test, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClassifier:\n",
    "- Feature Importance is computed as the total reduction of the criterion brought by that feature. Because the default setting for that classifier was used, it refers to the gini score. The chart below shows that San Francisco has the highest salary income of all cities where at least 30 jobs are offered. The chart above indicates that the state Washington has the highest salary income in total. From this aspect the feature importances from the decision tree make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "pd.DataFrame(list(zip(pipe.named_steps['prep_dum'].get_feature_names(), \n",
    "                      models[0].best_estimator_.feature_importances_)), \n",
    "             columns=['Feature', 'Importance']\n",
    "            ).sort_values(by='Importance', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show mean salary income of cities which offer at least 30 jobs\n",
    "city_order = jobs.groupby('city').agg({'company': 'count'}).company > 20\n",
    "city_order\n",
    "\n",
    "cities = jobs.groupby('city').agg({lambda x: x.count() > 30})['company']\n",
    "cities_idx = cities[cities.values.ravel()].index\n",
    "\n",
    "cities_above_30_jobs = jobs[jobs['city'].isin(cities_idx)].groupby('city')[['high_salary']] \\\n",
    "                           .mean().sort_values('high_salary', ascending=False)\n",
    "cities_above_30_jobs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.barplot(x='city', y='high_salary', data=jobs, order=cities_above_30_jobs.index,\n",
    "            errcolor='k')\n",
    "plt2 = plt.twinx()\n",
    "plt2.set_ylim([0, 210])\n",
    "plt2.plot(jobs.groupby('city').size().reindex(cities_above_30_jobs.index), lw=5, c='r')\n",
    "plt2.set_ylabel('job frequency')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "plt2.axhline(y=30, xmin=0, xmax=10, lw=2, c='b', zorder=0)\n",
    "plt2.text(-0.5, 18, '30 jobs', fontsize=14, c='b', bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression:\n",
    "- The logistc regression is using follwing link function:\n",
    "$$P(y=1|X)=\\frac{1}{1+e^{-z}},$$\n",
    "with $z=\\beta_0+\\beta_{1}X_{1}+...+\\beta_{n}X_{n}$ which means that a higher z value increases the probability of predicting class 1 and lower z values increase the probability to predict class 0.\n",
    "\n",
    "The first two coefficients of the feature importance show the same behaviour as the decision tree classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-2, 2, 100)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "plt.plot(x, np.exp(-x), c='g')\n",
    "plt.axvline(0, lw=1, ls='--')\n",
    "plt.axhline(1, lw=1, ls='--')\n",
    "plt.title(r'function: $e^{-z}$')\n",
    "plt.subplot(122)\n",
    "x = np.linspace(-10, 10, 100)\n",
    "y = 1/(1 + np.exp(-x))  \n",
    "plt.plot(x, y, c='g')\n",
    "plt.hlines(1, -10, 10, lw=1, ls='--')\n",
    "plt.hlines(0.5, -10, 10, lw=1, ls='--', colors='b')\n",
    "plt.hlines(0, -10, 10, lw=1, ls='--')\n",
    "plt.title('sigmoid function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "cols = pipe.named_steps['prep_dum'].get_feature_names()\n",
    "pd.DataFrame({'Feature': cols, \n",
    "              'Coefficient': models[1].best_estimator_.coef_[0], \n",
    "              'Abs_Coefficient': abs(models[1].best_estimator_.coef_[0])}\n",
    "            ).sort_values(by='Abs_Coefficient', ascending=False).drop(['Abs_Coefficient'], axis=1).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead using pipeline\n",
    "\n",
    "# X = jobs.copy()\n",
    "# y = X.pop('high_salary')\n",
    "# #X.reset_index(inplace=True)\n",
    "# X.drop(columns=['summary'], inplace=True)\n",
    "# X = pd.get_dummies(X, columns=['company', 'city', 'state'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super().build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "        \n",
    "        \n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super().build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sparse2DenseTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, *args): #Y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test demonstration of StemmedCountVectorizer and StemmedTfidfVectorizer\n",
    "\n",
    "# test_text = 'walks walked walking walker walkkt Walking'\n",
    "\n",
    "# stem_cvec = StemmedCountVectorizer(analyzer=\"word\", stop_words='english')\n",
    "\n",
    "# stem_tvec = StemmedTfidfVectorizer(analyzer=\"word\", \n",
    "#                                   stop_words='english')\n",
    "#                                   #ngram_range=(1,2))\n",
    "\n",
    "\n",
    "# display(pd.DataFrame(stem_cvec.fit_transform([test_text]).toarray(), \n",
    "#                      columns=stem_cvec.get_feature_names()))\n",
    "# display(pd.DataFrame(stem_tvec.fit_transform([test_text]).toarray(),\n",
    "#                      columns=stem_tvec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attrs = jobs.drop(['high_salary'], axis=1).select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_attrs = jobs.drop(['high_salary', 'summary', 'job_title'], axis=1).select_dtypes(include=['object']).columns\n",
    "text_attr = 'job_title'\n",
    "\n",
    "# so far no numerical features\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "text_pipeline = Pipeline([\n",
    "    ('tvec', StemmedTfidfVectorizer(analyzer='word', stop_words='english', max_df=0.3, \n",
    "                                    max_features=200, ngram_range=(1,2))),\n",
    "    ('dense', Sparse2DenseTransformer())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attrs),\n",
    "    ('text', text_pipeline, text_attr),\n",
    "    ('cat', cat_pipeline, cat_attrs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = jobs.copy()\n",
    "y = X.pop('high_salary')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    stratify=y, random_state=1)\n",
    "\n",
    "# X_train = preprocessor.fit_transform(X_train)\n",
    "# X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'estimator': [DecisionTreeClassifier(), \n",
    "                  LogisticRegression(solver='liblinear'),\n",
    "                  KNeighborsClassifier(),\n",
    "                  SVC(probability=True),\n",
    "                  RandomForestClassifier(),\n",
    "                  AdaBoostClassifier(),  # base estimator -> decision tree\n",
    "                  GradientBoostingClassifier()\n",
    "                 ],\n",
    "    \n",
    "    'file_names': ['dtc_job_titles',\n",
    "                   'lr_job_titles',\n",
    "                   'knn_job_titles',\n",
    "                   'svc_job_titles',\n",
    "                   'rfc_job_titles',\n",
    "                   'abc_job_titles',\n",
    "                   'gbc_job_titles'\n",
    "                  ],\n",
    "    \n",
    "    'param_distributions': [\n",
    "        { # DecisionTreeClassifier\n",
    "            'classifier__max_depth': [2, 3, 5, 8, 10],\n",
    "            'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'classifier__min_samples_split': [2, 4, 20, 30],\n",
    "            'classifier__ccp_alpha': [0, 0.001, 0.005, 0.01, 0.1],\n",
    "            'classifier__criterion': ['gini', 'entropy']\n",
    "        },\n",
    "        { # LogisticRegression\n",
    "            'classifier__C': np.logspace(-4, 4, 15), \n",
    "            'classifier__penalty': ['l2', 'l1'],\n",
    "        },\n",
    "        { # KNeighborsClassifier\n",
    "            'classifier__n_neighbors': [3, 5, 7, 9, 15, 25, 45],\n",
    "            'classifier__weights': ['uniform', 'distance'],\n",
    "            'classifier__leaf_size': [20, 30, 40]\n",
    "        },\n",
    "        { # SVC\n",
    "            'classifier__C': [0.025, 0.1, 0.5, 1, 100],\n",
    "            'classifier__kernel': ['linear', 'poly', 'rbf']\n",
    "        },\n",
    "        { # RandomForestClassifier\n",
    "            'classifier__n_estimators': [100, 200, 400],\n",
    "            'classifier__max_depth': [2, 3, 5, 8, 10],\n",
    "            'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'classifier__min_samples_split': [2, 4, 20],\n",
    "            'classifier__ccp_alpha': [0, 0.001, 0.005, 0.01, 0.1],\n",
    "            'classifier__criterion': ['gini', 'entropy']\n",
    "        },\n",
    "        { # AdaBoostClassifier\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__learning_rate': [0.1, 0.5, 1.]\n",
    "        },\n",
    "        { # GradientBoostingClassifier\n",
    "            'classifier__n_estimators': [100, 200, 400],\n",
    "            'classifier__min_samples_split': [2, 4, 20],\n",
    "            'classifier__max_depth': [2, 3, 5, 8, 10],\n",
    "            'classifier__ccp_alpha': [0, 0.001, 0.005, 0.01, 0.1],\n",
    "            'classifier__learning_rate': [0.1, 0.5, 1.],\n",
    "            'classifier__subsample': [0.5, 0.8, 1.]\n",
    "        }    \n",
    "    ]\n",
    "}\n",
    "\n",
    "model_params.update({'pipeline': [Pipeline(steps=[('preprocessor', preprocessor), ('classifier', c)]) \n",
    "                                  for c in model_params['estimator']],})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = get_estimators_scores(X_train, y_train, X_test, y_test,\n",
    "                                   models = model_params['pipeline'], \n",
    "                                   params = model_params['param_distributions'],\n",
    "                                   filenames=model_params['file_names'],\n",
    "                                   cv = skf, grid=False, n_jobs=2,\n",
    "                                   pipeline_classifier='classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [joblib.load(f'./models/{name}.sav') for name in model_params['file_names']]\n",
    "for m in models:\n",
    "    print_model_score(X_train, y_train, X_test, y_test, m, 'classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators=100)\n",
    "rc = RidgeClassifier(tol=1e-2, solver=\"sag\")\n",
    "per = Perceptron(max_iter=1000, tol=1e-3)\n",
    "pac = PassiveAggressiveClassifier(max_iter=1000, tol=1e-3)\n",
    "lsvc = LinearSVC(loss='squared_hinge', \n",
    "                 penalty='l2',\n",
    "                 max_iter=100000,\n",
    "                 #tol=0.01, \n",
    "                 dual=False)\n",
    "sgdc = SGDClassifier(alpha=.0001,\n",
    "                     penalty=\"elasticnet\",\n",
    "                     max_iter=1000,\n",
    "                     tol=1e-3)\n",
    "\n",
    "\n",
    "for model in [etc, rc, per, pac, lsvc, sgdc]:\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    model_name = type(model).__name__\n",
    "    print('{model} - Accuracy score: {score}' \\\n",
    "              .format(model=model_name,\n",
    "                      score=pipe.score(X_train, y_train).round(4)))\n",
    "    print('{model} - CV training score: {score}' \\\n",
    "              .format(model=model_name,\n",
    "                      score=cross_val_score(pipe, X_train, y_train, cv=skf).mean().round(4)))\n",
    "    print('{model} - CV testing score: {score}' \\\n",
    "              .format(model=model_name, \n",
    "                      score=cross_val_score(pipe, X_test, y_test, cv=skf).mean().round(4)))    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tuning of hyperparameters with gridsearch\n",
    "model_params = {\n",
    "    'estimators': [LinearSVC(max_iter=1000000),\n",
    "                   RidgeClassifier(),\n",
    "                   SVC(),\n",
    "                   LogisticRegression(solver='liblinear')\n",
    "                  ],\n",
    "    \n",
    "    'file_names': ['lin_svc_job_title',\n",
    "                   'rc_job_title',\n",
    "                   'svc_job_title_grid',\n",
    "                   'lr_job_title_grid'\n",
    "                  ],\n",
    "    \n",
    "    'param_grid': [\n",
    "        { # LinearSVC\n",
    "            'classifier__C': [0.01, 0.1, 0.5, 1., 10., 100., 1000.],\n",
    "            'classifier__fit_intercept': [True, False]\n",
    "        },\n",
    "        { # RidgeClassifier\n",
    "            'classifier__alpha': [0.01, 0.1, 0.5, 1., 10., 100., 1000.],\n",
    "            'classifier__fit_intercept': [True, False],\n",
    "        },\n",
    "        { # SVC\n",
    "            'classifier__C': np.logspace(-3, 4, 20),\n",
    "            'classifier__kernel': ['linear', 'poly', 'rbf']\n",
    "        },\n",
    "        { # LogisticRegression\n",
    "            'classifier__C': np.logspace(-4, 4, 15), \n",
    "            'classifier__penalty': ['l2', 'l1'],\n",
    "        },\n",
    "        \n",
    "    ]\n",
    "}\n",
    "\n",
    "model_params.update({'pipeline': [Pipeline(steps=[('preprocessor', preprocessor), ('classifier', c)]) \n",
    "                                  for c in model_params['estimators']]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = get_estimators_scores(X_train, y_train, X_test, y_test,\n",
    "                                  models = model_params['pipeline'], \n",
    "                                  params = model_params['param_grid'],\n",
    "                                  filenames=model_params['file_names'],\n",
    "                                  cv = skf, n_jobs=1, pipeline_classifier='classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in estimators:\n",
    "    print_model_score(X_train, y_train, X_test, y_test, model=m, classifier_name='classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# confusion matrix\n",
    "def docm(y_true, y_pred, labels=None):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1, 0])\n",
    "    if labels is not None:\n",
    "        cols = ['pred_' + c for c in labels]\n",
    "        df = pd.DataFrame(cm, index=labels, columns=cols)\n",
    "    else:\n",
    "        cols = ['pred_'+str(i) for i in range(len(cm))]\n",
    "        df = pd.DataFrame(cm, columns=cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearSVC\n",
    "docm(y_test, estimators[0].best_estimator_.predict(X_test), labels=['high_salary', 'low_salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "docm(y_test, estimators[3].best_estimator_.predict(X_test), labels=['high_salary', 'low_salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "### Model evaluation:\n",
    "\n",
    "Your boss would rather tell a client incorrectly that they would get a lower salary job than tell a client incorrectly that they would get a high salary job. Adjust one of your models to ease his mind, and explain what it is doing and any tradeoffs.\n",
    "\n",
    "\n",
    "- Use cross-validation to evaluate your models.\n",
    "- Evaluate the accuracy, AUC, precision and recall of the models.\n",
    "- Plot the ROC and precision-recall curves for at least one of your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve, recall_score, precision_score\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_svc = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                      ('classifier', LinearSVC(class_weight={0: .7, 1: .3}, random_state=42, max_iter=100000))])\n",
    "\n",
    "params = {\n",
    "    'classifier__loss': ['hinge', 'squared_hinge'],\n",
    "    'classifier__C': np.logspace(-1, 3, 40),\n",
    "}\n",
    "\n",
    "model_name = 'final_model'\n",
    "model = Path(f\"./models/{model_name}.sav\")\n",
    "if not model.exists():\n",
    "    gs = GridSearchCV(l_svc, \n",
    "                      scoring='precision', \n",
    "                      param_grid=params, \n",
    "                      verbose=1, \n",
    "                      n_jobs=1,\n",
    "                      cv=skf)\n",
    "    gs.fit(X_train, y_train)\n",
    "    cc = CalibratedClassifierCV(gs.best_estimator_.named_steps['classifier'])\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                          ('classifier', cc)])\n",
    "    clf.fit(X_train, y_train)\n",
    "    joblib.dump(clf, f'./models/{model_name}.sav')\n",
    "    \n",
    "else:\n",
    "    clf = joblib.load(f'./models/{model_name}.sav')\n",
    "                     \n",
    "print('Precision score:', np.round(clf.score(X_train, y_train), 4))\n",
    "print('CV training score:', np.round(cross_val_score(clf, X_train, y_train, cv=skf).mean(), 4))\n",
    "print('Test score:', np.round(clf.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rather to predict false negative than false positive, that's why class 0 was weighted higher \n",
    "# (and the gridsearch was layed out for f1 scoring)\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(12, 4), sharey=True)\n",
    "plot_confusion_matrix(clf, X_train, y_train, cmap='Blues', ax=ax[0], \n",
    "                      labels=[1,0], values_format='.0f') #, normalize='all')\n",
    "plot_confusion_matrix(clf, X_test, y_test, cmap='Blues', ax=ax[1],\n",
    "                      labels=[1,0], values_format='.0f') #, normalize='all')\n",
    "ax[0].set_title('Training set\\n', fontsize=20)\n",
    "ax[1].set_title('Test set\\n', fontsize=20)\n",
    "\n",
    "for a in ax:\n",
    "    texts = a.texts\n",
    "    for text in texts:\n",
    "        text.set_size(20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_at_threshold(x, threshold=0.5):\n",
    "    if x >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the threshold for the probability of class 1 to have a higher precision on prediction of class 0\n",
    "predictions_train = clf.predict(X_train)\n",
    "predictions_test = clf.predict(X_test)\n",
    "\n",
    "Y_prediction = pd.DataFrame(clf.predict_proba(X_test), columns=['low_salary', 'high_salary'])\n",
    "Y_prediction['predict_with_thres'] = Y_prediction['high_salary'].apply(predict_at_threshold, threshold=0.6)\n",
    "Y_prediction['true_value'] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy:', accuracy_score(y_train, predictions_train).round(4))\n",
    "print('Testing accuracy:', accuracy_score(y_test, predictions_test).round(4))\n",
    "print('-----------------------------')\n",
    "print('Training precision:', precision_score(y_train, predictions_train).round(4))\n",
    "print('Testing precision:', precision_score(y_test, predictions_test).round(4))\n",
    "print('-----------------------------')\n",
    "print('Testing precision with threshold:', precision_score(y_test, Y_prediction['predict_with_thres']).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docm(y_test, Y_prediction['predict_with_thres'], ['high_salary', 'low_salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ROC curve you want to gain a really strong slope in the beginning with as less false positive rate as possible. The best score would be having a area under the curve of 1 to have a perfect prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, plot_roc_curve, plot_precision_recall_curve\n",
    "import scikitplot as skplt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "cmap = ListedColormap(sns.color_palette(\"husl\", 3))\n",
    "probs_train = clf.predict_proba(X_train)\n",
    "probs_test = clf.predict_proba(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16,6))\n",
    "skplt.metrics.plot_roc(y_train, probs_train, plot_micro=True, plot_macro=True, \n",
    "                       title_fontsize=20, text_fontsize=14, cmap=cmap, ax=ax[0])\n",
    "skplt.metrics.plot_roc(y_test, probs_test, plot_micro=True, plot_macro=True, \n",
    "                       title_fontsize=20, text_fontsize=14, cmap=cmap, ax=ax[1])\n",
    "ax[0].set_title('ROC Curves (training set)', fontsize=18)\n",
    "ax[1].set_title('ROC Curves (test set)', fontsize=18)\n",
    "\n",
    "for axis in ax:\n",
    "    axis.set_xlim([-0.03, 1.03])\n",
    "    axis.set_ylim([-0.03, 1.03])\n",
    "    axis.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision shows the ratio of how often the positive labelled class was predicted correclty over \n",
    "all predictions which were done for that class. Whereas the recall depicts the ratio of that class over it occurence\n",
    "in the dataset. That means that you can predict less, but more precise to have a high precision score, but then chance\n",
    "increases that the class occurence more often then you actually predict it and then the recall decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16,6))\n",
    "skplt.metrics.plot_precision_recall(y_train, probs_train, plot_micro=True, \n",
    "                                    cmap=cmap, ax=ax[0], text_fontsize=14)\n",
    "\n",
    "skplt.metrics.plot_precision_recall(y_test, probs_test, plot_micro=True, \n",
    "                                    cmap=cmap, ax=ax[1], text_fontsize=14)\n",
    "\n",
    "ax[0].set_title('Precision-Recall Curve (training set)', fontsize=18)\n",
    "ax[1].set_title('Precision-Recall Curve (test set)', fontsize=18)\n",
    "for axis in ax:\n",
    "    axis.set_xlim([-0.03, 1.03])\n",
    "    axis.set_ylim([-0.03, 1.03])\n",
    "    axis.legend(fontsize=14)\n",
    "    axis.set_xlabel('Recall', fontsize=14)\n",
    "    axis.set_ylabel('Precision', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "<img src=\"http://imgur.com/xDpSobf.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### Bonus:\n",
    "\n",
    "- Answer the salary discussion by using your model to explain the tradeoffs between detecting high vs low salary positions. \n",
    "- Discuss the differences and explain when you want a high-recall or a high-precision model in this scenario.\n",
    "- Obtain the ROC/precision-recall curves for the different models you studied (at least the tuned model of each category) and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "focus": false,
    "id": "068dc1cf-7fd7-4f27-a1f1-7f0a5a221d29"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize your results in an executive summary written for a non-technical audience.\n",
    "   \n",
    "- Writeups should be at least 500-1000 words, defining any technical terms, explaining your approach, as well as any risks and limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR TEXT HERE IN MARKDOWN FORMAT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/xDpSobf.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### BONUS\n",
    "\n",
    "Convert your executive summary into a public blog post of at least 500 words, in which you document your approach in a tutorial for other aspiring data scientists. Link to this in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR LINK HERE IN MARKDOWN FORMAT "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
