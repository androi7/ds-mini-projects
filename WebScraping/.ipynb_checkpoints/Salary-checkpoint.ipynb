{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "\n",
    "# Web Scraping for Indeed.com and Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Case Overview\n",
    "\n",
    "You're working as a data scientist for a contracting firm that's rapidly expanding. Now that they have their most valuable employee (you!), they need to leverage data to win more contracts. Your firm offers technology and scientific solutions and wants to be competitive in the hiring market. Your principal wants you to\n",
    "\n",
    "   - determine the industry factors that are most important in predicting the salary amounts for these data.\n",
    "\n",
    "To limit the scope, your principal has suggested that you *focus on data-related job postings*, e.g. data scientist, data analyst, research scientist, business intelligence, and any others you might think of. You may also want to decrease the scope by *limiting your search to a single region.*\n",
    "\n",
    "Hint: Aggregators like [Indeed.com](https://www.indeed.com) regularly pool job postings from a variety of markets and industries.\n",
    "\n",
    "**Goal:** Scrape your own data from a job aggregation tool like Indeed.com in order to collect the data to best answer this question.\n",
    "\n",
    "---\n",
    "\n",
    "### Directions\n",
    "\n",
    "In this project you will be leveraging a variety of skills. The first will be to use the web-scraping and/or API techniques you've learned to collect data on data jobs from Indeed.com or another aggregator. Once you have collected and cleaned the data, you will use it to address the question above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factors that impact salary\n",
    "\n",
    "To predict salary the most appropriate approach would be a regression model.\n",
    "Here instead we just want to estimate which factors (like location, job title, job level, industry sector) lead to high or low salary and work with a classification model. To do so, split the salary into two groups of high and low salary, for example by choosing the median salary as a threshold (in principle you could choose any single or multiple splitting points).\n",
    "\n",
    "Use all the skills you have learned so far to build a predictive model.\n",
    "Whatever you decide to use, the most important thing is to justify your choices and interpret your results. *Communication of your process is key.* Note that most listings **DO NOT** come with salary information. You'll need to be able to extrapolate or predict the expected salaries for these listings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\").\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9732c901-ae26-4160-8376-42e22dd327df"
   },
   "source": [
    "#### Setup a request (using `requests`) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)\n",
    "\n",
    "The URL here has many query parameters:\n",
    "\n",
    "- `q` for the job search\n",
    "- This is followed by \"+20,000\" to return results with salaries (or expected salaries >$20,000)\n",
    "- `l` for a location \n",
    "- `start` for what result number to start on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "focus": false,
    "id": "e915023e-6b0d-4982-af2a-b1e0355f4927"
   },
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "focus": false,
    "id": "2efefc73-064a-482d-b3b5-ddf5508cb4ec"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "results = soup.find_all('div', class_='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"jobsearch-SerpJobCard unifiedRow row result\" data-jk=\"f1d32093c4f114d2\" data-tn-component=\"organicJob\" id=\"p_f1d32093c4f114d2\">\n",
      " <h2 class=\"title\">\n",
      "  <a class=\"jobtitle turnstileLink\" data-tn-element=\"jobTitle\" href=\"/rc/clk?jk=f1d32093c4f114d2&amp;fccid=fe404d18bb9eef1e&amp;vjs=3\" id=\"jl_f1d32093c4f114d2\" onclick=\"setRefineByCookie(['salest']); return rclk(this,jobmap[0],true,0);\" onmousedown=\"return rclk(this,jobmap[0],0);\" rel=\"noopener nofollow\" target=\"_blank\" title=\"Data Scientist - Publishing Royalties\">\n",
      "   <b>\n",
      "    Data\n",
      "   </b>\n",
      "   <b>\n",
      "    Scientist\n",
      "   </b>\n",
      "   - Publishing Royalties\n",
      "  </a>\n",
      "  <span class=\"new\">\n",
      "   new\n",
      "  </span>\n",
      " </h2>\n",
      " <div class=\"sjcl\">\n",
      "  <div>\n",
      "   <span class=\"company\">\n",
      "    <a class=\"turnstileLink\" data-tn-element=\"companyName\" href=\"/cmp/Spotify\" onmousedown=\"this.href = appendParamsOnce(this.href, 'from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=f1d32093c4f114d2&amp;jcid=fe404d18bb9eef1e')\" rel=\"noopener\" target=\"_blank\">\n",
      "     Spotify\n",
      "    </a>\n",
      "   </span>\n",
      "   <span class=\"ratingsDisplay\">\n",
      "    <a aria-label=\"Company rating 4.3 out of 5 stars\" class=\"ratingNumber\" data-tn-variant=\"cmplinktst2\" href=\"/cmp/Spotify/reviews\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=cmplinktst2&amp;from=SERP&amp;jt=Data+Scientist+-+Publishing+Royalties&amp;fromjk=f1d32093c4f114d2&amp;jcid=fe404d18bb9eef1e');\" rel=\"noopener\" target=\"_blank\" title=\"Spotify reviews\">\n",
      "     <span class=\"ratingsContent\">\n",
      "      4.3\n",
      "      <svg class=\"starIcon\" height=\"12px\" role=\"img\" width=\"12px\">\n",
      "       <g>\n",
      "        <path d=\"M 12.00,4.34 C 12.00,4.34 7.69,3.97 7.69,3.97 7.69,3.97 6.00,0.00 6.00,0.00 6.00,0.00 4.31,3.98 4.31,3.98 4.31,3.98 0.00,4.34 0.00,4.34 0.00,4.34 3.28,7.18 3.28,7.18 3.28,7.18 2.29,11.40 2.29,11.40 2.29,11.40 6.00,9.16 6.00,9.16 6.00,9.16 9.71,11.40 9.71,11.40 9.71,11.40 8.73,7.18 8.73,7.18 8.73,7.18 12.00,4.34 12.00,4.34 Z\" style=\"fill: #FFB103\">\n",
      "        </path>\n",
      "       </g>\n",
      "      </svg>\n",
      "     </span>\n",
      "    </a>\n",
      "   </span>\n",
      "  </div>\n",
      "  <div class=\"recJobLoc\" data-rc-loc=\"New York, NY\" id=\"recJobLoc_f1d32093c4f114d2\" style=\"display: none\">\n",
      "  </div>\n",
      "  <span class=\"location accessible-contrast-color-location\">\n",
      "   New York, NY\n",
      "  </span>\n",
      " </div>\n",
      " <div class=\"summary\">\n",
      "  <ul style=\"list-style-type:circle;margin-top: 0px;margin-bottom: 0px;padding-left:20px;\">\n",
      "   <li>\n",
      "    You have experience working with financial\n",
      "    <b>\n",
      "     data\n",
      "    </b>\n",
      "    and/or performing\n",
      "    <b>\n",
      "     data\n",
      "    </b>\n",
      "    reconciliations and quality assurance testing.\n",
      "   </li>\n",
      "  </ul>\n",
      " </div>\n",
      " <div class=\"jobsearch-SerpJobCard-footer\">\n",
      "  <div class=\"jobsearch-SerpJobCard-footerActions\">\n",
      "   <div class=\"result-link-bar-container\">\n",
      "    <div class=\"result-link-bar\">\n",
      "     <span class=\"date\">\n",
      "      7 days ago\n",
      "     </span>\n",
      "     <div class=\"tt_set\" id=\"tt_set_0\">\n",
      "      <div class=\"job-reaction\">\n",
      "       <button aria-expanded=\"false\" aria-haspopup=\"true\" aria-label=\"save or dislike\" class=\"job-reaction-kebab\" data-ol-has-click-handler=\"\" onclick=\"toggleKebabMenu('f1d32093c4f114d2', false, event); return false;\" tabindex=\"0\">\n",
      "       </button>\n",
      "       <span class=\"job-reaction-kebab-menu\">\n",
      "        <button class=\"job-reaction-kebab-item job-reaction-save\" data-ol-has-click-handler=\"\" onclick=\"changeJobState('f1d32093c4f114d2', 'save', 'linkbar', false, '');return false;\">\n",
      "         <svg focusable=\"false\" height=\"16\" viewbox=\"0 0 24 24\" width=\"16\">\n",
      "          <g>\n",
      "           <path d=\"M16.5,3A6,6,0,0,0,12,5.09,6,6,0,0,0,7.5,3,5.45,5.45,0,0,0,2,8.5C2,12.28,5.4,15.36,10.55,20L12,21.35,13.45,20C18.6,15.36,22,12.28,22,8.5A5.45,5.45,0,0,0,16.5,3ZM12.1,18.55l-0.1.1-0.1-.1C7.14,14.24,4,11.39,4,8.5A3.42,3.42,0,0,1,7.5,5a3.91,3.91,0,0,1,3.57,2.36h1.87A3.88,3.88,0,0,1,16.5,5,3.42,3.42,0,0,1,20,8.5C20,11.39,16.86,14.24,12.1,18.55Z\" fill=\"#2d2d2d\">\n",
      "           </path>\n",
      "          </g>\n",
      "         </svg>\n",
      "         <span class=\"job-reaction-kebab-item-text\">\n",
      "          Save job\n",
      "         </span>\n",
      "        </button>\n",
      "        <button class=\"job-reaction-kebab-item job-reaction-dislike\" data-ol-has-click-handler=\"\" onclick=\"dislikeJob(false, false, 'f1d32093c4f114d2', 'unsave', 'linkbar', false, '');\">\n",
      "         <span class=\"job-reaction-dislike-icon\">\n",
      "         </span>\n",
      "         <span class=\"job-reaction-kebab-item-text\">\n",
      "          Not interested\n",
      "         </span>\n",
      "        </button>\n",
      "        <button class=\"job-reaction-kebab-item job-reaction-report\" onclick=\"reportJob('f1d32093c4f114d2');\">\n",
      "         <span class=\"job-reaction-report-icon\">\n",
      "         </span>\n",
      "         <span class=\"job-reaction-kebab-item-text\">\n",
      "          Report Job\n",
      "         </span>\n",
      "        </button>\n",
      "       </span>\n",
      "      </div>\n",
      "      <span class=\"result-link-bar-separator\">\n",
      "       ·\n",
      "      </span>\n",
      "      <a class=\"sl resultLink save-job-link\" href=\"#\" id=\"sj_f1d32093c4f114d2\" onclick=\"changeJobState('f1d32093c4f114d2', 'save', 'linkbar', false, ''); return false;\" title=\"Save this job to my.indeed\">\n",
      "       Save job\n",
      "      </a>\n",
      "      <span class=\"result-link-bar-separator\">\n",
      "       ·\n",
      "      </span>\n",
      "      <button aria-expanded=\"false\" class=\"sl resultLink more-link\" id=\"tog_0\" onclick=\"toggleMoreLinks('f1d32093c4f114d2', '0'); return false;\">\n",
      "       More...\n",
      "      </button>\n",
      "     </div>\n",
      "     <script>\n",
      "      if (!window['result_f1d32093c4f114d2']) {window['result_f1d32093c4f114d2'] = {};}window['result_f1d32093c4f114d2']['showSource'] = false; window['result_f1d32093c4f114d2']['source'] = \"Spotify\"; window['result_f1d32093c4f114d2']['loggedIn'] = false; window['result_f1d32093c4f114d2']['showMyJobsLinks'] = false;window['result_f1d32093c4f114d2']['baseMyJobsUrl'] = \"https://myjobs.indeed.com\";window['result_f1d32093c4f114d2']['undoAction'] = \"unsave\";window['result_f1d32093c4f114d2']['relativeJobAge'] = \"7 days ago\";window['result_f1d32093c4f114d2']['jobKey'] = \"f1d32093c4f114d2\"; window['result_f1d32093c4f114d2']['myIndeedAvailable'] = true; window['result_f1d32093c4f114d2']['showMoreActionsLink'] = window['result_f1d32093c4f114d2']['showMoreActionsLink'] || true; window['result_f1d32093c4f114d2']['resultNumber'] = 0; window['result_f1d32093c4f114d2']['jobStateChangedToSaved'] = false; window['result_f1d32093c4f114d2']['searchState'] = \"q=data scientist $20,000&amp;l=New+York&amp;start=10\"; window['result_f1d32093c4f114d2']['basicPermaLink'] = \"https://www.indeed.com\"; window['result_f1d32093c4f114d2']['saveJobFailed'] = false; window['result_f1d32093c4f114d2']['removeJobFailed'] = false; window['result_f1d32093c4f114d2']['requestPending'] = false; window['result_f1d32093c4f114d2']['currentPage'] = \"serp\"; window['result_f1d32093c4f114d2']['sponsored'] = false;window['result_f1d32093c4f114d2']['reportJobButtonEnabled'] = false; window['result_f1d32093c4f114d2']['showMyJobsHired'] = false; window['result_f1d32093c4f114d2']['showSaveForSponsored'] = false; window['result_f1d32093c4f114d2']['showJobAge'] = true; window['result_f1d32093c4f114d2']['showHolisticCard'] = true; window['result_f1d32093c4f114d2']['showDislike'] = true; window['result_f1d32093c4f114d2']['showKebab'] = true; window['result_f1d32093c4f114d2']['showReport'] = true;\n",
      "     </script>\n",
      "    </div>\n",
      "   </div>\n",
      "  </div>\n",
      " </div>\n",
      " <div class=\"tab-container\">\n",
      "  <div class=\"more-links-container result-tab\" id=\"tt_display_0\" style=\"display:none;\">\n",
      "   <div class=\"more_actions\" id=\"more_0\">\n",
      "    <ul>\n",
      "     <li>\n",
      "      <span class=\"mat\">\n",
      "       View all\n",
      "       <a href=\"/q-Spotify-l-New-York,-NY-jobs.html\">\n",
      "        Spotify jobs in New York, NY\n",
      "       </a>\n",
      "       -\n",
      "       <a href=\"/l-New-York,-NY-jobs.html\">\n",
      "        New York jobs\n",
      "       </a>\n",
      "      </span>\n",
      "     </li>\n",
      "     <li>\n",
      "      <span class=\"mat\">\n",
      "       Salary Search:\n",
      "       <a href=\"/salaries/data-scientist-Salaries,-New-York-NY\" onmousedown=\"this.href = appendParamsOnce(this.href, '?campaignid=serp-more&amp;fromjk=f1d32093c4f114d2&amp;from=serp-more');\">\n",
      "        Data Scientist salaries in New York, NY\n",
      "       </a>\n",
      "      </span>\n",
      "     </li>\n",
      "     <li>\n",
      "      <span class=\"mat\">\n",
      "       Learn more about working at\n",
      "       <a href=\"/cmp/Spotify/about\" onmousedown=\"this.href = appendParamsOnce(this.href, '?fromjk=f1d32093c4f114d2&amp;from=serp-more&amp;campaignid=serp-more&amp;jcid=fe404d18bb9eef1e');\">\n",
      "        Spotify\n",
      "       </a>\n",
      "      </span>\n",
      "     </li>\n",
      "     <li>\n",
      "      <span class=\"mat\">\n",
      "       See popular\n",
      "       <a href=\"/cmp/Spotify/faq\" onmousedown=\"this.href = appendParamsOnce(this.href, '?from=serp-more&amp;campaignid=serp-more&amp;fromjk=f1d32093c4f114d2&amp;jcid=fe404d18bb9eef1e');\">\n",
      "        questions &amp; answers about Spotify\n",
      "       </a>\n",
      "      </span>\n",
      "     </li>\n",
      "     <li>\n",
      "      <span class=\"mat\">\n",
      "       Explore career as Data Scientist:\n",
      "       <a href=\"/career/data-scientist\" onmousedown=\"this.href = appendParamsOnce(this.href, 'from=jasx');\">\n",
      "        overview\n",
      "       </a>\n",
      "       ,\n",
      "       <a href=\"/career/data-scientist/career-advice\" onmousedown=\"this.href = appendParamsOnce(this.href, 'from=jasx');\">\n",
      "        career advice\n",
      "       </a>\n",
      "       ,\n",
      "       <a href=\"/career/data-scientist/faq\" onmousedown=\"this.href = appendParamsOnce(this.href, 'from=jasx');\">\n",
      "        FAQs\n",
      "       </a>\n",
      "      </span>\n",
      "     </li>\n",
      "    </ul>\n",
      "   </div>\n",
      "   <a class=\"close-link closeLink\" href=\"#\" onclick=\"toggleMoreLinks('f1d32093c4f114d2'); return false;\" title=\"Close\">\n",
      "   </a>\n",
      "  </div>\n",
      "  <div class=\"dya-container result-tab\">\n",
      "  </div>\n",
      "  <div class=\"tellafriend-container result-tab email_job_content\">\n",
      "  </div>\n",
      "  <div class=\"sign-in-container result-tab\">\n",
      "  </div>\n",
      " </div>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results[0].prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "bb0b866a-26a7-45e9-8084-5a0f90eb4b3e"
   },
   "source": [
    "Let's look at one result more closely. A single `result` looks like\n",
    "\n",
    "```\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=2480d203f7e97210&amp;jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```\n",
    "\n",
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is in a `span` with `class='salaryText'`.\n",
    "- The title of a job is in a link with class set to `jobtitle` and a `data-tn-element='jobTitle'`.  \n",
    "- The location is set in a `span` with `class='location'`. \n",
    "- The company is set in a `span` with `class='company'`. \n",
    "- Decide which other components could be relevant, for example the region or the summary of the job advert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = {\n",
    "    'salary': [],\n",
    "    'job_title': [],\n",
    "    'location': [],\n",
    "    'company': [],\n",
    "    'company_rating': [],\n",
    "    'description': []\n",
    "}\n",
    "\n",
    "for job in results:\n",
    "    try:\n",
    "        jobs['salary'].append(job.find('span', class_='salaryText').text)\n",
    "    except:\n",
    "        jobs['salary'].append(np.nan)\n",
    "        \n",
    "    try:\n",
    "        # job.find('h2', class_='title').find('a')['title']\n",
    "        jobs['job_title'].append(job.find('a', attrs={'data-tn-element': 'jobTitle'})['title'])\n",
    "    except:\n",
    "        jobs['job_title'].append(np.nan)\n",
    "        \n",
    "    try:\n",
    "        jobs['location'].append(job.find('span', class_='location').text.strip())  \n",
    "    except:\n",
    "        jobs['location'].append(np.nan)\n",
    "        \n",
    "    try:\n",
    "        company_name = job.find('a', attrs={'data-tn-element':'companyName'})\n",
    "        if company_name:\n",
    "            jobs['company'].append(company_name.text.strip())\n",
    "        else:\n",
    "            jobs['company'].append(job.find('span', class_='company').text.strip())\n",
    "    except:\n",
    "        jobs['company'].append(np.nan)\n",
    "        \n",
    "    try:\n",
    "        jobs['company_rating'].append(job.find('span', class_='ratingsContent').text.strip())\n",
    "    except:\n",
    "        jobs['company_rating'].append(np.nan)\n",
    "        \n",
    "    try:\n",
    "        lists = job.find('div', class_='summary').find_all('li')   \n",
    "        jobs['description'].append((' ').join([lst.text for lst in lists]))\n",
    "    except:\n",
    "        jobs['description'].append(np.nan)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'company': ['Spotify',\n",
      "             'Rhino',\n",
      "             'Vee',\n",
      "             'Shopify',\n",
      "             'Atlassian',\n",
      "             'Naval Nuclear Laboratory',\n",
      "             'QuaEra',\n",
      "             'Turner',\n",
      "             'Codecademy',\n",
      "             'Facebook',\n",
      "             'Jefferies & Company, Inc.',\n",
      "             'White Plains Hospital',\n",
      "             'Neuberger Berman',\n",
      "             'Turner',\n",
      "             'Codecademy'],\n",
      " 'company_rating': ['4.3',\n",
      "                    nan,\n",
      "                    '3.9',\n",
      "                    '3.9',\n",
      "                    '4.6',\n",
      "                    '2.8',\n",
      "                    nan,\n",
      "                    '4.0',\n",
      "                    '4.2',\n",
      "                    '4.2',\n",
      "                    '3.7',\n",
      "                    '4.0',\n",
      "                    '3.9',\n",
      "                    '4.0',\n",
      "                    '4.2'],\n",
      " 'description': ['You have experience working with financial data and/or '\n",
      "                 'performing data reconciliations and quality assurance '\n",
      "                 'testing.',\n",
      "                 \"Actively contribute to Rhino's Data culture by building out \"\n",
      "                 'core data models, tooling and best practices as well as '\n",
      "                 'training other Rhinos on using our data…',\n",
      "                 \"You will help build Vee's data capability and data strategy. \"\n",
      "                 'Solid background in data mining and statistical analysis.',\n",
      "                 'Masterful data storytelling and strategic thinking. '\n",
      "                 'Influence leadership to drive more data-informed decisions. '\n",
      "                 'Deep understanding of advanced SQL techniques.',\n",
      "                 'As the ideal data scientist, you are someone who can both do '\n",
      "                 'a technical dive and communicate effectively with others.',\n",
      "                 'Processing, refining, and verifying the integrity of data '\n",
      "                 'used for analysis. Experience with data visualization '\n",
      "                 'packages, such as Tableau, SAS, and Rstudio.',\n",
      "                 'Experience with R, Python, PySpark and data visualization '\n",
      "                 'software such as Tableau. Ability to efficiently construct '\n",
      "                 'data sets from large scale distributed…',\n",
      "                 'Develop video labeling models to identify objects, '\n",
      "                 'individuals and scene breaks of interest. Work with human '\n",
      "                 'annotators to develop a rigorous precision measure…',\n",
      "                 'Work with our data science and engineering teams to maintain '\n",
      "                 'data integrity. You have strong data intuition and knowledge '\n",
      "                 'of using data science best practices…',\n",
      "                 '5+ years of hands-on data science experience, Data analysis '\n",
      "                 'skill, willing to get your hands dirty with data. Team is '\n",
      "                 'based in Bellevue.',\n",
      "                 '4+ years of experience within consulting, data research, '\n",
      "                 'data science or similar roles. Keen interest in the “data '\n",
      "                 'economy” within financial services.',\n",
      "                 'Expert technical knowledge in data warehousing, advanced '\n",
      "                 'analytics, and data visualization. Integrate data from '\n",
      "                 'disparate sources.',\n",
      "                 'Identify, develop and apply statistical and machine learning '\n",
      "                 'techniques to large data sets for data pre-processing, '\n",
      "                 'feature engineering, patten recognition and…',\n",
      "                 'Experience in data processing using SQL. The HBO Max Data '\n",
      "                 'Science team is responsible for designing and executing '\n",
      "                 'end-to-end data science solution to transform…',\n",
      "                 'Work with our data science and engineering teams to maintain '\n",
      "                 'data integrity. You have strong data intuition and knowledge '\n",
      "                 'of using data science best practices…'],\n",
      " 'job_title': ['Data Scientist - Publishing Royalties',\n",
      "               'Data Scientist',\n",
      "               'NLP Data Scientist Internship',\n",
      "               'Senior Data Scientist (Americas - Remote)',\n",
      "               'Data Scientist, Enterprise, Trello (US Remote)',\n",
      "               'Data Scientist',\n",
      "               'Data Scientist',\n",
      "               'Virtual Data Science Intern, Summer 2021',\n",
      "               'Data Scientist, Analytics & Inference - New York or Remote',\n",
      "               'Data Scientist, Analytics-Remote Presence',\n",
      "               'Data Strategy Data Scientist',\n",
      "               'Data Scientist',\n",
      "               'Data Scientist',\n",
      "               'Virtual HBO Max Data Science Intern –\\xa0Summer 2021',\n",
      "               'Senior Data Scientist, Analytics & Inference - New York or '\n",
      "               'Remote'],\n",
      " 'location': ['New York, NY',\n",
      "              'New York State',\n",
      "              'New York State',\n",
      "              'New York, NY',\n",
      "              'New York, NY',\n",
      "              'Niskayuna, NY 12309',\n",
      "              'New York, NY 10018 (Garment District area)',\n",
      "              'New York, NY',\n",
      "              'New York, NY',\n",
      "              'New York, NY 10003 (Flatiron District area)',\n",
      "              'New York, NY 10022 (Midtown area)',\n",
      "              'White Plains, NY 10601',\n",
      "              'New York, NY',\n",
      "              'New York, NY',\n",
      "              'New York State'],\n",
      " 'salary': [nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan,\n",
      "            nan]}\n"
     ]
    }
   ],
   "source": [
    "pprint(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist - Publishing Royalties</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>4.3</td>\n",
       "      <td>You have experience working with financial dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York State</td>\n",
       "      <td>Rhino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Actively contribute to Rhino's Data culture by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NLP Data Scientist Internship</td>\n",
       "      <td>New York State</td>\n",
       "      <td>Vee</td>\n",
       "      <td>3.9</td>\n",
       "      <td>You will help build Vee's data capability and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Data Scientist (Americas - Remote)</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Shopify</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Masterful data storytelling and strategic thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist, Enterprise, Trello (US Remote)</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Atlassian</td>\n",
       "      <td>4.6</td>\n",
       "      <td>As the ideal data scientist, you are someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   salary                                       job_title        location  \\\n",
       "0     NaN           Data Scientist - Publishing Royalties    New York, NY   \n",
       "1     NaN                                  Data Scientist  New York State   \n",
       "2     NaN                   NLP Data Scientist Internship  New York State   \n",
       "3     NaN       Senior Data Scientist (Americas - Remote)    New York, NY   \n",
       "4     NaN  Data Scientist, Enterprise, Trello (US Remote)    New York, NY   \n",
       "\n",
       "     company company_rating                                        description  \n",
       "0    Spotify            4.3  You have experience working with financial dat...  \n",
       "1      Rhino            NaN  Actively contribute to Rhino's Data culture by...  \n",
       "2        Vee            3.9  You will help build Vee's data capability and ...  \n",
       "3    Shopify            3.9  Masterful data storytelling and strategic thin...  \n",
       "4  Atlassian            4.6  As the ideal data scientist, you are someone w...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(jobs).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "f1eddb90-4ba8-483c-a229-77e93aa53119"
   },
   "source": [
    "### Write 4 functions to extract each item: location, company, job, and salary.\n",
    "\n",
    "Example: \n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
    "\n",
    "- **Make sure these functions are robust and can handle cases where the data/field may not be available.**\n",
    "    - Remember to check if a field is empty or `None` for attempting to call methods on it.\n",
    "    - Remember to use `try/except` if you anticipate errors.\n",
    "- **Test** the functions on the results above and simple examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_null(content):\n",
    "    if content not in ('', None):\n",
    "        return content\n",
    "    else:\n",
    "        raise Exception('No content found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "focus": false,
    "id": "a1af53c9-9090-494f-b82e-cadb60a54909"
   },
   "outputs": [],
   "source": [
    "def extract_location_from_result(result):\n",
    "    try:\n",
    "        data = result.find('span', class_='location').text.strip()\n",
    "        return not_null(data)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_company_from_result(result):\n",
    "    try:\n",
    "        company_name = result.find('a', attrs={'data-tn-element':'companyName'})\n",
    "        if company_name:\n",
    "            return not_null(company_name.text.strip())\n",
    "        else:\n",
    "            data = result.find('span', class_='company').text.strip()\n",
    "            return not_null(data)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_from_result(result):\n",
    "    try:\n",
    "        return not_null(result.find('a', attrs={'data-tn-element': 'jobTitle'})['title'])\n",
    "    except:\n",
    "        return np.nan\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_salary_from_result(result):\n",
    "    try:\n",
    "        return not_null(result.find('span', class_='salaryText').text.strip())\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rating_from_result(result): \n",
    "    try:\n",
    "        return not_null(result.find('span', class_='ratingsContent').text.strip())\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_summary_from_result(result):\n",
    "    try:\n",
    "        lists = result.find('div', class_='summary').find_all('li')   \n",
    "        return not_null((' ').join([lst.text for lst in lists]))\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "results = soup.find_all('div', class_='result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Publishing Royalties</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>You have experience working with financial dat...</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York State</td>\n",
       "      <td>Rhino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Actively contribute to Rhino's Data culture by...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NLP Data Scientist Internship</td>\n",
       "      <td>New York State</td>\n",
       "      <td>Vee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>You will help build Vee's data capability and ...</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist (Americas - Remote)</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Shopify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Masterful data storytelling and strategic thin...</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist, Enterprise, Trello (US Remote)</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Atlassian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As the ideal data scientist, you are someone w...</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Niskayuna, NY 12309</td>\n",
       "      <td>Naval Nuclear Laboratory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Processing, refining, and verifying the integr...</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY 10018 (Garment District area)</td>\n",
       "      <td>QuaEra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Experience with R, Python, PySpark and data vi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Virtual Data Science Intern, Summer 2021</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Turner</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Develop video labeling models to identify obje...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist, Analytics &amp; Inference - New Yo...</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Codecademy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Work with our data science and engineering tea...</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist, Analytics-Remote Presence</td>\n",
       "      <td>New York, NY 10003 (Flatiron District area)</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5+ years of hands-on data science experience, ...</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0              Data Scientist - Publishing Royalties   \n",
       "1                                     Data Scientist   \n",
       "2                      NLP Data Scientist Internship   \n",
       "3          Senior Data Scientist (Americas - Remote)   \n",
       "4     Data Scientist, Enterprise, Trello (US Remote)   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7           Virtual Data Science Intern, Summer 2021   \n",
       "8  Data Scientist, Analytics & Inference - New Yo...   \n",
       "9          Data Scientist, Analytics-Remote Presence   \n",
       "\n",
       "                                      location                   company  \\\n",
       "0                                 New York, NY                   Spotify   \n",
       "1                               New York State                     Rhino   \n",
       "2                               New York State                       Vee   \n",
       "3                                 New York, NY                   Shopify   \n",
       "4                                 New York, NY                 Atlassian   \n",
       "5                          Niskayuna, NY 12309  Naval Nuclear Laboratory   \n",
       "6   New York, NY 10018 (Garment District area)                    QuaEra   \n",
       "7                                 New York, NY                    Turner   \n",
       "8                                 New York, NY                Codecademy   \n",
       "9  New York, NY 10003 (Flatiron District area)                  Facebook   \n",
       "\n",
       "   salary                                            summary rating  \n",
       "0     NaN  You have experience working with financial dat...    4.3  \n",
       "1     NaN  Actively contribute to Rhino's Data culture by...    NaN  \n",
       "2     NaN  You will help build Vee's data capability and ...    3.9  \n",
       "3     NaN  Masterful data storytelling and strategic thin...    3.9  \n",
       "4     NaN  As the ideal data scientist, you are someone w...    4.6  \n",
       "5     NaN  Processing, refining, and verifying the integr...    2.8  \n",
       "6     NaN  Experience with R, Python, PySpark and data vi...    NaN  \n",
       "7     NaN  Develop video labeling models to identify obje...    4.0  \n",
       "8     NaN  Work with our data science and engineering tea...    4.2  \n",
       "9     NaN  5+ years of hands-on data science experience, ...    4.2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary = []\n",
    "job_title = [] \n",
    "location = []\n",
    "company = []\n",
    "summary = []\n",
    "rating = []\n",
    "\n",
    "for job in results:\n",
    "    salary.append(extract_salary_from_result(job))\n",
    "    job_title.append(extract_job_from_result(job))\n",
    "    location.append(extract_location_from_result(job))\n",
    "    company.append(extract_company_from_result(job))\n",
    "    rating.append(extract_rating_from_result(job))\n",
    "    summary.append(extract_summary_from_result(job))\n",
    "    \n",
    "\n",
    "job_market = pd.DataFrame({'job_title': job_title,\n",
    "                           'location': location,\n",
    "                           'company': company,\n",
    "                           'salary': salary,\n",
    "                           'summary': summary,\n",
    "                           'rating': rating})\n",
    "\n",
    "job_market.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34070e89-9521-4b45-90c8-57a6599aac68"
   },
   "source": [
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL above.\n",
    "\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "There are two query parameters here we can alter to collect more results, the `l=New+York` and the `start=10`. The first controls the location of the results (so we can try a different city). The second controls where in the results to start and gives 10 results (thus, we can keep incrementing by 10 to go further in the list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10%22\n",
    "\n",
    "titles = ['data scientist', \n",
    "          'data analyst',\n",
    "          'research scientist',\n",
    "          'business intelligence',\n",
    "          'database developer',\n",
    "          'data engineer',\n",
    "          'database administrator']\n",
    "\n",
    "cities = ['New York',\n",
    "          'Dallas',\n",
    "          'Boston',\n",
    "          'Houston',\n",
    "          'San Francisco',\n",
    "          'Seattle',\n",
    "          'Austin',\n",
    "          'Miami',\n",
    "          'New Orleans',\n",
    "          'Atlanta',\n",
    "          'Jacksonville',\n",
    "          'Chicago',\n",
    "          'Philadelphia',\n",
    "          'Las Vegas',\n",
    "          'Los Angeles',\n",
    "          'Phoenix']\n",
    "\n",
    "titles_encoded = ('%2C+').join([t.replace(' ', '+') for t in set(titles)])\n",
    "\n",
    "# Ascii Encoding Reference:\n",
    "# space -> %20\n",
    "# # -> %23\n",
    "# $ -> %24\n",
    "# % -> %25\n",
    "# & -> %26\n",
    "# , -> %2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.scrapehero.com/how-to-fake-and-rotate-user-agents-using-python-3/\n",
    "\n",
    "user_agent_list = [\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "]\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\", \n",
    "    \"Accept-Encoding\": \"gzip, deflate, sdch\", \n",
    "    \"Accept-Language\": \"en-GB,en-US;q=0.9,en;q=0.8\", \n",
    "    \"Dnt\": \"1\", # do not track (1... prefers not to be tracked)\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "#     \"Host\": \"indeed.com\",\n",
    "#     \"Cache-Control\": \"max-age=0\",\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.scrapehero.com/how-to-rotate-proxies-and-ip-addresses-using-python-3/\n",
    "# xpath expressions:\n",
    "# / -> selects from the root node (if occurring after a node then referring to children node)\n",
    "# // -> selects nodes from the current node\n",
    "# . -> selects current node\n",
    "\n",
    "from lxml.html import fromstring\n",
    "def get_proxies():\n",
    "#     url = 'https://free-proxy-list.net/'\n",
    "    url = 'https://www.us-proxy.org/'\n",
    "    response = requests.get(url)\n",
    "    # fromstring() returns document_fromstring or fragment_fromstring\n",
    "    parser = fromstring(response.text)\n",
    "    proxies = set()\n",
    "    for i in parser.xpath('//tbody/tr')[:20]:\n",
    "        if i.xpath('.//td[7][contains(text(),\"yes\")]'):  # <td class='hx'>yes</td>\n",
    "            #Grabbing IP and corresponding PORT\n",
    "            # i.xpath('.//td[1]')[0].text\n",
    "            proxy = \":\".join([i.xpath('.//td[1]/text()')[0], i.xpath('.//td[2]/text()')[0]])\n",
    "            proxies.add(proxy)\n",
    "    return proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_indeed(cities, titles_encoded, headers=None, user_agent_list=None, delay=False):\n",
    "\n",
    "    salary = []\n",
    "    job_title = [] \n",
    "    location = []\n",
    "    company = []\n",
    "    rating = []\n",
    "    summary = []\n",
    "    url_template = \"http://www.indeed.com/jobs?q={job}+%2420%2C000&l={location}&start={page}\"\n",
    "    \n",
    "    if type(cities) != list:\n",
    "        raise Exception('cities must be a list')\n",
    "        return\n",
    "\n",
    "#     from itertools import cycle\n",
    "#     proxies = get_proxies()\n",
    "#     proxy_pool = cycle(proxies)\n",
    "\n",
    "    for c in tqdm(set(cities)):\n",
    "        if user_agent_list:\n",
    "            user_agent = random.choice(user_agent_list)\n",
    "            headers['User-Agent'] = user_agent\n",
    "#         proxy = next(proxy_pool)\n",
    "#         proxy_flag = False\n",
    "\n",
    "#         while not proxy_flag:\n",
    "#             try:\n",
    "#                 response = requests.get('http://www.indeed.com', proxies={'http': proxy, 'https': proxy})\n",
    "#                 print(f\"Request {c}\")\n",
    "#                 print(response.json())\n",
    "#                 proxy_flag = True\n",
    "#             except:\n",
    "#                 proxy = next(proxy_pool)\n",
    "#                 print(\"Skipping. Connnection error\")\n",
    "\n",
    "        for page in tqdm(range(10, 800, 10), position=0):\n",
    "            try:\n",
    "                r = requests.get(url_template.format(job=titles_encoded,\n",
    "                                                     location=c.replace(' ', '+'),\n",
    "                                                     page=page),\n",
    "                                 headers=headers)\n",
    "#                                  proxies={\"http\": proxy, \"https\": proxy})\n",
    "            except:\n",
    "                raise Exception('check headers')\n",
    "\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            results = soup.find_all('div', class_='result')\n",
    "\n",
    "            # when the last result is shown a message box appears which includes \n",
    "            # a paragraph with a class attribute called 'dupetext'\n",
    "            duplicate_msg = soup.find('p', class_='dupetext')\n",
    "\n",
    "            for job in results:\n",
    "                salary.append(extract_salary_from_result(job))\n",
    "                job_title.append(extract_job_from_result(job))\n",
    "                location.append(extract_location_from_result(job))\n",
    "                company.append(extract_company_from_result(job))\n",
    "                rating.append(extract_rating_from_result(job))\n",
    "                summary.append(extract_summary_from_result(job))\n",
    "\n",
    "            if not results or duplicate_msg:  # nothing found or end result is reached\n",
    "                if delay:\n",
    "                    time.sleep(15 + random.random() * 10)  # 15-25 sec, prevent to submit captchas\n",
    "                print(f'{c} with {page/10} pages.')\n",
    "                break\n",
    "            elif page % 80 == 0:\n",
    "                if delay:\n",
    "                    time.sleep(10 + random.random() * 5)  # 10-15 sec\n",
    "            else:\n",
    "#                 print(f'city: {c}, page: {page}')\n",
    "                if delay:\n",
    "                    time.sleep(1 + random.random() * 3)  # 1-4 sec\n",
    "                \n",
    "    df = pd.DataFrame({'job_title': job_title,\n",
    "                       'location': location,\n",
    "                       'company': company,\n",
    "                       'salary': salary,\n",
    "                       'rating': rating,\n",
    "                       'summary': summary})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file_exists(filename, cities, titles_encoded, headers=None, user_agent_list=None, delay=False):\n",
    "    file = Path(f\"./datasets/{filename}.csv\")\n",
    "    if not file.exists():\n",
    "        df = scrape_indeed(cities=cities, titles_encoded=titles_encoded, \n",
    "                           headers=headers, user_agent_list=user_agent_list, \n",
    "                           delay=delay)\n",
    "        df.to_csv(f'./datasets/{filename}.csv', index=False)\n",
    "    else:\n",
    "        print('file already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>rating</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Syracuse, NY</td>\n",
       "      <td>Excelacom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Bachelor’s Degree or higher. Responds to data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst/Assistant Research Scientist (par...</td>\n",
       "      <td>New York, NY 10012 (Greenwich Village area)</td>\n",
       "      <td>New York University</td>\n",
       "      <td>$18 an hour</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Cultivate deep familiarity with methodological...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Intelligence Analyst</td>\n",
       "      <td>New York, NY 10176 (Murray Hill area)</td>\n",
       "      <td>CBS Interactive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>As a business intelligence analyst, you’ll lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Melville, NY 11747</td>\n",
       "      <td>North American Partners in Anesthesia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1+ year of hands-on experience with MS SQL as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Northwestern Mutual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.8</td>\n",
       "      <td>This team focuses on developing data science m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                                       Data Analyst   \n",
       "1  Data Analyst/Assistant Research Scientist (par...   \n",
       "2                      Business Intelligence Analyst   \n",
       "3                              Business Data Analyst   \n",
       "4                                     Data Scientist   \n",
       "\n",
       "                                      location  \\\n",
       "0                                 Syracuse, NY   \n",
       "1  New York, NY 10012 (Greenwich Village area)   \n",
       "2        New York, NY 10176 (Murray Hill area)   \n",
       "3                           Melville, NY 11747   \n",
       "4                                 New York, NY   \n",
       "\n",
       "                                 company       salary  rating  \\\n",
       "0                              Excelacom          NaN     3.2   \n",
       "1                    New York University  $18 an hour     4.2   \n",
       "2                        CBS Interactive          NaN     3.5   \n",
       "3  North American Partners in Anesthesia          NaN     2.9   \n",
       "4                    Northwestern Mutual          NaN     3.8   \n",
       "\n",
       "                                             summary  \n",
       "0  Bachelor’s Degree or higher. Responds to data ...  \n",
       "1  Cultivate deep familiarity with methodological...  \n",
       "2  As a business intelligence analyst, you’ll lea...  \n",
       "3  1+ year of hands-on experience with MS SQL as ...  \n",
       "4  This team focuses on developing data science m...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_file_exists('df_0', cities=[cities[0]], titles_encoded=titles_encoded, headers=headers, user_agent_list=user_agent_list)\n",
    "df_0 = pd.read_csv('./datasets/df_0.csv')\n",
    "df_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0[df_0['salary'].notnull()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "e8beed7c-3e42-40c0-810f-5f67f8f885a0"
   },
   "source": [
    "### Complete the following code to collect results from multiple cities and starting points. \n",
    "- Enter your city below to add it to the search.\n",
    "- Remember to convert your salary to U.S. Dollars to match the other cities if the currency is different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "20339c09-5032-4e27-91be-286e9b46cd13"
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_1', cities=[cities[1]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_1 = pd.read_csv('./datasets/df_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_2', cities=[cities[2]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_2 = pd.read_csv('./datasets/df_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_3', cities=[cities[3]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_3 = pd.read_csv('./datasets/df_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_4', cities=[cities[4]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_4 = pd.read_csv('./datasets/df_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_5', cities=[cities[5]], titles_encoded=titles_encoded)\n",
    "df_5 = pd.read_csv('./datasets/df_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_6', cities=[cities[6]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_6 = pd.read_csv('./datasets/df_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_7', cities=[cities[7]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_7 = pd.read_csv('./datasets/df_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_8', cities=[cities[8]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_8 = pd.read_csv('./datasets/df_8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_9', cities=[cities[9]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_9 = pd.read_csv('./datasets/df_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_10', cities=[cities[10]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_10 = pd.read_csv('./datasets/df_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_11', cities=[cities[11]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_11 = pd.read_csv('./datasets/df_11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_12', cities=[cities[12]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_12 = pd.read_csv('./datasets/df_12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_13', cities=[cities[13]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_13 = pd.read_csv('./datasets/df_13.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_14', cities=[cities[14]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_14 = pd.read_csv('./datasets/df_14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "check_file_exists('df_15', cities=[cities[15]], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_15 = pd.read_csv('./datasets/df_15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exists\n"
     ]
    }
   ],
   "source": [
    "MY_CITY = 'London'  # no exchange conversion needed, autimatically set to dollar\n",
    "check_file_exists('df_16', cities=[MY_CITY], titles_encoded=titles_encoded, \n",
    "                  headers=headers, user_agent_list=user_agent_list)\n",
    "df_16 = pd.read_csv('./datasets/df_16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14992, 7)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if MY_CITY not in cities:\n",
    "    cities.append(MY_CITY)\n",
    "for i in range(len(cities)):\n",
    "    globals()[f'df_{i}']['city'] = np.repeat(cities[i], globals()[f'df_{i}'].shape[0])\n",
    "    \n",
    "df_indeed = pd.concat([df_0, df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8,\n",
    "                       df_9, df_10, df_11, df_12, df_13, df_14, df_15, df_16], axis=0)\n",
    "df_indeed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>rating</th>\n",
       "      <th>summary</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Data Analyst - Loan Acquisitions</td>\n",
       "      <td>Dallas, TX 75234</td>\n",
       "      <td>Rushmore Loan Management Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Develops data validation tools and techniques ...</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>Engineering Manager</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Root Insurance Company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Mentors and grows other engineers. Able to pos...</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>Administrator I</td>\n",
       "      <td>Rochester, NY</td>\n",
       "      <td>University of Rochester</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Create and maintain a database of graduate stu...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Sailpoint IIQ engineer</td>\n",
       "      <td>Columbus, OH</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Hands on Dev experience in Sailpoint with 1 or...</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>Director, ShapingEDU</td>\n",
       "      <td>Tempe, AZ</td>\n",
       "      <td>Arizona State University</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Experience leading and/or managing a quickly-e...</td>\n",
       "      <td>Phoenix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            job_title          location  \\\n",
       "618  Data Analyst - Loan Acquisitions  Dallas, TX 75234   \n",
       "865               Engineering Manager       Chicago, IL   \n",
       "903                   Administrator I     Rochester, NY   \n",
       "236            Sailpoint IIQ engineer      Columbus, OH   \n",
       "718              Director, ShapingEDU         Tempe, AZ   \n",
       "\n",
       "                               company salary  rating  \\\n",
       "618  Rushmore Loan Management Services    NaN     3.1   \n",
       "865             Root Insurance Company    NaN     3.7   \n",
       "903            University of Rochester    NaN     4.0   \n",
       "236                          Capgemini    NaN     3.8   \n",
       "718           Arizona State University    NaN     4.2   \n",
       "\n",
       "                                               summary      city  \n",
       "618  Develops data validation tools and techniques ...    Dallas  \n",
       "865  Mentors and grows other engineers. Able to pos...   Chicago  \n",
       "903  Create and maintain a database of graduate stu...  New York  \n",
       "236  Hands on Dev experience in Sailpoint with 1 or...    London  \n",
       "718  Experience leading and/or managing a quickly-e...   Phoenix  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indeed.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2061"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indeed[df_indeed['salary'].notnull()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def not_null1(content):\n",
    "#     if content not in ('', None):\n",
    "#         return content\n",
    "#     else:\n",
    "#         raise Exception('No content found!')\n",
    "        \n",
    "# def extract_location_from_result1(result):\n",
    "#     try:\n",
    "#         data = result.find_element_by_css_selector('span.location').text.strip()\n",
    "#         return not_null1(data)\n",
    "#     except:\n",
    "#         return np.nan\n",
    "    \n",
    "    \n",
    "# def extract_job_from_result1(result):\n",
    "#     try:\n",
    "#         return not_null1(result.find_element_by_css_selector('a[data-tn-element=jobTitle]').get_attribute('title'))                                                        \n",
    "#     except:\n",
    "#         return np.nan\n",
    "    \n",
    "# def extract_company_from_result1(result):\n",
    "#     try:\n",
    "#         company_name = result.find_element_by_css_selector('a[data-tn-element=companyName]') \n",
    "#         if company_name:\n",
    "#             return company_name.text.strip()\n",
    "#         else:\n",
    "#             data = result.find_element_by_css_selector('span.company').text.strip()\n",
    "#             return not_null1(data)\n",
    "#     except:\n",
    "#         return np.nan\n",
    "    \n",
    "# def extract_salary_from_result1(result):\n",
    "#     try:\n",
    "#         return not_null1(result.find_element_by_css_selector('span.salaryText').text.strip())\n",
    "#     except:\n",
    "#         return np.nan\n",
    "\n",
    "# driver = webdriver.Chrome(executable_path='/Users/gabriel/Desktop/DataScience/chromedriver')\n",
    "\n",
    "\n",
    "# def extract_summary1(result):\n",
    "#     sleep(2)\n",
    "\n",
    "#     try:\n",
    "#         summary_html = result.find_element_by_css_selector('div#vjs-desc').get_attribute('innerHTML')\n",
    "#         return not_null1(summary_html)\n",
    "#     except:\n",
    "#         return np.nan\n",
    "\n",
    "\n",
    "# url_template = \"http://www.indeed.com/jobs?q={job}+%2420%2C000&l={location}&start={page}\"\n",
    "# max_results_per_city = 10 #5000 \n",
    "\n",
    "# titles = ['data scientist', \n",
    "#           'data analyst',\n",
    "#           'research scientist',\n",
    "#           'business intelligence',\n",
    "#           'database developer',\n",
    "#           'data engineer',\n",
    "#           'database administrator']\n",
    "\n",
    "# titles_encoded = ('%2C+').join([t.replace(' ', '+') for t in titles])\n",
    "# titles_conded = 'data+scientist'\n",
    "                        \n",
    "# salary1 = []\n",
    "# job_title1 = [] \n",
    "# location1 = []\n",
    "# company1 = []\n",
    "# summary1 = []\n",
    "\n",
    "# for city in tqdm(set(['New+York'])): #, 'Chicago', 'San+Francisco', 'Austin', 'Seattle', \n",
    "# #     'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', \n",
    "# #     'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', YOUR_CITY])):\n",
    "#     counter = 0\n",
    "#     for start in range(0, max_results_per_city, 10):\n",
    "#         r = driver.get(url_template.format(job=titles_encoded,\n",
    "#                                              location=city,\n",
    "#                                              page=start))\n",
    "        \n",
    "#         results = driver.find_elements_by_css_selector('div.result')\n",
    "#         try:\n",
    "#             duplicate_test = driver.find_element_by_css_selector('p.dupetext')\n",
    "#         except:\n",
    "#             duplicate_test = None\n",
    "#         try:\n",
    "#             duplicate_test2 = driver.find_element_by_css_selector('div.related_searches') \n",
    "#         except:\n",
    "#             duplacte_test2 = None\n",
    "        \n",
    "#         print(f'City: {city}, Page: {start}, counter: {counter}, duplicate_test: {bool(duplicate_test) or bool(duplicate_test2)}')\n",
    "\n",
    "        \n",
    "#         if duplicate_test or duplicate_test2:\n",
    "#             counter += 1    \n",
    "#             if counter > 1:\n",
    "#                 break\n",
    "    \n",
    "\n",
    "#         for job in results:\n",
    "#             salary1.append(extract_salary_from_result1(job))\n",
    "#             job_title1.append(extract_job_from_result1(job))\n",
    "#             location1.append(extract_location_from_result1(job))\n",
    "#             company1.append(extract_company_from_result1(job))\n",
    "#             job.click()\n",
    "#             summary1.append(extract_summary1(driver))\n",
    "                        \n",
    "# test1 = pd.DataFrame({'tilte': job_title1, 'location': location1, 'salary': salary1, 'company': company1,\n",
    "#                      'summary': summary1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly, these will not be useful to us for now.\n",
    "1. Some of the entries may be duplicated.\n",
    "1. The salaries are given as text and usually with ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly (filter those that refer to hour or week). Also, remove duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = df_indeed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1538, 7)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.drop_duplicates(inplace=True)\n",
    "jobs[jobs['salary'].notnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.dropna(subset=['salary'], inplace=True)\n",
    "# jobs = jobs[jobs['salary'].str.contains(r'year')]\n",
    "# jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[jobs['salary'].str.contains('hour')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "975"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[jobs['salary'].str.contains('year')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[jobs['salary'].str.contains('month')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$219 a day       1\n",
       "$40 per class    1\n",
       "Name: salary, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[~jobs['salary'].str.contains('hour|year|month')]['salary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_hourly = jobs[jobs['salary'].str.contains('hour')].copy()\n",
    "jobs_monthly = jobs[jobs['salary'].str.contains('month')].copy()\n",
    "jobs_yearly = jobs[jobs['salary'].str.contains('year')].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "7d4bc860-b214-4f75-9cd0-b234830b1ec2"
   },
   "source": [
    "#### Write a function that takes a salary string and converts it to a number, averaging a salary range if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$60,000 - $70,000 a year' '$123,438 a year' '$50,000 - $60,000 a year'\n",
      " '$55,000 - $60,000 a year' '$63,809 - $80,882 a year']\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "print(jobs_yearly['salary'].sample(5).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$4,301 - $7,500 a month' '$4,096 - $5,766 a month'\n",
      " '$6,999 - $7,900 a month' '$4,500 - $4,900 a month' '$4,095 a month']\n"
     ]
    }
   ],
   "source": [
    "print(jobs_monthly['salary'].sample(5).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From $60 an hour' '$41 - $50 an hour' '$50 - $55 an hour'\n",
      " 'From $13 an hour' '$14 - $29 an hour']\n"
     ]
    }
   ],
   "source": [
    "print(jobs_hourly['salary'].sample(5).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sal_to_num(salary):    \n",
    "#     sal= int    \n",
    "#     '''Takes in a salary entry (as string) and extracts the digits as an integer.    \n",
    "#     If the salary is in a range (eg 20,000-25,00) it returns the average'''    \n",
    "    \n",
    "#     try:        \n",
    "#         sal = int(''.join(re.findall(r'([\\d-])', salary)))    \n",
    "#     except:        \n",
    "#         sal = (int(''.join(re.findall(r'([\\d-])', salary)).split(\"-\")[0]) + \n",
    "#                int(''.join(re.findall(r'([\\d-])', salary)).split(\"-\")[1])) / 2            \n",
    "        \n",
    "#     return int(sal)        \n",
    "\n",
    "# df.loc[:,'Salary'] = df.Salary.map(lambda x: sal_to_num(x)).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "focus": false,
    "id": "a0f701e0-80bd-40ba-9101-4535860c0968"
   },
   "outputs": [],
   "source": [
    "def convert_salary(salary, period='y', currency_rate=1):\n",
    "    try:\n",
    "        if period == 'y':\n",
    "            # [, ] -> space for some other currencies than dollar\n",
    "            sal = np.mean([float(re.sub(r'[, ]', '', s)) for s in re.findall(r'\\d+[, ]\\d{3,}', salary)])\n",
    "        elif period == 'm':\n",
    "            # could be less than $1000 therefore using r'\\d*[, ]?'\n",
    "            sal = np.mean([float(re.sub(r'[, ]', '', s)) for s in re.findall(r'\\d*[, ]?\\d{3,}', salary)])  \n",
    "        elif period == 'h':\n",
    "            # get rid of decimal points -> (?<![\\.|,])\\d{2,3} only give number back if there is no previous decimal point or coma \n",
    "            sal = np.mean([float(re.sub(r'[, ]', '', s)) for s in re.findall(r'(?<![\\.|,])\\d{2,3}|\\d[, ]?\\d{3}', salary)]) \n",
    "        else:\n",
    "            raise Exception(\"define period: ['y', 'm', 'h']\")\n",
    "        sal *= currency_rate\n",
    "        \n",
    "    except:\n",
    "        sal = np.nan\n",
    "    \n",
    "    return sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_hourly['salary'] = jobs_hourly['salary'].apply(lambda x: convert_salary(x, 'h'))\n",
    "jobs_monthly['salary'] = jobs_monthly['salary'].apply(lambda x: convert_salary(x, 'm'))\n",
    "jobs_yearly['salary'] = jobs_yearly['salary'].apply(lambda x: convert_salary(x, 'y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000.0    32\n",
       "50000.0    27\n",
       "70000.0    24\n",
       "55000.0    22\n",
       "65000.0    22\n",
       "Name: salary, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_yearly['salary'].value_counts().iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ != \"__main__\":\n",
    "    jobs_hourly.to_csv('./datasets/jobs_hourly.csv', index=False)\n",
    "    jobs_monthly.to_csv('./datasets/jobs_monthly.csv', index=False)\n",
    "    jobs_yearly.to_csv('./datasets/jobs_yearly.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "### Load in the the data of scraped salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>rating</th>\n",
       "      <th>summary</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intelligence Operations Specialist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>US Department of Homeland Security</td>\n",
       "      <td>144688.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Presents formal briefings or written reports o...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investigative Analyst</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York District Attorney's Office</td>\n",
       "      <td>48909.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>One year experience preferred, either as a par...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>Cyber Tech Group</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Providing legal and scholarly research; Keen e...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Research Scientist 1 (Biostatistics or Health ...</td>\n",
       "      <td>Albany, NY 12237</td>\n",
       "      <td>Health, Department of</td>\n",
       "      <td>72364.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Research Scientist will work under the dir...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>NYC HOUSING AUTHORITY</td>\n",
       "      <td>70437.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Fields of finance; economic, fiscal or statist...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title          location  \\\n",
       "0                 Intelligence Operations Specialist      New York, NY   \n",
       "1                              Investigative Analyst      New York, NY   \n",
       "2                                   Business Analyst      Brooklyn, NY   \n",
       "3  Research Scientist 1 (Biostatistics or Health ...  Albany, NY 12237   \n",
       "4                                   Business Analyst     Manhattan, NY   \n",
       "\n",
       "                               company    salary  rating  \\\n",
       "0   US Department of Homeland Security  144688.0     3.8   \n",
       "1  New York District Attorney's Office   48909.0     4.4   \n",
       "2                     Cyber Tech Group   65000.0     NaN   \n",
       "3                Health, Department of   72364.0     NaN   \n",
       "4                NYC HOUSING AUTHORITY   70437.5     3.8   \n",
       "\n",
       "                                             summary      city  \n",
       "0  Presents formal briefings or written reports o...  New York  \n",
       "1  One year experience preferred, either as a par...  New York  \n",
       "2  Providing legal and scholarly research; Keen e...  New York  \n",
       "3  The Research Scientist will work under the dir...  New York  \n",
       "4  Fields of finance; economic, fiscal or statist...  New York  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/jobs_yearly.csv')\n",
    "jobs = df.copy()\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(975, 7)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median).\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the salary value here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW salary.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extreme salaries. We don't have to choose the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of salaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 975 entries, 0 to 974\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   job_title  975 non-null    object \n",
      " 1   location   851 non-null    object \n",
      " 2   company    975 non-null    object \n",
      " 3   salary     975 non-null    float64\n",
      " 4   rating     574 non-null    float64\n",
      " 5   summary    971 non-null    object \n",
      " 6   city       975 non-null    object \n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 53.4+ KB\n"
     ]
    }
   ],
   "source": [
    "jobs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>975.000000</td>\n",
       "      <td>574.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>84166.722051</td>\n",
       "      <td>3.752787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>34348.361173</td>\n",
       "      <td>0.556025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29500.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78081.500000</td>\n",
       "      <td>3.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>101061.500000</td>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>400000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              salary      rating\n",
       "count     975.000000  574.000000\n",
       "mean    84166.722051    3.752787\n",
       "std     34348.361173    0.556025\n",
       "min     29500.000000    1.000000\n",
       "25%     60000.000000    3.500000\n",
       "50%     78081.500000    3.800000\n",
       "75%    101061.500000    4.200000\n",
       "max    400000.000000    5.000000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0489"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[['rating', 'salary']].corr().iloc[0,1].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating    401\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[['rating']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs['rating'].fillna(value=jobs['rating'].median(), inplace=True)\n",
    "if 'rating' in jobs.columns:\n",
    "    jobs.drop(['rating'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title      0\n",
       "location     124\n",
       "company        0\n",
       "salary         0\n",
       "summary        4\n",
       "city           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Checkmate Partners</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>Working cross-functionally with data scientist...</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Houston</td>\n",
       "      <td>JES Tech</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Bachelor’s degree or certification in Data Sci...</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Measurement Data Analyst</td>\n",
       "      <td>Houston</td>\n",
       "      <td>SPL, Inc.</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Associates degree (A.A.) or equivalent from a ...</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    job_title location             company    salary  \\\n",
       "102             Data Engineer  Houston  Checkmate Partners  205000.0   \n",
       "116            Data Scientist  Houston            JES Tech   55000.0   \n",
       "117  Measurement Data Analyst  Houston           SPL, Inc.   80000.0   \n",
       "\n",
       "                                               summary     city  \n",
       "102  Working cross-functionally with data scientist...  Houston  \n",
       "116  Bachelor’s degree or certification in Data Sci...  Houston  \n",
       "117  Associates degree (A.A.) or equivalent from a ...  Houston  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['summary'].fillna(value='Nothing', inplace=True)\n",
    "empty_location_idx = jobs[jobs['location'].isnull()].index\n",
    "jobs.loc[empty_location_idx, 'location'] = jobs.loc[empty_location_idx].apply(lambda col: col['city'], axis=1)\n",
    "jobs.loc[empty_location_idx].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26     New York State\n",
       "102           Houston\n",
       "116           Houston\n",
       "117           Houston\n",
       "118           Houston\n",
       "Name: location, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[~jobs['location'].str.contains(',')]['location'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        New York, NY\n",
       "1        New York, NY\n",
       "2        Brooklyn, NY\n",
       "3    Albany, NY 12237\n",
       "4       Manhattan, NY\n",
       "Name: location, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs[jobs['location'].str.contains(',')]['location'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_location(data, c=True):\n",
    "    \"\"\"\n",
    "    This function returns either the city or the state name depending on the parameter c\n",
    "    (if c is True then city else state), but only if the string contains a comma. Otherwise\n",
    "    it returns the raw text. \n",
    "    \n",
    "    Parameters:\n",
    "    data [String]: location data\n",
    "    c [Boolean]: True for city name, False for state name\n",
    "    \n",
    "    Return:\n",
    "    city [String]: city name\n",
    "    or\n",
    "    state [String]: state name\n",
    "    or\n",
    "    data [String]: raw data\n",
    "    \"\"\"\n",
    "    if ',' in data:\n",
    "        first_data, *second_data = data.split(',')  # in the case of several commas\n",
    "        splitted_names = re.findall(r'[A-Z][a-z]+', first_data)\n",
    "        city = (' ').join(splitted_names) if splitted_names else np.nan\n",
    "        state_match = re.search(r'[A-Z]{2}', second_data[0])\n",
    "        state =  state_match.group() if state_match else np.nan\n",
    "    else:\n",
    "        return data\n",
    "    if c:\n",
    "        return city\n",
    "    else:\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intelligence Operations Specialist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>US Department of Homeland Security</td>\n",
       "      <td>144688.0</td>\n",
       "      <td>Presents formal briefings or written reports o...</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Investigative Analyst</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York District Attorney's Office</td>\n",
       "      <td>48909.0</td>\n",
       "      <td>One year experience preferred, either as a par...</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>Cyber Tech Group</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Providing legal and scholarly research; Keen e...</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            job_title      location  \\\n",
       "0  Intelligence Operations Specialist  New York, NY   \n",
       "1               Investigative Analyst  New York, NY   \n",
       "2                    Business Analyst  Brooklyn, NY   \n",
       "\n",
       "                               company    salary  \\\n",
       "0   US Department of Homeland Security  144688.0   \n",
       "1  New York District Attorney's Office   48909.0   \n",
       "2                     Cyber Tech Group   65000.0   \n",
       "\n",
       "                                             summary      city state  \n",
       "0  Presents formal briefings or written reports o...  New York    NY  \n",
       "1  One year experience preferred, either as a par...  New York    NY  \n",
       "2  Providing legal and scholarly research; Keen e...  Brooklyn    NY  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['city'] = jobs['location'].apply(lambda x: split_location(x))\n",
    "jobs['state'] = jobs['location'].apply(lambda x: split_location(x, False))\n",
    "jobs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty_states_indices = jobs[jobs['state'].isnull()].index.tolist()\n",
    "# empty_states_indices\n",
    "# jobs.loc[empty_states_indices, :]\n",
    "jobs['state'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TX                168\n",
       "FL                107\n",
       "AZ                 93\n",
       "CA                 82\n",
       "GA                 76\n",
       "IL                 68\n",
       "NV                 62\n",
       "WA                 52\n",
       "MA                 34\n",
       "NY                 34\n",
       "LA                 24\n",
       "OH                 22\n",
       "Austin             21\n",
       "PA                 20\n",
       "Phoenix            20\n",
       "Los Angeles        19\n",
       "San Francisco      15\n",
       "Miami              14\n",
       "Atlanta            13\n",
       "Chicago            11\n",
       "Houston            11\n",
       "NJ                  5\n",
       "DE                  2\n",
       "IN                  1\n",
       "New York State      1\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs['state'].replace({'Los Angeles': 'CA', \n",
    "                       'San Francisco': 'CA',\n",
    "                       'Austin': 'TX',\n",
    "                       'Houston': 'TX',\n",
    "                       'Chicago': 'IL',\n",
    "                       'Phoenix': 'AZ',\n",
    "                       'Miami': 'FL',\n",
    "                       'Atlanta': 'GA',\n",
    "                       'New York State': 'NY'}, inplace=True)\n",
    "jobs.drop(['location'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>summary</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>975</td>\n",
       "      <td>975</td>\n",
       "      <td>975</td>\n",
       "      <td>975</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>825</td>\n",
       "      <td>677</td>\n",
       "      <td>905</td>\n",
       "      <td>150</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Indeed</td>\n",
       "      <td>Experience in an ML engineer or data scientist...</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   job_title company  \\\n",
       "count                    975     975   \n",
       "unique                   825     677   \n",
       "top     Senior Data Engineer  Indeed   \n",
       "freq                      14      29   \n",
       "\n",
       "                                                  summary    city state  \n",
       "count                                                 975     975   975  \n",
       "unique                                                905     150    16  \n",
       "top     Experience in an ML engineer or data scientist...  Austin    TX  \n",
       "freq                                                    8      96   200  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "707                Supervisory Financial Systems Analyst\n",
       "530           Big Data Engineer, Digital Innovation Team\n",
       "131                              Financial Analyst, FP&A\n",
       "460                                   Programmer Analyst\n",
       "552    Analyst/Senior Analyst, Digital Success Experi...\n",
       "107                           IT Data Programmer Analyst\n",
       "629                              Senior Business Analyst\n",
       "289                 Database Administrator and Developer\n",
       "528                    Economist - local candidates only\n",
       "6                                           Data Analyst\n",
       "Name: job_title, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs['job_title'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78081.5"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_salary = jobs['salary'].median()\n",
    "median_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "\n",
    "# salary distribution can be quite skewed therefore taking whisker factor 3\n",
    "sns.boxplot(x=jobs['salary'], orient='h', fliersize=8, \n",
    "            linewidth=1.5, saturation=0.5, whis=3.0, ax=ax)\n",
    "ax.set_title('Salary\\n', fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969, 7)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1, q3 = np.quantile(jobs['salary'], [0.25, 0.75])\n",
    "iqr = q3 - q1\n",
    "outlier_upper_limit = q3 + 3*iqr\n",
    "salary_outlier_idx = jobs.loc[jobs['salary'] > outlier_upper_limit].index\n",
    "jobs.drop(index=salary_outlier_idx, inplace=True)\n",
    "jobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer = Binarizer(threshold=median_salary)\n",
    "jobs['high_salary'] = binarizer.transform(jobs[['salary']]).astype(int)\n",
    "# jobs.loc[:, 'salary'] = jobs['salary'].map(lambda x: 'High' if x > median_salary else 'Low')\n",
    "jobs.drop(['salary'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_order = jobs.groupby('state').mean().sort_values(by='high_salary', ascending=False)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='state', y='high_salary', data=jobs, order=state_order.index, \n",
    "            errcolor='k')\n",
    "plt2 = plt.twinx()\n",
    "plt2.set_ylim([0, 210])\n",
    "plt2.plot(jobs.groupby('state').size().reindex(state_order.index), lw=5, c='r')\n",
    "plt2.set_ylabel('job frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5046"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_accuracy = round(jobs['high_salary'].value_counts(normalize=True).max(), 4)\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "### Create a classification model to predict High/Low salary. \n",
    "\n",
    "\n",
    "- Start by ONLY using the location as a feature.\n",
    "- Use at least two different classifiers you find suitable.\n",
    "- Remember that scaling your features might be necessary.\n",
    "- Display the coefficients/feature importances and write a short summary of what they mean.\n",
    "- Create a few new variables in your dataframe to represent interesting features of a job title (e.g. whether 'Senior' or 'Manager' is in the title).\n",
    "- Incorporate other text features from the title or summary that you believe will predict the salary.\n",
    "- Then build new classification models including also those features. Do they add any value?\n",
    "- Tune your models by testing parameter ranges, regularization strengths, etc. Discuss how that affects your models.\n",
    "- Discuss model coefficients or feature importances as applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_union, make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_Albany</th>\n",
       "      <th>city_Alpharetta</th>\n",
       "      <th>city_Anaheim</th>\n",
       "      <th>city_Andover</th>\n",
       "      <th>city_Arlington Heights</th>\n",
       "      <th>city_Atlanta</th>\n",
       "      <th>city_Austin</th>\n",
       "      <th>city_Avondale</th>\n",
       "      <th>city_Baldwinsville</th>\n",
       "      <th>city_Bellevue</th>\n",
       "      <th>...</th>\n",
       "      <th>state_IN</th>\n",
       "      <th>state_LA</th>\n",
       "      <th>state_MA</th>\n",
       "      <th>state_NJ</th>\n",
       "      <th>state_NV</th>\n",
       "      <th>state_NY</th>\n",
       "      <th>state_OH</th>\n",
       "      <th>state_PA</th>\n",
       "      <th>state_TX</th>\n",
       "      <th>state_WA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_Albany  city_Alpharetta  city_Anaheim  city_Andover  \\\n",
       "0            0                0             0             0   \n",
       "\n",
       "   city_Arlington Heights  city_Atlanta  city_Austin  city_Avondale  \\\n",
       "0                       0             0            0              0   \n",
       "\n",
       "   city_Baldwinsville  city_Bellevue  ...  state_IN  state_LA  state_MA  \\\n",
       "0                   0              0  ...         0         0         0   \n",
       "\n",
       "   state_NJ  state_NV  state_NY  state_OH  state_PA  state_TX  state_WA  \n",
       "0         0         0         1         0         0         0         0  \n",
       "\n",
       "[1 rows x 164 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = jobs[['city', 'state', 'high_salary']].copy()\n",
    "X = pd.get_dummies(X, prefix=['city', 'state'], columns=['city', 'state'], drop_first=True)\n",
    "y = X.pop('high_salary')\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropDummyfierPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, columns_to_drop=None, columns_to_dummify=None, prefix=None, drop_first=True):\n",
    "        self.feature_names = []\n",
    "        self.columns_to_drop = columns_to_drop\n",
    "        self.columns_to_dummify = columns_to_dummify\n",
    "        self.prefix = prefix\n",
    "        self.drop_first = drop_first\n",
    "        \n",
    "    def _drop_unused_cols(self, X):\n",
    "        \"\"\"Try to drop each given column by its own\"\"\"\n",
    "        for col in self.columns_to_drop:\n",
    "            try:\n",
    "                X = X.drop(col, axis=1)\n",
    "            except:\n",
    "                pass\n",
    "        return X\n",
    "\n",
    "    def _make_dummy_cols(self, X):\n",
    "        if len(self.prefix) != len(self.columns_to_dummify):\n",
    "            self.prefix = None\n",
    "        X = pd.get_dummies(X, columns=self.columns_to_dummify, prefix=self.prefix, drop_first=self.drop_first)\n",
    "        return X\n",
    "    \n",
    "    def transform(self, X, *args):\n",
    "        X = self._make_dummy_cols(X)\n",
    "        X = self._drop_unused_cols(X)\n",
    "        self.feature_names = X.columns\n",
    "        return X\n",
    "    \n",
    "    def fit(self, X, *args):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "        \n",
    "    def fit(self, X, *args):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, *args):\n",
    "        return X[self.column].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('prep_dum', DropDummyfierPreprocessor(columns_to_drop=['job_title', 'company', 'summary', 'high_salary'], \n",
    "                                                        columns_to_dummify=['state', 'city'], \n",
    "                                                        prefix=['state', 'city'])),\n",
    "                 ('prep_scale', StandardScaler())])\n",
    "X = pipe.fit_transform(jobs)\n",
    "y = jobs['high_salary'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, BaggingClassifier, \\\n",
    "AdaBoostClassifier, AdaBoostRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'estimator': [DecisionTreeClassifier(), \n",
    "                  DecisionTreeRegressor(),\n",
    "                  LogisticRegression(solver='liblinear'),\n",
    "                  KNeighborsClassifier(),\n",
    "                 ],\n",
    "    \n",
    "    'param_grid': [\n",
    "        {\n",
    "            'max_depth': [1, 2, 3],\n",
    "            'max_features': [None, 1, 2, 3],\n",
    "            'min_samples_split': [2, 3, 4, 20,  30, 50],\n",
    "            'ccp_alpha': [0, 0.001, 0.005, 0.01]\n",
    "        },\n",
    "        {\n",
    "            'max_depth': [1, 2, 3],\n",
    "            'max_features': [None, 1, 2, 3],\n",
    "            'min_samples_split': [2, 3, 4, 20,  30, 50],\n",
    "            'ccp_alpha': [0, 0.001, 0.005, 0.01]\n",
    "        },\n",
    "        {\n",
    "            'C': np.logspace(-4, 4, 15), \n",
    "            'penalty': ['l2', 'l1'],\n",
    "        },\n",
    "        {\n",
    "            'n_neighbors': range(3, 100, 2),\n",
    "            'weights': ['uniform', 'distance']\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimators_scores(X_train, y_train, X_test=None, y_test=None, \n",
    "                          models=[], params=[], verbose=1, n_jobs=2, cv=5):\n",
    "    best_estimators = []\n",
    "    for i, _ in enumerate(models):\n",
    "        p = {'param_grid': params[i]}\n",
    "        gs = GridSearchCV(estimator=models[i], \n",
    "                          verbose = verbose,\n",
    "                          n_jobs = n_jobs,\n",
    "                          cv = cv,\n",
    "                          **p)\n",
    "        gs.fit(X_train, y_train)\n",
    "        model_name = type(gs.estimator).__name__\n",
    "        print('{model} - Accuracy score: {score}'.format(model=model_name,\n",
    "                                                         score=gs.score(X_train, y_train).round(4)))\n",
    "        print('{model} - CV training score: {score}'.format(model=model_name, \n",
    "                                                            score=gs.best_score_.round(4)))\n",
    "        \n",
    "        if isinstance(X_test, pd.DataFrame) and isinstance(y_test, pd.Series):\n",
    "            print('{model} - CV test score: {score}'.format(model=model_name,\n",
    "                                                            score=gs.score(X_test, y_test).round(4)))\n",
    "        print()\n",
    "        best_estimators.append(gs)\n",
    "    return best_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done 780 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=2)]: Done 1440 out of 1440 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier - Accuracy score: 0.591\n",
      "DecisionTreeClassifier - CV training score: 0.5819\n",
      "\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 1372 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=2)]: Done 1440 out of 1440 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor - Accuracy score: 0.0577\n",
      "DecisionTreeRegressor - CV training score: 0.0439\n",
      "\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 150 out of 150 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression - Accuracy score: 0.6748\n",
      "LogisticRegression - CV training score: 0.6323\n",
      "\n",
      "Fitting 5 folds for each of 98 candidates, totalling 490 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 300 tasks      | elapsed:    4.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier - Accuracy score: 0.6826\n",
      "KNeighborsClassifier - CV training score: 0.6077\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 490 out of 490 | elapsed:    7.1s finished\n"
     ]
    }
   ],
   "source": [
    "estimators = get_estimators_scores(X_train, y_train, X_test, y_test,\n",
    "                                  models = model_params['estimator'], \n",
    "                                  params = model_params['param_grid'],\n",
    "                                  cv = skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClassifier/ DecisionTreeRegressor:\n",
    "- Feature Importance is computed as the total reduction of the criterion brought by that feature. Because the default setting for that classifier was used, it refers to the gini score. The state California has the highest effect to the classification in the given case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-234-3212cc7a762d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# DecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m pd.DataFrame(list(zip(X_train.columns, estimators[0].best_estimator_.feature_importances_)), \n\u001b[0m\u001b[1;32m      3\u001b[0m              \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Feature'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Importance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             ).sort_values(by='Importance', ascending=False)[:3]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier\n",
    "pd.DataFrame(list(zip(X_train.columns, estimators[0].best_estimator_.feature_importances_)), \n",
    "             columns=['Feature', 'Importance']\n",
    "            ).sort_values(by='Importance', ascending=False)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeRegressor\n",
    "pd.DataFrame(list(zip(X_train.columns, estimators[1].best_estimator_.feature_importances_)), \n",
    "             columns=['Feature', 'Importance']\n",
    "            ).sort_values(by='Importance', ascending=False)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression:\n",
    "- If following link function is used:\n",
    "$$P(y=1|X)=\\frac{1}{1+e^{-z}}$$,\n",
    "then is the probability to predict class 1 by 50% if the sum of all coefficients multiplied by their features is 0. Otherwise if z increases the probability for predicting class 1 increases as well and vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "pd.DataFrame({'Feature': X_train.columns, \n",
    "              'Coefficient': estimators[2].best_estimator_.coef_[0], \n",
    "              'Abs_Coefficient': abs(estimators[2].best_estimator_.coef_[0])}\n",
    "            ).sort_values(by='Abs_Coefficient', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = jobs.copy()\n",
    "X.drop(['salary'], axis=1, inplace=True)\n",
    "y = X.pop('high_salary')\n",
    "#X.reset_index(inplace=True)\n",
    "X.drop(columns=['location', 'summary'], inplace=True)\n",
    "X = pd.get_dummies(X, columns=['company', 'city', 'state'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(stop_words='english',\n",
    "                            #sublinear_tf=True,\n",
    "                            max_df=0.3,\n",
    "                            max_features=1000)\n",
    "\n",
    "tvec.fit(X_train['job_title']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_job_title = tvec.transform(X_train['job_title'])\n",
    "X_test_job_title = tvec.transform(X_test['job_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(X_train_job_title.toarray(),\n",
    "                  columns=tvec.get_feature_names())\n",
    "\n",
    "df_train.transpose().sort_values(0, ascending=False).transpose().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(X_test_job_title.toarray(),\n",
    "                  columns=tvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['job_title'], axis=1, inplace=True)\n",
    "X_test.drop(columns=['job_title'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(inplace=True)\n",
    "X_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, df_train], axis=1)\n",
    "X_test = pd.concat([X_test, df_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X= pd.concat([X.loc[:, ~X.columns.isin(['job_title'])], df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs_prep = DropDummyfierPreprocessor(columns_to_drop=['location', 'summary'], \n",
    "#                               columns_to_dummify=['company', 'city', 'state'])\n",
    "\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# pipe = Pipeline(steps=[('jobs_prep', jobs_prep),\n",
    "#                        ('scaler', scaler)])\n",
    "\n",
    "# p = pipe.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = get_estimators_scores(X_train, y_train, X_test, y_test,\n",
    "                                  models = model_params['estimator'], \n",
    "                                  params = model_params['param_grid'],\n",
    "                                  cv = skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# confusion matrix\n",
    "def docm(y_true, y_pred, labels=None):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if labels is not None:\n",
    "        cols = ['pred_' + c for c in labels]\n",
    "        df = pd.DataFrame(cm, index=labels, columns=cols)\n",
    "    else:\n",
    "        cols = ['pred_'+str(i) for i in range(len(cm))]\n",
    "        df = pd.DataFrame(cm, columns=cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "docm(y_test, estimators[0].best_estimator_.predict(X_test), labels=['high_salary', 'low_salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression\n",
    "docm(y_test, estimators[2].best_estimator_.predict(X_test), labels=['high_salary', 'low_salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(gamma='scale')\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "etc = ExtraTreesClassifier(n_estimators=100)\n",
    "rc = RidgeClassifier(tol=1e-2, solver=\"sag\")\n",
    "per = Perceptron(max_iter=1000, tol=1e-3)\n",
    "pac = PassiveAggressiveClassifier(max_iter=1000, tol=1e-3)\n",
    "lsvc = LinearSVC(loss='squared_hinge', \n",
    "                 penalty='l2',\n",
    "                 max_iter=100000,\n",
    "                 #tol=0.01, \n",
    "                 dual=False)\n",
    "sgdc = SGDClassifier(alpha=.0001,\n",
    "                     penalty=\"elasticnet\",\n",
    "                     max_iter=1000,\n",
    "                     tol=1e-3)\n",
    "knn = estimators[3].best_estimator_\n",
    "bg_knn = BaggingClassifier(base_estimator=knn, \n",
    "                           n_estimators=100, \n",
    "                           max_samples=0.8,\n",
    "                           max_features=0.8)\n",
    "dtc = estimators[0].best_estimator_\n",
    "bg_dtc = BaggingClassifier(base_estimator=dtc, \n",
    "                           n_estimators=100, \n",
    "                           max_samples=0.8,\n",
    "                           max_features=0.8)\n",
    "adaboost_dtc = AdaBoostClassifier(base_estimator=dtc,\n",
    "                                  n_estimators=10,\n",
    "                                  algorithm='SAMME')\n",
    "gradientboost = GradientBoostingClassifier(n_estimators=100,\n",
    "                                           criterion='mse',\n",
    "                                           loss='exponential',\n",
    "                                           max_depth=3,\n",
    "                                           learning_rate=1.0)\n",
    "\n",
    "\n",
    "for model in [svc, rfc, etc, rc, per, pac, lsvc, sgdc, bg_knn, bg_dtc, adaboost_dtc, gradientboost]:\n",
    "    model.fit(X_train, y_train)\n",
    "    model_name = type(model).__name__\n",
    "    print('{model} - Accuracy score: {score}' \\\n",
    "              .format(model=model_name,\n",
    "                      score=model.score(X_train, y_train).round(4)))\n",
    "    print('{model} - CV training score: {score}' \\\n",
    "              .format(model=model_name,\n",
    "                      score=cross_val_score(model, X_train, y_train, cv=skf).mean().round(4)))\n",
    "    print('{model} - CV testing score: {score}' \\\n",
    "              .format(model=model_name, \n",
    "                      score=cross_val_score(model, X_test, y_test, cv=skf).mean().round(4)))    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tuning of hyperparameters with gridsearch\n",
    "model_params = {\n",
    "    'models': [RandomForestClassifier(n_estimators=200), \n",
    "               ExtraTreesClassifier(n_estimators=200), \n",
    "               LinearSVC(dual=False)],\n",
    "    'gs_params': [\n",
    "        {\n",
    "            'max_depth': [1, 2, 3, None],\n",
    "            'max_features': [None, 1, 2, 3],\n",
    "            'min_samples_split': [2, 3, 4, 20,  30, 50],\n",
    "            'ccp_alpha': [0, 0.001, 0.005, 0.01, 0.1]\n",
    "        },\n",
    "        {\n",
    "            'max_depth': [1, 2, 3, None],\n",
    "            'max_features': [None, 1, 2, 3],\n",
    "            'min_samples_split': [2, 3, 4, 20,  30, 50],\n",
    "            'ccp_alpha': [0, 0.001, 0.005, 0.01, 0.1]\n",
    "        },\n",
    "        {\n",
    "            'penalty': ['l2', 'l1'],\n",
    "            'loss': ['hinge', 'squared_hinge'],\n",
    "            'C': [1, 10, 100, 1000],\n",
    "            'fit_intercept': [True, False]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = get_estimators_scores(X_train, y_train, X_test, y_test,\n",
    "                                  models = model_params['models'], \n",
    "                                  params = model_params['gs_params'],\n",
    "                                  cv = skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "### Model evaluation:\n",
    "\n",
    "Your boss would rather tell a client incorrectly that they would get a lower salary job than tell a client incorrectly that they would get a high salary job. Adjust one of your models to ease his mind, and explain what it is doing and any tradeoffs.\n",
    "\n",
    "\n",
    "- Use cross-validation to evaluate your models.\n",
    "- Evaluate the accuracy, AUC, precision and recall of the models.\n",
    "- Plot the ROC and precision-recall curves for at least one of your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, plot_confusion_matrix, \\\n",
    "plot_roc_curve, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimators[0].best_estimator_.predict(X_train, y_train)\n",
    "rfc = RandomForestClassifier(n_estimators=100, n_jobs=2, class_weight={0:.6, 1:.4})\n",
    "\n",
    "params = {\n",
    "    'max_depth': [1, 3, None],\n",
    "    'max_features': [None, 1, 3],\n",
    "    'min_samples_split': [2, 3, 50],\n",
    "    'ccp_alpha': [0, 0.001, 0.1]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(rfc, # scoring='precision', \n",
    "                  param_grid=params, \n",
    "                  verbose=1, \n",
    "                  n_jobs=2,\n",
    "                  cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print('Accuracy score:', gs.score(X_train, y_train))\n",
    "print('CV score:', gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rather to predict false negative than false positive, that's why class 0 was weighted higher \n",
    "# (and the gridsearch was layed out for precision scoring)\n",
    "plot_confusion_matrix(gs, X_train, y_train, cmap='Blues', labels=[1, 0], values_format='.0f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(gs, X_test, y_test, cmap='Blues', labels=[1, 0], values_format='.0f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_at_threshold(x, threshold=0.5):\n",
    "    if x >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = gs.predict(X_train)\n",
    "predictions_test = gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the threshold for the probability of class 1 to have a higher precision on prediction of class 0\n",
    "Y_prediction = pd.DataFrame(gs.predict_proba(X_train), columns=['high_salary', 'low_salary'])\n",
    "Y_prediction['predict_with_thres'] = Y_prediction['high_salary'].apply(predict_at_threshold, threshold=0.6)\n",
    "Y_prediction['true_value'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prediction.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy:', accuracy_score(y_train, predictions_train))\n",
    "print('Testing accuracy:', accuracy_score(y_test, predictions_test))\n",
    "\n",
    "print('Training precision:', precision_score(y_train, predictions_train))\n",
    "print('Testing precision:', precision_score(y_test, predictions_test))\n",
    "\n",
    "print('Training recall:', recall_score(y_train, predictions_train))\n",
    "print('Testing recall:', recall_score(y_test, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, plot_roc_curve, plot_precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ROC curve you want to gain a really strong slope in the beginning with as less false positive rate as possible. The best score would be having a area under the curve of 1 to have a perfect prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plot_roc_curve(gs.best_estimator_, X_train, y_train, ax=ax)\n",
    "ax.plot([0, 1], [0, 1], 'k--', linewidth=4)  # baseline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision shows the ratio of how often the positive labelled class was predicted correclty over \n",
    "all predictions which were done for that class. Whereas the recall depicts the ratio of that class over it occurence\n",
    "in the dataset. That means that you can predict less, but more precise to have a high precision score, but then chance\n",
    "increases that the class occurence more often then you actually predict it and then the recall decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plot_precision_recall_curve(gs, X_train, y_train, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "<img src=\"http://imgur.com/xDpSobf.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### Bonus:\n",
    "\n",
    "- Answer the salary discussion by using your model to explain the tradeoffs between detecting high vs low salary positions. \n",
    "- Discuss the differences and explain when you want a high-recall or a high-precision model in this scenario.\n",
    "- Obtain the ROC/precision-recall curves for the different models you studied (at least the tuned model of each category) and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "focus": false,
    "id": "068dc1cf-7fd7-4f27-a1f1-7f0a5a221d29"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize your results in an executive summary written for a non-technical audience.\n",
    "   \n",
    "- Writeups should be at least 500-1000 words, defining any technical terms, explaining your approach, as well as any risks and limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR TEXT HERE IN MARKDOWN FORMAT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/xDpSobf.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### BONUS\n",
    "\n",
    "Convert your executive summary into a public blog post of at least 500 words, in which you document your approach in a tutorial for other aspiring data scientists. Link to this in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR LINK HERE IN MARKDOWN FORMAT "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
